<?xml version="1.0" encoding="UTF-8"?><?xml-stylesheet href="/scripts/pretty-feed-v3.xsl" type="text/xsl"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:h="http://www.w3.org/TR/html4/"><channel><title>cloudinwind&apos;s blog</title><description>è®°å½•ä¸ªäººç»å†</description><link>https://claudiakim6827362.github.io</link><item><title>RLç¬”è®°ï¼ˆ29ï¼‰ï¼šæ¨ç†æ¨¡å‹çš„å´›èµ· (GRPO &amp; PRM)</title><link>https://claudiakim6827362.github.io/blog/rl-note-29</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/rl-note-29</guid><description>å¤§æ¨¡å‹è®­ç»ƒçš„æ–°èŒƒå¼ï¼šè¯¦è§£ DeepSeek æå‡ºçš„ GRPO å¦‚ä½•å½»åº•çœå» Critic ç½‘ç»œï¼Œä»¥åŠ PRM å¦‚ä½•é€šè¿‡è¿‡ç¨‹ç›‘ç£è®©æ¨¡å‹å­¦ä¼šæ­£ç¡®æ¨ç†ã€‚</description><pubDate>Wed, 07 Jan 2026 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;å¼•è¨€ï¼ˆIntroductionï¼‰&lt;/h2&gt;
&lt;p&gt;åœ¨ä¸Šä¸€ç¯‡ç¬”è®°ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ç»å…¸çš„ &lt;strong&gt;PPO + RLHF&lt;/strong&gt; æµç¨‹ã€‚è™½ç„¶ PPO éå¸¸æœ‰æ•ˆï¼Œä½†åœ¨è®­ç»ƒè¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹æ—¶ï¼Œå®ƒé¢ä¸´ä¸¤ä¸ªæŒ‘æˆ˜ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;èµ„æºæ¶ˆè€—å·¨å¤§&lt;/strong&gt;ï¼šPPO éœ€è¦ç»´æŠ¤ Actorã€Refã€Rewardã€Critic å››ä¸ªæ¨¡å‹ï¼Œæ˜¾å­˜å¼€é”€æé«˜ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç»“æœå¯¼å‘çš„å±€é™&lt;/strong&gt;ï¼šä¼ ç»Ÿçš„å¥–åŠ±æ¨¡å‹åªå¯¹æœ€ç»ˆç­”æ¡ˆè¯„åˆ†ï¼ˆORMï¼‰ï¼Œè€Œä¸å…³å¿ƒæ¨ç†è¿‡ç¨‹ã€‚å¦‚æœæ¨¡å‹å‡‘å·§çŒœå¯¹äº†ç­”æ¡ˆï¼Œä¹Ÿä¼šå¾—åˆ°é«˜åˆ†ï¼Œè¿™ä¼šå¯¼è‡´â€œèµ°æ·å¾„â€å’Œå¹»è§‰ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;æœ¬ç« å°†ä»‹ç» &lt;strong&gt;GRPO&lt;/strong&gt; â€”â€”ä¸€ç§æ›´è½»é‡ã€æ›´é«˜æ•ˆçš„ç­–ç•¥ä¼˜åŒ–ç®—æ³•ï¼Œä»¥åŠ &lt;strong&gt;PRM&lt;/strong&gt; â€”â€”ä¸€ç§å¯¹æ€ç»´è¿‡ç¨‹è¿›è¡Œç»†ç²’åº¦ç›‘ç£çš„å¥–åŠ±æœºåˆ¶ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;GRPO (Group Relative Policy Optimization)&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;è®ºæ–‡&lt;/strong&gt;ï¼š&lt;a href=&quot;https://arxiv.org/abs/2402.03300&quot;&gt;DeepSeekMath: Pushing the Limits of Mathematical Reasoning in LLMs&lt;/a&gt;
&lt;strong&gt;åº”ç”¨&lt;/strong&gt;ï¼šDeepSeek-V3 / DeepSeek-R1&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;GRPO çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºï¼š&lt;strong&gt;å½»åº•ä¸¢å¼ƒäº† Critic æ¨¡å‹ï¼Œåˆ©ç”¨ç»„å†…ç›¸å¯¹æ’åæ¥ä¼°è®¡ä¼˜åŠ¿å‡½æ•°ï¼ˆAdvantageï¼‰ã€‚&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;æ ¸å¿ƒæ€æƒ³ï¼šç»„å†…ç›¸å¯¹è¯„ä»·&lt;/h3&gt;
&lt;p&gt;åœ¨ PPO ä¸­ï¼Œæˆ‘ä»¬éœ€è¦ Critic ç½‘ç»œæ¥é¢„æµ‹çŠ¶æ€ä»·å€¼ $V(s)$ï¼Œä»è€Œè®¡ç®—ä¼˜åŠ¿ $A = Q - V$ã€‚
è€Œåœ¨ GRPO ä¸­ï¼Œå¯¹äºæ¯ä¸€ä¸ªæç¤ºè¯ï¼ˆPromptï¼‰$q$ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;è®©æ¨¡å‹ç”Ÿæˆ&lt;strong&gt;ä¸€ç»„&lt;/strong&gt;ä¸åŒçš„å›å¤ ${o_1, o_2, o_3, ..., o_G}$ï¼ˆç»„å¤§å°ä¸º $G$ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;åˆ©ç”¨å¥–åŠ±æ¨¡å‹ï¼ˆæˆ–è§„åˆ™å¥–åŠ±ï¼‰è®¡ç®—å‡ºè¿™ä¸€ç»„å›å¤çš„åˆ†æ•° ${r_1, r_2, r_3, ..., r_G}$ã€‚&lt;/li&gt;
&lt;li&gt;é€šè¿‡è¿™ç»„åˆ†æ•°çš„&lt;strong&gt;ç›¸å¯¹å¼ºå¼±&lt;/strong&gt;æ¥ç›´æ¥å¾—å‡ºæ¯ä¸ªå›å¤çš„ä¼˜åŠ¿ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;ä¼˜åŠ¿å‡½æ•°è®¡ç®—&lt;/h3&gt;
&lt;p&gt;ç¬¬ $i$ ä¸ªå›å¤çš„ä¼˜åŠ¿å‡½æ•° $A_i$ è®¡ç®—å…¬å¼ä¸ºï¼š
$$
A_i = \frac{r_i - \text{mean}(r_1, r_2, ..., r_G)}{\text{std}(r_1, r_2, ..., r_G)}
$$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;ğŸ’¡ ç›´è§‰ç†è§£&lt;/strong&gt;ï¼š
è¿™å°±åƒæ˜¯åœ¨ç­çº§é‡Œè€ƒè¯•ã€‚æˆ‘ä»¬ä¸éœ€è¦ä¸€ä¸ªç»å¯¹çš„â€œæ»¡åˆ†æ ‡å‡†â€ï¼ˆCriticï¼‰ï¼Œåªéœ€è¦çœ‹ä½ åœ¨ç­çº§é‡Œçš„æ’åã€‚å¦‚æœä½ æ¯”ç­çº§å¹³å‡åˆ†é«˜ï¼Œæˆ‘ä»¬å°±å¢åŠ ä½ è¿™ç§è¡Œä¸ºçš„æ¦‚ç‡ï¼›åä¹‹åˆ™é™ä½ã€‚&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;GRPO æŸå¤±å‡½æ•°&lt;/h3&gt;
&lt;p&gt;$$
L_{GRPO}(\theta) = \frac{1}{G} \sum_{i=1}^G \left[ \min\left( \frac{\pi_\theta(o_i|q)}{\pi_{\text{old}}(o_i|q)} A_i, \text{clip}\left(\frac{\pi_\theta(o_i|q)}{\pi_{\text{old}}(o_i|q)}, 1-\epsilon, 1+\epsilon\right) A_i \right) - \beta D_{KL}(\pi_\theta || \pi_{\text{ref}}) \right]
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜åŠ¿&lt;/strong&gt;ï¼šç”±äºçœå»äº† Critic ç½‘ç»œï¼Œåœ¨å¤§æ¨¡å‹è®­ç»ƒä¸­å¯ä»¥èŠ‚çœçº¦ &lt;strong&gt;50%&lt;/strong&gt; çš„æ¢¯åº¦è®¡ç®—ç›¸å…³æ˜¾å­˜ï¼Œä»è€Œå…è®¸æ›´é•¿çš„ä¸Šä¸‹æ–‡æˆ–æ›´å¤§çš„ Batch Sizeã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;PRM (Process Reward Models)&lt;/h2&gt;
&lt;p&gt;ä¼ ç»Ÿçš„å¥–åŠ±æ¨¡å‹è¢«ç§°ä¸º &lt;strong&gt;ORM (Outcome Reward Models)&lt;/strong&gt;ï¼šåªçœ‹ç»“æœã€‚
&lt;strong&gt;PRM (Process Reward Models)&lt;/strong&gt; åˆ™æ˜¯å¯¹æ¨ç†é“¾æ¡ä¸­çš„&lt;strong&gt;æ¯ä¸€ä¸ªæ­¥éª¤&lt;/strong&gt;è¿›è¡Œæ‰“åˆ†ã€‚&lt;/p&gt;
&lt;h3&gt;æ ¸å¿ƒåŠ¨æœº&lt;/h3&gt;
&lt;p&gt;åœ¨å¤æ‚çš„æ•°å­¦æ¨å¯¼æˆ–ç¼–ç¨‹ä»»åŠ¡ä¸­ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä¸­é—´é”™ä¸€æ­¥ï¼Œæ­¥æ­¥é”™&lt;/strong&gt;ï¼šå³ä½¿æœ€ç»ˆç­”æ¡ˆå¯¹ï¼Œä¸­é—´é€»è¾‘ä¹Ÿå¯èƒ½æœ‰æ¯’ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å¥–åŠ±ç¨€ç–&lt;/strong&gt;ï¼šåªæœ‰åˆ°æœ€åæ‰ç»™åˆ†ï¼Œæ¨¡å‹å¾ˆéš¾å­¦ä¼šé•¿é“¾æ¡çš„é€»è¾‘ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;è®­ç»ƒä¸è¿ä½œæœºåˆ¶&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;æ­¥éª¤æ‹†è§£&lt;/strong&gt;ï¼šå°†æ¨¡å‹ç”Ÿæˆçš„æ€ç»´é“¾ï¼ˆCoTï¼‰åˆ©ç”¨æ¢è¡Œç¬¦æˆ–ç‰¹æ®Š token æ‹†åˆ†ä¸º $S_1, S_2, ..., S_n$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç»†ç²’åº¦æ ‡æ³¨&lt;/strong&gt;ï¼šé€šè¿‡äººç±»ä¸“å®¶æˆ–æ›´å¼ºæ¨¡å‹ï¼ˆå¦‚ GPT-4ï¼‰å¯¹æ¯ä¸€ä¸ª $S_i$ æ ‡æ³¨â€œæ­£ç¡®â€ã€â€œé”™è¯¯â€æˆ–â€œä¸­æ€§â€ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ¨¡å‹é¢„æµ‹&lt;/strong&gt;ï¼šPRM æ¨¡å‹å­¦ä¹ é¢„æµ‹æ¯ä¸€æ­¥çš„æ­£ç¡®æ¦‚ç‡ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;å¼ºåŒ–å­¦ä¹ ä¸­çš„åº”ç”¨&lt;/h3&gt;
&lt;p&gt;åœ¨ RL è¿‡ç¨‹ä¸­ï¼Œå¥–åŠ±å‡½æ•°ä¸å†æ˜¯æ ‡é‡ï¼Œè€Œæ˜¯ä¸€ä¸ªåºåˆ—ï¼š
$$ \mathcal{R} = {r(S_1), r(S_2), ..., r(S_n)} $$
è¿™å…è®¸ PPO æˆ– GRPO è¿›è¡Œ&lt;strong&gt;æ›´å¯†é›†çš„å¥–åŠ±ä¿¡å·åé¦ˆ&lt;/strong&gt;ï¼Œæ˜¾è‘—æå‡æ¨¡å‹å¤„ç†å¤æ‚æ¨ç†é—®é¢˜çš„é€»è¾‘ä¸¥å¯†æ€§ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;æ¡ˆä¾‹åˆ†æï¼šDeepSeek-R1 çš„å¼ºåŒ–å­¦ä¹ èŒƒå¼&lt;/h2&gt;
&lt;p&gt;DeepSeek-R1 å±•ç¤ºäº† GRPO ç»“åˆâ€œè§„åˆ™å¥–åŠ±â€çš„æƒŠäººæ•ˆæœï¼š&lt;/p&gt;
&lt;h3&gt;è§„åˆ™å¯¼å‘çš„ PRM&lt;/h3&gt;
&lt;p&gt;åœ¨æ¨ç†ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬æœ‰æ—¶ä¸éœ€è¦ç¥ç»ç½‘ç»œåšå¥–åŠ±æ¨¡å‹ï¼Œè€Œæ˜¯ä½¿ç”¨&lt;strong&gt;ç¡¬è§„åˆ™&lt;/strong&gt;ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;å‡†ç¡®æ€§å¥–åŠ± (Accuracy)&lt;/strong&gt;ï¼šç­”æ¡ˆå¿…é¡»å¯¹ï¼ˆä¾‹å¦‚æ•°å­¦é¢˜ï¼Œæå–æœ€åçš„ç»“æœæ¯”å¯¹ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ ¼å¼å¥–åŠ± (Format)&lt;/strong&gt;ï¼šæ€ç»´é“¾å¿…é¡»æ”¾åœ¨ &lt;code&gt;&amp;#x3C;think&gt;&lt;/code&gt; å’Œ &lt;code&gt;&amp;#x3C;/think&gt;&lt;/code&gt; æ ‡ç­¾ä¹‹é—´ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;æ¶Œç°èƒ½åŠ›&lt;/h3&gt;
&lt;p&gt;DeepSeek å‘ç°ï¼Œé€šè¿‡è¿™ç§ç®€å•çš„ GRPO + è§„åˆ™å¥–åŠ±ï¼Œæ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šå‡ºç°&lt;strong&gt;è‡ªæˆ‘åæ€ï¼ˆSelf-reflectionï¼‰&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å½“æ¨¡å‹å‘ç°ä¹‹å‰çš„æ¨å¯¼æœ‰é—®é¢˜æ—¶ï¼Œå®ƒä¼šè‡ªå‘åœ°å†™ä¸‹â€œWait, that&apos;s not right...â€ï¼ˆç­‰ä¸€ä¸‹ï¼Œè¿™ä¸å¯¹â€¦â€¦ï¼‰ï¼Œç„¶åé‡æ–°æ¨å¯¼ã€‚&lt;/li&gt;
&lt;li&gt;è¿™ç§èƒ½åŠ›å¹¶ä¸æ˜¯é€šè¿‡ SFTï¼ˆç›‘ç£å¾®è°ƒï¼‰åˆ»æ„æ•™å‡ºæ¥çš„ï¼Œè€Œæ˜¯é€šè¿‡ RL æœ€å¤§åŒ–å¥–åŠ±çš„è¿‡ç¨‹ä¸­&lt;strong&gt;è‡ªå‘è¿›åŒ–&lt;/strong&gt;å‡ºæ¥çš„ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;æ€»ç»“ä¸å¯¹æ¯”ï¼šPPO vs. GRPO&lt;/h2&gt;
&lt;p&gt;| ç»´åº¦ | PPO (æ ‡å‡†ç‰ˆ) | GRPO (ç»„ç›¸å¯¹ç‰ˆ) |
| :--- | :--- | :--- |
| &lt;strong&gt;æ˜¾å­˜æ¶ˆè€—&lt;/strong&gt; | é«˜ (éœ€è¦ Critic ç½‘ç»œ) | &lt;strong&gt;ä½ (ä¸¢å¼ƒ Critic ç½‘ç»œ)&lt;/strong&gt; |
| &lt;strong&gt;ä¼˜åŠ¿ä¼°è®¡&lt;/strong&gt; | ä¾èµ–å­¦å‡ºæ¥çš„ $V(s)$ | &lt;strong&gt;ä¾èµ–ç»„å†…æ ·æœ¬çš„ç»Ÿè®¡åˆ†å¸ƒ&lt;/strong&gt; |
| &lt;strong&gt;è®­ç»ƒç¨³å®šæ€§&lt;/strong&gt; | å®¹æ˜“å— Critic ç½‘ç»œæ³¢åŠ¨å½±å“ | æ›´ç¨³å®šï¼Œå› ä¸ºå¯¹æ¯”æ˜¯ç›¸å¯¹çš„ |
| &lt;strong&gt;ä¸»è¦åº”ç”¨&lt;/strong&gt; | æ—©æœŸ ChatGPT, Llama 3 å¯¹é½ | &lt;strong&gt;DeepSeek-R1/V3 æ¨ç†è®­ç»ƒ&lt;/strong&gt; |&lt;/p&gt;
&lt;h3&gt;å¯ç¤º&lt;/h3&gt;
&lt;p&gt;å¼ºåŒ–å­¦ä¹ åœ¨å¤§æ¨¡å‹æ—¶ä»£çš„è¿›åŒ–æ–¹å‘éå¸¸æ˜ç¡®ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;ç®—åŠ›ä¼˜åŒ–&lt;/strong&gt;ï¼šé€šè¿‡åƒ GRPO è¿™æ ·çš„ç®—æ³•å‡å°‘è®­ç»ƒå¼€é”€ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;é€»è¾‘ç›‘ç£&lt;/strong&gt;ï¼šé€šè¿‡ PRM æˆ– è§„åˆ™å¥–åŠ± å¼ºåŒ–æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ï¼Œè€Œä¸ä»…ä»…æ˜¯æœ€ç»ˆç­”æ¡ˆã€‚&lt;/li&gt;
&lt;/ol&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-5.32ifmhjene.webp"/><enclosure url="https://pic.hana0721.top/rl-note-5.32ifmhjene.webp"/></item><item><title>RLç¬”è®°ï¼ˆ28ï¼‰ï¼šå¤§è¯­è¨€æ¨¡å‹ä¸å¼ºåŒ–å­¦ä¹  (LLM + RLHF)</title><link>https://claudiakim6827362.github.io/blog/rl-note-28</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/rl-note-28</guid><description>å¤§æ¨¡å‹çš„æœ€åä¸€å—æ‹¼å›¾ï¼šè¯¦è§£åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹  (RLHF)ã€‚æ¶µç›–ä» SFT åˆ°å¥–åŠ±æ¨¡å‹ï¼Œä»¥åŠåˆ©ç”¨ PPO ç®—æ³•è¿›è¡Œç­–ç•¥å¯¹é½çš„å®Œæ•´æµç¨‹ã€‚</description><pubDate>Tue, 06 Jan 2026 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;å¼•è¨€ï¼ˆIntroductionï¼‰&lt;/h2&gt;
&lt;p&gt;åœ¨ä¹‹å‰çš„ç¬”è®°ä¸­ï¼Œæˆ‘ä»¬ä¸€ç›´åœ¨ç ”ç©¶å¦‚ä½•è®©æ™ºèƒ½ä½“åœ¨ç‰©ç†ç¯å¢ƒæˆ–åšå¼ˆç¯å¢ƒï¼ˆå¦‚ Atari, MuJoCo, SMACï¼‰ä¸­æ‹¿é«˜åˆ†ã€‚è€Œç°åœ¨ï¼Œæˆ‘ä»¬è¦å¤„ç†çš„å¯¹è±¡æ˜¯ &lt;strong&gt;å¤§è¯­è¨€æ¨¡å‹ (LLM)&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;å¤§æ¨¡å‹çš„è®­ç»ƒé€šå¸¸åˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µï¼š&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;é¢„è®­ç»ƒ (Pre-training)&lt;/strong&gt;ï¼šåœ¨æµ·é‡æ–‡æœ¬ä¸Šé€šè¿‡è‡ªç›‘ç£å­¦ä¹ â€œçŸ¥è¯†â€ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æŒ‡ä»¤å¾®è°ƒ (SFT, Supervised Fine-Tuning)&lt;/strong&gt;ï¼šåœ¨é«˜è´¨é‡é—®ç­”å¯¹ä¸Šå­¦ä¹ â€œå¯¹è¯æ ¼å¼â€ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;äººç±»å¯¹é½ (Alignment)&lt;/strong&gt;ï¼šé€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼Œè®©æ¨¡å‹ç”Ÿæˆç¬¦åˆäººç±»ä»·å€¼è§‚ï¼ˆæœ‰ç”¨ã€è¯šå®ã€æ— å®³ï¼‰çš„å†…å®¹ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;ä¸ºä»€ä¹ˆè¦ç”¨ RL è€Œä¸æ˜¯ SFTï¼Ÿ&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;éš¾ä»¥å†™å‡ºæ ‡å‡†ç­”æ¡ˆ&lt;/strong&gt;ï¼šå¯¹äºâ€œå†™ä¸€é¦–è¯—â€è¿™ç§å¼€æ”¾æ€§é—®é¢˜ï¼Œä¸å­˜åœ¨å”¯ä¸€çš„æ­£è§£ï¼ˆLabelï¼‰ã€‚äººç±»å¯ä»¥å¾ˆå®¹æ˜“åˆ¤æ–­è°å†™å¾—æ›´å¥½ï¼Œä½†å¾ˆéš¾å†™å‡ºå®Œç¾çš„ç¤ºèŒƒã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åˆ†å¸ƒåç§»é—®é¢˜&lt;/strong&gt;ï¼šSFT å±äºè¡Œä¸ºå…‹éš†ï¼ˆBCï¼‰ï¼Œå¦‚æœæ¨¡å‹åœ¨ç”Ÿæˆæ—¶äº§ç”Ÿäº†ä¸€ä¸ªæ²¡è§è¿‡çš„è¯ï¼Œè¯¯å·®ä¼šè¿…é€Ÿç´¯ç§¯ã€‚RL åˆ™è®©æ¨¡å‹åœ¨â€œè¯•é”™â€ä¸­å­¦ä¼šä»å„ç§å›å¤ä¸­æ‰¾åˆ°æœ€ä¼˜è·¯å¾„ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;æ ¸å¿ƒæ˜ å°„ï¼šå°† LLM å»ºæ¨¡ä¸º RL é—®é¢˜&lt;/h2&gt;
&lt;p&gt;è¦ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒ LLMï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦å°†æ–‡æœ¬ç”Ÿæˆè¿‡ç¨‹å¯¹åº”åˆ° MDP äº”å…ƒç»„ä¸­ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;çŠ¶æ€ (State, $s$)&lt;/strong&gt;ï¼šå½“å‰è¾“å…¥çš„æç¤ºè¯ï¼ˆPromptï¼‰ä»¥åŠæ¨¡å‹å·²ç»ç”Ÿæˆçš„ Token åºåˆ—ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åŠ¨ä½œ (Action, $a$)&lt;/strong&gt;ï¼šæ¨¡å‹é¢„æµ‹çš„ä¸‹ä¸€ä¸ª Tokenã€‚åŠ¨ä½œç©ºé—´å°±æ˜¯è¯è¡¨ï¼ˆVocab Sizeï¼Œé€šå¸¸ä¸º 3w ~ 10wï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç­–ç•¥ (Policy, $\pi$)&lt;/strong&gt;ï¼šå¤§è¯­è¨€æ¨¡å‹æœ¬èº«ï¼Œè¾“å…¥æç¤ºè¯ï¼Œè¾“å‡ºä¸‹ä¸€ä¸ªè¯çš„æ¦‚ç‡åˆ†å¸ƒã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å¥–åŠ± (Reward, $R$)&lt;/strong&gt;ï¼šåæ˜ ç”Ÿæˆçš„ä¸€æ•´æ®µè¯å¥½ä¸å¥½ã€‚è¿™ä¸ªå¥–åŠ±ä¸æ˜¯ç¯å¢ƒç»™çš„ï¼Œè€Œæ˜¯ç”± &lt;strong&gt;å¥–åŠ±æ¨¡å‹ (Reward Model)&lt;/strong&gt; è¯„åˆ†ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;RLHF çš„ä¸‰å¤§æ­¥éª¤&lt;/h2&gt;
&lt;p&gt;RLHF (Reinforcement Learning from Human Feedback) é€šå¸¸åŒ…å«ä»¥ä¸‹ç»å…¸æµç¨‹ï¼š&lt;/p&gt;
&lt;h3&gt;é˜¶æ®µä¸€ï¼šç›‘ç£å¾®è°ƒ (SFT)&lt;/h3&gt;
&lt;p&gt;åœ¨é¢„è®­ç»ƒæ¨¡å‹çš„åŸºç¡€ä¸Šï¼Œä½¿ç”¨äººç±»ç¼–å†™çš„é«˜è´¨é‡ (Prompt, Answer) æ•°æ®é›†è¿›è¡Œå¾®è°ƒã€‚æ­¤æ—¶æ¨¡å‹å­¦ä¼šäº†åŸºæœ¬çš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›ã€‚&lt;/p&gt;
&lt;h3&gt;é˜¶æ®µäºŒï¼šå¥–åŠ±æ¨¡å‹è®­ç»ƒ (Reward Modeling)&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;ç»™åŒä¸€ä¸ª Promptï¼Œè®© SFT åçš„æ¨¡å‹ç”Ÿæˆå¤šä¸ªä¸åŒçš„å›å¤ ${y^1, y^2, y^3, y^4}$ã€‚&lt;/li&gt;
&lt;li&gt;è®©äººç±»å¯¹è¿™äº›å›å¤è¿›è¡Œæ’åºï¼ˆä¾‹å¦‚ $y^2 &gt; y^1 &gt; y^4 &gt; y^3$ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;è®­ç»ƒä¸€ä¸ªæ ‡é‡å¥–åŠ±æ¨¡å‹ $r_\theta(x, y)$ï¼Œä½¿å…¶è¾“å‡ºçš„åˆ†æ•°ç¬¦åˆäººç±»çš„æ’åºè§„å¾‹ã€‚æŸå¤±å‡½æ•°é€šå¸¸é‡‡ç”¨ &lt;strong&gt;Pairwise Ranking Loss&lt;/strong&gt;ï¼š
$$ L(\theta) = - \mathbb{E}&lt;em&gt;{(x, y_w, y_l) \sim \mathcal{D}} \left[ \log \sigma \left( r&lt;/em&gt;\theta(x, y_w) - r_\theta(x, y_l) \right) \right] $$
å…¶ä¸­ $y_w$ æ˜¯èƒœå‡ºçš„å›å¤ï¼Œ$y_l$ æ˜¯å¤±è´¥çš„å›å¤ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;é˜¶æ®µä¸‰ï¼šå¼ºåŒ–å­¦ä¹ å¯¹é½ (PPO)&lt;/h3&gt;
&lt;p&gt;åˆ©ç”¨å¥–åŠ±æ¨¡å‹ç»™å‡ºçš„åˆ†æ•°ï¼Œé€šè¿‡ PPO ç®—æ³•è°ƒæ•´ LLM çš„å‚æ•°ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;RLHF ä¸­çš„ PPO ç›®æ ‡å‡½æ•°&lt;/h2&gt;
&lt;p&gt;åœ¨å¯¹é½é˜¶æ®µï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯æœ€å¤§åŒ–å¥–åŠ±æ¨¡å‹çš„åˆ†æ•°ã€‚ä½†å¦‚æœåªè€ƒè™‘å¥–åŠ±ï¼Œæ¨¡å‹å¯èƒ½ä¼šå­¦ä¼šâ€œé’»ç©ºå­â€ï¼ˆReward Hackingï¼‰ï¼Œç”Ÿæˆä¸€äº›äººç±»çœ‹ä¸æ‡‚ä½†å¥–åŠ±æ¨¡å‹ç»™é«˜åˆ†çš„ä¹±ç ã€‚&lt;/p&gt;
&lt;p&gt;å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦çº¦æŸæ¨¡å‹ï¼Œä½¿å…¶ä¸è¦åç¦»åŸå§‹æ¨¡å‹å¤ªè¿œã€‚ç›®æ ‡å‡½æ•°å®šä¹‰ä¸ºï¼š&lt;/p&gt;
&lt;p&gt;$$
J(\phi) = \mathbb{E}&lt;em&gt;{x \sim \mathcal{D}, y \sim \pi&lt;/em&gt;\phi(y|x)} \left[ r_\theta(x, y) - \beta \log \left( \frac{\pi_\phi(y|x)}{\pi_{\text{ref}}(y|x)} \right) \right]
$$&lt;/p&gt;
&lt;h3&gt;å…¬å¼æ‹†è§£ï¼š&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;$r_\theta(x, y)$&lt;/strong&gt;ï¼šå¥–åŠ±æ¨¡å‹å¯¹ç”Ÿæˆçš„å®Œæ•´å¥å­ $y$ ç»™å‡ºçš„é¢„æµ‹åˆ†æ•°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;$\log \left( \frac{\pi_\phi(y|x)}{\pi_{\text{ref}}(y|x)} \right)$&lt;/strong&gt;ï¼šè¿™æ˜¯æ–°ç­–ç•¥ $\pi_\phi$ ä¸å‚è€ƒæ¨¡å‹ï¼ˆé€šå¸¸æ˜¯ SFT åçš„æ¨¡å‹ï¼‰$\pi_{\text{ref}}$ ä¹‹é—´çš„ &lt;strong&gt;KL æ•£åº¦&lt;/strong&gt;ï¼ˆå‡†ç¡®è¯´æ˜¯ KL æƒ©ç½šé¡¹ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;$\beta$&lt;/strong&gt;ï¼šKL æƒ©ç½šç³»æ•°ã€‚$\beta$ è¶Šå¤§ï¼Œæ¨¡å‹è¶Šä¿å®ˆï¼Œè¶ŠåƒåŸå§‹æ¨¡å‹ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;ğŸ’¡ ç›´è§‰ç†è§£&lt;/strong&gt;ï¼š
è¿™ä¸€é¡¹çš„ä½œç”¨æ˜¯ï¼š&lt;strong&gt;â€œä½ å¯ä»¥å°½é‡è®¨å¥½äººç±»ï¼Œä½†ä¸èƒ½å¿˜äº†æ€ä¹ˆè¯´è¯ã€‚â€&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2&gt;LLM-PPO çš„è®­ç»ƒæ¶æ„&lt;/h2&gt;
&lt;p&gt;åœ¨è¿™ä¸€é˜¶æ®µï¼Œæ˜¾å­˜ä¸­é€šå¸¸éœ€è¦åŒæ—¶åŠ è½½å››ä¸ªæ¨¡å‹ï¼ˆé€šå¸¸é‡‡ç”¨å‚æ•°å…±äº«æˆ–å±‚å†»ç»“æ¥ä¼˜åŒ–ï¼‰ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Actor (Policy Network)&lt;/strong&gt;ï¼šå½“å‰æ­£åœ¨è®­ç»ƒçš„ LLMï¼Œå‚æ•°ä¸º $\phi$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reference Model&lt;/strong&gt;ï¼šå†»ç»“çš„ SFT æ¨¡å‹ï¼Œç”¨äºè®¡ç®— KL æƒ©ç½šã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Critic (Value Network)&lt;/strong&gt;ï¼šä¸€ä¸ªé¢å¤–çš„å¤´éƒ¨ï¼Œè¾“å…¥ Token åºåˆ—ï¼Œé¢„æµ‹ä»å½“å‰ä½ç½®å¼€å§‹èƒ½è·å¾—çš„æœªæ¥æ€»å¥–åŠ±ï¼ˆå³ $V(s)$ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reward Model&lt;/strong&gt;ï¼šå†»ç»“çš„è¯„åˆ†æ¨¡å‹ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;è®­ç»ƒå¾ªç¯ï¼š&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;é‡‡æ · (Rollout)&lt;/strong&gt;ï¼šè¾“å…¥ Prompt $x$ï¼ŒActor ç”Ÿæˆå›å¤ $y$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è¯„åˆ† (Evaluation)&lt;/strong&gt;ï¼šReward Model å¯¹ $(x, y)$ æ‰“åˆ†ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è®¡ç®—ä¼˜åŠ¿ (Advantage)&lt;/strong&gt;ï¼š
åˆ©ç”¨åºåˆ—ä¸­çš„æ¯ä¸€ä¸ª Token çš„ TD Error æ¥è®¡ç®—ä¼˜åŠ¿ $\hat{A}$ã€‚
æ³¨æ„ï¼šåœ¨ LLM ä¸­ï¼Œå¥–åŠ±é€šå¸¸æ˜¯åœ¨&lt;strong&gt;æœ€åä¸€ä¸ª Token&lt;/strong&gt; ç»™å‡ºçš„ï¼Œè€Œå‰é¢çš„ Token å¥–åŠ±ä¸º 0ï¼ˆé™¤äº† KL æƒ©ç½šï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ›´æ–° (Update)&lt;/strong&gt;ï¼š
åˆ©ç”¨ PPO çš„ Clip æŸå¤±å‡½æ•°æ›´æ–° Actorï¼Œåˆ©ç”¨ MSE æŸå¤±æ›´æ–° Criticã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2&gt;è¿›é˜¶ï¼šDPO (Direct Preference Optimization)&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;è®ºæ–‡&lt;/strong&gt;ï¼š&lt;a href=&quot;https://arxiv.org/abs/2305.18290&quot;&gt;Direct Preference Optimization: Your Language Model is Secretly a Reward Model&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;PPO è™½ç„¶ç»å…¸ï¼Œä½†éå¸¸å¤æ‚ï¼ˆéœ€è¦ 4 ä¸ªæ¨¡å‹ï¼Œæ˜¾å­˜å¼€é”€å·¨å¤§ï¼Œè®­ç»ƒæä¸ç¨³å®šï¼‰ã€‚
2023 å¹´æå‡ºçš„ &lt;strong&gt;DPO&lt;/strong&gt; å½»åº•ç®€åŒ–äº†è¿™ä¸ªè¿‡ç¨‹ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DPO çš„æ ¸å¿ƒå‘ç°&lt;/strong&gt;ï¼š
æˆ‘ä»¬å¯ä»¥é€šè¿‡æ•°å­¦å˜æ¢ï¼Œç›´æ¥å°†å¥–åŠ±å‡½æ•° $r$ è¡¨è¾¾ä¸ºæœ€ä¼˜ç­–ç•¥ $\pi^*$ çš„å‡½æ•°ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬&lt;strong&gt;ä¸éœ€è¦è®­ç»ƒå¥–åŠ±æ¨¡å‹&lt;/strong&gt;ï¼Œä¹Ÿä¸éœ€è¦å¼ºåŒ–å­¦ä¹ ï¼Œç›´æ¥åœ¨åå¥½æ•°æ® $(y_w, y_l)$ ä¸Šè¿›è¡Œ&lt;strong&gt;ç›‘ç£å¼å­¦ä¹ &lt;/strong&gt;å³å¯ã€‚&lt;/p&gt;
&lt;p&gt;DPO æŸå¤±å‡½æ•°ï¼š
$$
L_{DPO}(\pi_\phi; \pi_{\text{ref}}) = - \mathbb{E}&lt;em&gt;{(x, y_w, y_l) \sim \mathcal{D}} \left[ \log \sigma \left( \beta \log \frac{\pi&lt;/em&gt;\phi(y_w|x)}{\pi_{\text{ref}}(y_w|x)} - \beta \log \frac{\pi_\phi(y_l|x)}{\pi_{\text{ref}}(y_l|x)} \right) \right]
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç›´è§‰&lt;/strong&gt;ï¼šå¦‚æœæ¨¡å‹åœ¨å¥½å›å¤ $y_w$ ä¸Šçš„æ¦‚ç‡æå‡æ¯”åœ¨åå›å¤ $y_l$ ä¸Šå¿«ï¼ŒLoss å°±å˜å°ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;æ€»ç»“&lt;/h2&gt;
&lt;p&gt;LLM + RL çš„ç»“åˆæ ‡å¿—ç€å¼ºåŒ–å­¦ä¹ ä»â€œè§£å†³ç©å…·é—®é¢˜â€èµ°å‘äº†â€œèµ‹èƒ½é€šç”¨äººå·¥æ™ºèƒ½â€ã€‚&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;RLHF&lt;/strong&gt; å»ºç«‹äº†æ¨¡å‹è¡Œä¸ºä¸äººç±»åå¥½çš„æ¡¥æ¢ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PPO&lt;/strong&gt; æä¾›äº†ç¨³å®šçš„ä¼˜åŒ–æ¡†æ¶ï¼Œé€šè¿‡ KL æƒ©ç½šä¿è¯äº†è¯­è¨€çš„è‡ªç„¶æ€§ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DPO&lt;/strong&gt; ç­‰åç»­ç®—æ³•è¿›ä¸€æ­¥é™ä½äº†å¯¹é½çš„é—¨æ§›ï¼Œä½¿å¾—ä¸­å°å‹å›¢é˜Ÿä¹Ÿèƒ½è¿›è¡Œæ¨¡å‹å¯¹é½ã€‚&lt;/li&gt;
&lt;/ol&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-5.32ifmhjene.webp"/><enclosure url="https://pic.hana0721.top/rl-note-5.32ifmhjene.webp"/></item><item><title>Paper Reading: Embodied AI 2</title><link>https://claudiakim6827362.github.io/blog/paper-reading-eba2</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/paper-reading-eba2</guid><description>ä»é›¶å¼€å§‹çš„Embodied AIç ”ç©¶ç”Ÿæ´»ã€‚</description><pubDate>Fri, 26 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;import { ArxivRating, RatingCriteria } from &apos;@/components/advanced&apos;&lt;/p&gt;
&lt;p&gt;import { ManualTOC } from &apos;@/components/advanced&apos;&lt;/p&gt;
&lt;p&gt;&amp;#x3C;ManualTOC
title=&apos;&apos;
categories={[
{
title: &apos;Embodied AI Paper Reading&apos;,
items: [
{
title: &apos;Batch 1&apos;,
href: &apos;/blog/paper-reading-eba1&apos;,
order: &apos;1&apos;
},
{
title: &apos;Batch 2&apos;,
href: &apos;/blog/paper-reading-eba2&apos;,
order: &apos;2&apos;
},
{
title: &apos;Batch 3&apos;,
href: &apos;/blog/paper-reading-eba3&apos;,
order: &apos;3&apos;
},
{
title: &apos;Batch 4&apos;,
href: &apos;/blog/paper-reading-eba4&apos;,
order: &apos;4&apos;
}
]
}
]}
/&gt;&lt;/p&gt;
&lt;h2&gt;å‰è¨€&lt;/h2&gt;
&lt;p&gt;RLèœé¸¡å¼€å§‹è¿›å†›Embodied AIï¼Œæ…¢æ…¢ç§¯ç´¯ï¼Œæå‡è‡ªå·±ã€‚&lt;/p&gt;
&lt;h2&gt;LLARVA&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://pic.hana0721.top/LLARVA.8z70f5s0j6.webp&quot; alt=&quot;&quot;&gt;
LLARVA æ˜¯ä¸€ç§ OpenVLA-like çš„ VLAï¼Œä½¿ç”¨ Instruction Tuning è¿›è¡Œå¾®è°ƒï¼Œå¹¶é€šè¿‡è¾“å‡º 2D Visual Trace å»å¼•å¯¼ Action ç”Ÿæˆã€‚&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://pic.hana0721.top/LLARVA-prompt.7axnhz1uu9.webp&quot; alt=&quot;&quot;&gt;
LLARVA çš„è¾“å…¥æŒ‡ä»¤è¢«è§„èŒƒåŒ–ä¸º Promptï¼Œè¯¦ç»†è§å›¾ã€‚
LLM çš„ä¸»å¹²ä¸º LLaMA2 7Bï¼Œå¹¶ä½¿ç”¨ LoRA è¿›è¡Œå¾®è°ƒã€‚
å…ˆé¢„æµ‹ 2D Visual Trace å†ç”Ÿæˆ Action Chunkï¼Œæœ¬è´¨ä¸Šæ˜¯åŸºäº CoT çš„æ€æƒ³ã€‚&lt;/p&gt;
&lt;h2&gt;ATM&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://pic.hana0721.top/ATM.83aizqrop9.webp&quot; alt=&quot;&quot;&gt;
ATM çš„äº®ç‚¹åœ¨äºä»…å¯ä»¥ä½¿ç”¨ Action-free çš„æ•°æ®å»è®­ç»ƒæœºå™¨äººæ“ä½œç­–ç•¥ã€‚
ATM æ˜¯ä¸€ç§ Pipeline æ–¹æ³•ï¼Œåˆ†ä¸ºä»»æ„ç‚¹è½¨è¿¹å»ºæ¨¡ä¸è½¨è¿¹å¼•å¯¼ç­–ç•¥å­¦ä¹ ä¸¤ä¸ªéƒ¨åˆ†ã€‚
åœ¨ä»»æ„ç‚¹è½¨è¿¹å»ºæ¨¡éƒ¨åˆ†ï¼ŒATM åˆ©ç”¨äº†å¤§é‡ Label-free çš„è§†é¢‘è®­ç»ƒäº†ä¸€ä¸ª Points-Trackerï¼Œè¾“å…¥æ˜¯å½“å‰è§‚å¯Ÿ Obsã€ä»»åŠ¡ Instruction ä»¥åŠåˆå§‹ Pointsï¼Œè¾“å‡ºæ˜¯æœªæ¥çš„ Points-Trajectoryã€‚
åœ¨è½¨è¿¹å¼•å¯¼ç­–ç•¥å­¦ä¹ éƒ¨åˆ†ï¼Œç­–ç•¥ç½‘ç»œä»¥ä¸Šä¸ªæ­¥éª¤é¢„æµ‹çš„ Points-Trajectory ä»¥åŠå½“å‰ Obs ä¸ºè¾“å…¥ï¼Œè¾“å‡ºæœºå™¨äººçš„ Actionã€‚&lt;/p&gt;
&lt;p&gt;ä»»æ„ç‚¹è½¨è¿¹å»ºæ¨¡ï¼š
åœ¨æ•°æ®å¤„ç†éƒ¨åˆ†ï¼ŒATM ä½¿ç”¨äº†ç¦»çº¿çš„ Points-Tracker æ¨¡å‹å»å¾—å‡ºçš„ Labelã€‚
åŒæ—¶ï¼Œè¿‡æ»¤æ‰äº†å¤§éƒ¨åˆ†é™æ­¢çš„ Pointsï¼Œåªä¿ç•™äº† 32 ä¸ªé«˜é¢‘æ´»åŠ¨çš„ Pointsã€‚
å¯¹äºå½“å‰ Obsï¼Œä½¿ç”¨ ViT å°†å›¾åƒåˆ‡åˆ†ä¸º Patchesï¼Œå¹¶éšæœº Mask æ‰ 50% çš„ Patchesï¼Œå¾—å‡º Image Tokenã€‚
å¯¹äºä»»åŠ¡ Instructionï¼Œä½¿ç”¨ BERT è¿›è¡Œä¿¡æ¯æå– Language Tokenã€‚
å¯¹äºåˆå§‹ Pointsï¼Œåœ¨æ–‡ä¸­æ˜¯æœ‰32ä¸ªï¼Œç¼–ç ä¸º Track Tokenã€‚
ä»¥ Obs ä»¥åŠ Instruction ä¸º Base çš„ Points-Tracker è¢«å®šä¹‰ä¸ºä¸€ä¸ª Transformerï¼Œè¾“å…¥ä¸º Image Tokenã€Language Token ä»¥åŠ Track Tokenï¼Œè¾“å‡ºä¸ºæœªæ¥çš„ Points-Trajectoryã€‚
æŒ‰ç…§é¢˜ä¸»çš„ç†è§£ï¼Œè¾“å‡ºçš„ Points-Trajectory å…¶å®å°±æ˜¯ä»»åŠ¡å¯¼å‘çš„ Vision-Language Fusionã€‚&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://pic.hana0721.top/ATM-policy.9kgo1hvysf.webp&quot; alt=&quot;&quot;&gt;
è½¨è¿¹å¼•å¯¼ç­–ç•¥å­¦ä¹ ï¼š
é¦–å…ˆï¼Œä½¿ç”¨äº† BERT-like çš„ Transformer å¯¹ Image Token ä»¥åŠ Track Token è¿›è¡Œ Fusionï¼Œå¾—å‡ºç‰¹å¾ [CLS]ã€‚
ç„¶åï¼Œç­–ç•¥ç½‘ç»œè®¾å®šä¸º MLPï¼Œä»¥ [CLS] ä»¥åŠ Track Token ä¸ºè¾“å…¥ï¼Œè¾“å‡ºæœºå™¨äººçš„ Actionã€‚
åœ¨ç­–ç•¥å­¦ä¹ çš„è¿‡ç¨‹ä¸­ï¼Œå¹¶æ²¡æœ‰å¼•å…¥ Instruction çš„ä¿¡æ¯ï¼Œå› ä¸ºåœ¨è½¨è¿¹å»ºæ¨¡é˜¶æ®µå·²ç»å¼•å…¥äº†ã€‚
åŒæ—¶ï¼Œå¯¹ Track Token è¿›è¡Œäº†ä¸¤æ¬¡ Fusionï¼Œè¿™æ ·ä¼šæœ‰æ›´å¥½çš„æ•ˆæœï¼Œè¯¦ç»†è§åŸæ–‡ã€‚&lt;/p&gt;
&lt;h2&gt;Track2Act&lt;/h2&gt;
&lt;p&gt;Track2Act æœ¬è´¨ä¸Šå’Œ ATM æ˜¯ä¸€æ ·çš„ï¼Œéƒ½æ˜¯ä»¥ Points-Trajectory å»å¼•å¯¼åŠ¨ä½œçš„ç”Ÿæˆã€‚
Track2Act ä¸»è¦åˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µï¼šPoints-Trajectory é¢„æµ‹ã€Open-loop åŠ¨ä½œæ±‚è§£ä»¥åŠ Residual Policy é—­ç¯ä¿®æ­£ã€‚&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://pic.hana0721.top/Track2Act-pt.13m9i5xvjf.webp&quot; alt=&quot;&quot;&gt;
åœ¨ Points-Trajectory é¢„æµ‹é˜¶æ®µï¼ŒTrack2Act ä½¿ç”¨äº† DiT ç”Ÿæˆæ¨¡å‹ã€‚
DiT çš„ Condition è¢«è®¾ç½®ä¸ºåˆå§‹å›¾åƒ $I_0$ ä»¥åŠç›®æ ‡å›¾åƒ $\mathcal{G}$ çš„è¡¨å¾ï¼Œç»™å®šéšæœºé‡‡æ ·çš„æŸ¥è¯¢ç‚¹é›† $P_0$ï¼Œç”Ÿæˆ Points-Trajectoryã€‚&lt;/p&gt;
&lt;p&gt;åœ¨ Open-loop åŠ¨ä½œæ±‚è§£é˜¶æ®µï¼ŒTrack2Act ä½¿ç”¨äº†ä¸€ä¸ªç¡®å®šæ€§çš„ç®—æ³•è¿›è¡Œåˆšæ€§åŠ¨ä½œçš„æ±‚è§£ï¼Œä¸æ¶‰åŠç¥ç»ç½‘ç»œè®­ç»ƒã€‚
è¿™ä¸ªç®—æ³•çš„è¾“å…¥æ˜¯ Points-Trajectoryï¼Œè¾“å‡ºä¸€ç³»åˆ—çš„åˆšæ€§å˜æ¢ $[\textbf{T}&lt;em&gt;t]&lt;/em&gt;{t=1}^H$ã€‚
å…·ä½“æ±‚è§£ç®—æ³•è§åŸæ–‡ï¼Œè¿™é‡Œä¸è¯¦ç»†å±•å¼€ã€‚
æœ€åï¼ŒåŸºäºåˆšæ€§å˜æ¢ï¼Œå¯ä»¥æ±‚è§£å‡ºæœºå™¨äººçš„ Open-loop åŠ¨ä½œåºåˆ— $[\bar{a}&lt;em&gt;t]&lt;/em&gt;{t=1}^H$ã€‚&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://pic.hana0721.top/Track2Act-rp.4n877z0ttz.webp&quot; alt=&quot;&quot;&gt;
åœ¨ Residual Policy é—­ç¯ä¿®æ­£é˜¶æ®µï¼ŒTrack2Act ä½¿ç”¨ä¸€ä¸ª Residual Policy å»ä¿®æ­£ Open-loop åŠ¨ä½œã€‚å…¶å®å°±æ˜¯ä½¿ç”¨ä¸€ä¸ª Transformer-Encoder å»é¢„æµ‹è¯¯å·®ï¼Œæœ€ååŠ åœ¨ä¸€èµ·ã€‚&lt;/p&gt;
&lt;p&gt;æœ€åç®€å•ç‘èä¸€ä¸‹ï¼Œå…¶å®åšä¸»è§‰å¾—åé¢ä¸¤ä¸ªé˜¶æ®µå®Œæˆå¯ä»¥ä½¿ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œè¡¨å¾ï¼Œæœ‰ç‚¹å¤šä½™ï¼Œè™½ç„¶æ®‹å·®ä¿®æ­£åŠ¨ä½œè¿™ä¸ªæ€æƒ³æ˜¯å¥½çš„ã€‚&lt;/p&gt;
&lt;h2&gt;ECoT&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://pic.hana0721.top/ECoT.73ufntxfff.webp&quot; alt=&quot;&quot;&gt;
ECoT è¿™ç¯‡å·¥ä½œæŒ‡å‡º LLM é‚£è¾¹çš„ CoT æ˜¯æ— æ³•ç›´æ¥è¿ç§»åˆ° Embodied ä»»åŠ¡ç¯å¢ƒä¸­çš„ã€‚
è‹¥åªæ˜¯ç®€å•çš„è¯­ä¹‰æ¨ç†ï¼Œé‚£ä¹ˆå°±ä¼šå‡ºç°å¤§é‡ä¸ç¬¦åˆå®é™…ç‰©ç†ç¯å¢ƒçš„å¹»è§‰ã€‚
å› æ­¤ï¼ŒECoT åœ¨ CoT çš„åŸºç¡€ä¸Šæ·»åŠ äº†æ™ºèƒ½ä½“å¯¹ç¯å¢ƒçš„æ„ŸçŸ¥ï¼Œä»è€Œä½¿å¾— CoT å…·æœ‰ Embodied æ€§è´¨ã€‚
ECoT çš„å…·ä½“è®¾ç½®è§ä¸Šå›¾ï¼Œå’Œ CoT ç±»ä¼¼ï¼Œåªæ˜¯åŠ å…¥äº† Embodied çš„æ„ŸçŸ¥ã€‚
ECoT ä½¿ç”¨çš„æ¨¡å‹åŸºåº§æ˜¯ OpenVLAï¼Œä½¿ç”¨ ECoT åæ•ˆæœå¾—åˆ°äº†å¾ˆå¥½çš„æ”¹å–„ã€‚&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://pic.hana0721.top/ECoT-data.1vz50u4k0o.webp&quot; alt=&quot;&quot;&gt;
ECoT è¿˜æå‡ºäº†ä¸€å¥—ä½¿ç”¨æœºå™¨äººæ•°æ®äº§ç”Ÿ CoT è®­ç»ƒæ•°æ®çš„ Pipelineã€‚
å…·ä½“å°±ä¸å¤šè¯´äº†ï¼Œå›¾é‡Œé¢è¯´çš„å¾ˆæ¸…æ¥šã€‚&lt;/p&gt;
&lt;p&gt;è¿™ç§æ¨ç†è¿‡ç¨‹æ˜¯æ˜¾å¼çš„ï¼Œå…·æœ‰ä¸€å®šçš„è§£é‡Šæ€§ï¼Œç¼ºç‚¹å°±æ˜¯è¿™æ ·ä¼šé™ä½æ¨ç†çš„é€Ÿåº¦ï¼Œæ–‡ä¸­ä¹Ÿç»™äº†ä¸€äº›è§£å†³æ–¹æ¡ˆã€‚&lt;/p&gt;
&lt;h2&gt;VoxPoser&lt;/h2&gt;
&lt;p&gt;VoxPoser æ˜¯ä¸€ç§ Code for Robotic çš„æ–¹æ³•ã€‚
ç®€å•çš„æ¥è¯´ï¼ŒVoxPoser ä½¿ç”¨ LLM å»ç”Ÿæˆ Python ä»£ç ï¼Œè¿™é‡Œçš„ä»£ç ä¼šè°ƒç”¨ VLM çš„ API ç”Ÿæˆ 3D Value Mapï¼Œç„¶åè¿›è¡Œ MPCã€‚&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://pic.hana0721.top/VoxPoser.1vz50wovrd.webp&quot; alt=&quot;&quot;&gt;
é¦–å…ˆï¼ŒVoxPoser ä¼šå‘Šè¯‰ LLM ä»»åŠ¡çš„æ–‡æœ¬æè¿°ä»¥åŠä¸€äº› VLM å…·æœ‰çš„ APIå‡½æ•°ï¼Œè®©å®ƒå»äº§ç”Ÿèƒ½å¤ŸåŸºäº RGB-D å›¾åƒè®¡ç®— 3D Value Map çš„ Python ä»£ç ã€‚
ç„¶åï¼Œä½¿ç”¨ Python æ‰§è¡Œå™¨å»æ‰§è¡Œä»£ç ï¼Œè¿‡ç¨‹ä¸­ä¼šè°ƒç”¨ VLM çš„ APIï¼Œå…¶å®å°±æ˜¯ OWL-ViT è·å–è¾¹æ¡†è¿˜æœ‰ SAM è·å– Maskï¼Œç„¶åé‡å»º 3D Points Cloudï¼Œè®¡ç®—å¾—å‡º 3D Value Mapã€‚
æœ€åï¼Œæœ‰äº† 3D Value Map ä½œä¸ºä»·å€¼å¼•å¯¼ï¼Œå°±å¯ä»¥ä½¿ç”¨ MPC çš„æ–¹æ³•åˆæˆè½¨è¿¹ï¼Œè¿›è¡Œè§„åˆ’ã€‚
åœ¨æ–‡ä¸­ï¼Œæä¾›äº†åœ¨çº¿è®­ç»ƒ MPC ä»¥åŠ å¯å‘å¼ MPC ä¸¤ç§æ–¹å¼ï¼Œå‰è€…éœ€è¦ç¯å¢ƒäº¤äº’ï¼Œåè€…åˆ™æ— éœ€è®­ç»ƒã€‚&lt;/p&gt;
&lt;h2&gt;PIVOT&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://pic.hana0721.top/PIVOT-example.2rvmgdu2g2.webp&quot; alt=&quot;&quot;&gt;
PIVOT çš„æ€æƒ³å¾ˆç®€å•ï¼Œå°±æ˜¯æŠŠæœºå™¨äººçš„ä½çº§ Action æŠ•å½±åˆ°å›¾åƒä¸­ï¼Œå¹¶é‡‡ç”¨ VQA çš„å½¢å¼è®© VLM å»é€‰æ‹© Action é›†åˆã€‚&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://pic.hana0721.top/PIVOT.szfq1osvp.webp&quot; alt=&quot;&quot;&gt;
PIVOT ç»´æŠ¤ä¸€ä¸ª Action çš„åˆ†å¸ƒï¼Œåˆå§‹åŒ–ä¸ºå‡åŒ€åˆ†å¸ƒï¼Œæœ‰ç‚¹åƒ MPC ä¸­çš„äº¤å‰ç†µæ–¹æ³•ã€‚
PIVOT ä½¿ç”¨çš„æ˜¯ Zero-Shot çš„è¿­ä»£ç®—æ³•ï¼Œä¸æ–­å»ä¼˜åŒ– Action çš„åˆ†å¸ƒï¼Œç›´åˆ°æ”¶æ•›ã€‚
é¦–å…ˆï¼ŒPIVOT ä»åˆ†å¸ƒä¸­é‡‡æ ·ä¸€ç³»åˆ—çš„ Actionï¼Œç„¶åå°† Action æŠ•å½±åˆ° 2D å›¾åƒä¸Šï¼Œè¯¦ç»†è§å›¾ï¼Œæ¯ä¸ª Action éƒ½å¯¹åº”äº†åºå·ã€‚
ç„¶åï¼Œç»™å®šä»»åŠ¡æè¿°æ–‡æœ¬ä»¥åŠ 2D å›¾åƒï¼Œç¼–å†™åˆé€‚çš„ Prompt è®© VLM å»é€‰æ‹©æœ€ä¼˜ Action é›†åˆã€‚
æ¥ç€ï¼Œæ ¹æ®é€‰å–çš„ Action é›†åˆå»ç»´æŠ¤ Action åˆ†å¸ƒï¼Œç±»ä¼¼äº MPC ä¸­çš„äº¤å‰ç†µæ–¹æ³•ã€‚
ç»è¿‡ä¸æ–­è¿­ä»£ï¼Œå¯ä»¥å¾—å‡ºè¾ƒå¥½çš„ Action å€™é€‰é›†åˆã€‚&lt;/p&gt;
&lt;p&gt;PIVOT çš„æ€è·¯å¾ˆæœ‰å¯å‘æ€§ï¼Œä½†ç¼ºé™·ä¹Ÿæ˜¯æ˜æ˜¾çš„ã€‚æ¯”å¦‚ï¼Œ3D æ­§ä¹‰ç†è§£ã€ç»†ç²’åº¦æ§åˆ¶ä»¥åŠ VLM çš„å¹»è§‰é—®é¢˜ã€‚&lt;/p&gt;
&lt;h2&gt;Code As Policies&lt;/h2&gt;
&lt;p&gt;CaP æ ¸å¿ƒæ€æƒ³ä¸æ˜¯è®­ç»ƒç­–ç•¥ç½‘ç»œï¼Œè€Œæ˜¯é€šè¿‡ Prompt è®© LLM å»è°ƒç”¨æœºå™¨äºº APIï¼Œä»è€Œå®Œæˆä»»åŠ¡ã€‚&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://pic.hana0721.top/CaP.77e1n0y43g.webp&quot; alt=&quot;&quot;&gt;
é¦–å…ˆï¼ŒCaP è¿›è¡Œäº† LMP å½¢å¼åŒ–ï¼Œå…¶å®å°±æ˜¯è®©ç­–ç•¥åˆ©ç”¨ Python è¯­è¨€çš„ä¸€äº›ç‰¹æ€§ã€‚
ç„¶åï¼Œä¸ºäº†å¤„ç†å¤æ‚ä»»åŠ¡ä»£ç è¿‡é•¿æˆ–è€…é€»è¾‘å¤æ‚çš„é—®é¢˜ï¼ŒCaP ä½¿ç”¨äº†å±‚æ¬¡åŒ–ä»£ç ç”Ÿæˆçš„æ–¹æ³•ï¼Œå…¶å®å°±æ˜¯è‡ªä¸‹è€Œä¸Šåˆ†è€Œæ²»ä¹‹çš„æ€æƒ³ã€‚
æœ€åï¼ŒCaP è¿›è¡Œäº†æ„ŸçŸ¥ä¸åŠ¨ä½œçš„å¯¹é½ã€‚
LLM ä¼šåŸºäº Prompt å¾—å‡ºä¸€äº›é¢„å®šä¹‰çš„æ„ŸçŸ¥ API ä»¥åŠ æ§åˆ¶ APIã€‚
LLM å¯ä»¥é€šè¿‡æ„ŸçŸ¥ API å»è·å–è§†è§‰ä¿¡æ¯çš„å˜é‡ã€‚
LLM ä¼šè®¡ç®—æ§åˆ¶ API çš„å‚æ•°ï¼Œå¹¶æ‰§è¡Œã€‚&lt;/p&gt;
&lt;p&gt;CaP çš„å·¥ä½œè™½ç„¶ç®€å•ï¼Œä½†å®ƒå°†é«˜å±‚è§„åˆ’å’Œåº•å±‚æ‰§è¡Œè”ç³»åœ¨äº†ä¸€èµ·ã€‚&lt;/p&gt;
&lt;h2&gt;RoboPoint&lt;/h2&gt;
&lt;p&gt;RoboPoint é€šè¿‡æ„å»ºä¸€å¥—ç¨‹åºåŒ–åˆæˆæ•°æ®ç”Ÿæˆæµæ°´çº¿ï¼Œå°†é€šç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰å¾®è°ƒä¸ºèƒ½æ ¹æ®è‡ªç„¶è¯­è¨€æŒ‡ä»¤é¢„æµ‹ç²¾ç¡® 2D ç©ºé—´æ“ä½œç‚¹ï¼ˆSpatial Affordanceï¼‰çš„æ¨¡å‹ï¼Œä»è€Œå®ç°äº†æ— éœ€çœŸå®ä¸–ç•Œæ•°æ®è®­ç»ƒçš„æœºå™¨äººé›¶æ ·æœ¬ï¼ˆZero-shotï¼‰æ“æ§ä¸å¯¼èˆªã€‚&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://pic.hana0721.top/RoboPoint.lw7w2yur8.webp&quot; alt=&quot;&quot;&gt;
åœ¨æ•°æ®ç”Ÿæˆé˜¶æ®µï¼ŒRoboPoint åˆ©ç”¨ç¨‹åºåŒ–ç”ŸæˆæŠ€æœ¯æ„å»ºå¤šæ ·åŒ–çš„ 3D ä»¿çœŸåœºæ™¯ï¼Œé€šè¿‡åˆ©ç”¨æ¨¡æ‹Ÿå™¨ä¸­çš„ç²¾ç¡®å‡ ä½•ä¿¡æ¯è‡ªåŠ¨è®¡ç®—ç‰©ä½“é—´çš„ç©ºé—´å…³ç³»ï¼Œå¹¶åˆ›é€ æ€§åœ°é‡‡ç”¨â€œç§»é™¤ç›®æ ‡ç‰©ä½“å†é‡‡æ ·â€çš„ç­–ç•¥æ¥è‡ªåŠ¨æ ‡æ³¨è‡ªç”±ç©ºé—´ï¼ˆFree Spaceï¼‰ï¼Œä»è€Œä½æˆæœ¬åœ°ç”Ÿæˆäº†æµ·é‡åŒ…å«â€œå›¾åƒ-æŒ‡ä»¤-åƒç´ åæ ‡ç‚¹â€çš„é«˜è´¨é‡åˆæˆè®­ç»ƒæ•°æ®ã€‚&lt;/p&gt;
&lt;p&gt;åœ¨æŒ‡ä»¤å¾®è°ƒé˜¶æ®µï¼ŒRoboPoint å¥—ç”¨ LLaVA çš„æ¶æ„ï¼Œå†»ä½è§†è§‰å±‚åªç»ƒè¯­è¨€æ¨¡å‹ï¼ŒæŠŠâ€œæ‰¾åæ ‡â€ç›´æ¥è½¬åŒ–æˆâ€œæ–‡æœ¬ç”Ÿæˆâ€ä»»åŠ¡ï¼Œè®©æ¨¡å‹ç›´æ¥è¾“å‡ºåæ ‡æ•°å­—
åŒæ—¶ï¼Œä¸ºäº†é˜²æ­¢äº† VLM çš„é—å¿˜ï¼ŒåŠ å…¥äº† VQA æ•°æ®è¿›è¡Œ Co-Trainingã€‚&lt;/p&gt;
&lt;p&gt;åœ¨çœŸå®æ‰§è¡Œé˜¶æ®µï¼Œå…ˆä½¿ç”¨ RoboPoint è®¡ç®—å‡º RGB å›¾åƒä¸Šçš„ 2D åæ ‡ï¼Œç„¶åç»“åˆæ·±åº¦å›¾è½¬æ¢ä¸º 3D åæ ‡ï¼Œæœ€åç›´æ¥å¥—ç”¨ä¸€ä¸ªé¢„è®¾å¥½çš„æŠ“å–å§¿æ€ï¼ŒæŠŠç›®æ ‡ä¼ ç»™ä¼ ç»Ÿçš„è¿åŠ¨è§„åˆ’ç®—æ³•å»è§£ç®—è·¯å¾„ï¼Œæœºæ¢°è‡‚ç…§åšå°±è¡Œäº†ã€‚&lt;/p&gt;
&lt;p&gt;RoboPoint å…¶å®ä¹Ÿæ˜¯ä¸€ç§é«˜å±‚å†³ç­–çš„è§„åˆ’ï¼Œä¹Ÿæ˜¯ä¸€ç§ System 2 çš„æ–¹æ³•ã€‚&lt;/p&gt;
&lt;h2&gt;GR-1&lt;/h2&gt;
&lt;p&gt;GR-1 è¯æ˜äº†è§†é¢‘ç”Ÿæˆæ˜¯ç­–ç•¥å­¦ä¹ çš„é«˜æ•ˆä»£ç†ä»»åŠ¡ï¼Œå®ƒé€šè¿‡å¤§è§„æ¨¡è§†é¢‘ç”Ÿæˆå¼é¢„è®­ç»ƒè¿«ä½¿ GPT æ¨¡å‹å†…åŒ–ç¯å¢ƒåŠ¨æ€ä¸ç‰©ç†å…ˆéªŒï¼Œä»è€Œåœ¨ä¸‹æ¸¸æœºå™¨äººä»»åŠ¡ä¸­å®ç°äº†å“è¶Šçš„å°æ ·æœ¬å­¦ä¹ ä¸é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ã€‚&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://pic.hana0721.top/GR-1-all.1sfj4q0vsm.webp&quot; alt=&quot;&quot;&gt;
GR-1 é‡‡ç”¨ GPT-style Causal Transformer æ¶æ„å¤„ç†å¤šæ¨¡æ€äº¤ç»‡åºåˆ—ï¼Œå…ˆé€šè¿‡å¤§è§„æ¨¡è§†é¢‘ç”Ÿæˆé¢„è®­ç»ƒå­¦ä¹ ç¯å¢ƒåŠ¨æ€ï¼Œå†ç»ç”±åŠ¨ä½œä¸æœªæ¥å¸§è”åˆé¢„æµ‹ä»»åŠ¡è¿›è¡Œå¾®è°ƒï¼Œå®ç°ç«¯åˆ°ç«¯çš„è‡ªå›å½’ç­–ç•¥å­¦ä¹ ã€‚&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://pic.hana0721.top/GR-1-input.2vf8flx9ka.webp&quot; alt=&quot;&quot;&gt;
åœ¨é¢„è®­ç»ƒé˜¶æ®µï¼ŒGR-1 åˆ©ç”¨å¤§è§„æ¨¡äººç±»ç¬¬ä¸€è§†è§’è§†é¢‘æ•°æ®é›†ï¼ˆEgo4Dï¼‰æ‰§è¡Œè¯­è¨€æ¡ä»¶ä¸‹çš„è§†é¢‘é¢„æµ‹ä»»åŠ¡ï¼Œæ—¨åœ¨æ— éœ€åŠ¨ä½œæ ‡æ³¨å³å¯ä¹ å¾—é€šç”¨ç‰©ç†åŠ¨æ€ã€‚
æ¨¡å‹æ¶æ„ä¸Šå†»ç»“äº† CLIP æ–‡æœ¬ç¼–ç å™¨ä¸ MAE-ViT è§†è§‰ç¼–ç å™¨ï¼ˆè¾…ä»¥ Perceiver Resampler å‹ç¼©ç‰¹å¾ï¼‰ï¼Œå°†è¯­è¨€æŒ‡ä»¤ã€å†å²å›¾åƒå¸§ä¸å¯å­¦ä¹ çš„ [OBS] Token äº¤ç»‡è¾“å…¥è‡³ GPT ä¸»å¹²ç½‘ç»œã€‚
è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹å±è”½ [ACT] Tokenï¼Œä»…é€šè¿‡å› æœæ©ç æ³¨æ„åŠ›æœºåˆ¶åˆ©ç”¨ [OBS] Token é©±åŠ¨è§†è§‰è§£ç å™¨ï¼ˆVision Decoderï¼‰é‡å»ºæœªæ¥å¸§åƒç´ ï¼Œä»è€Œè¿«ä½¿æ¨¡å‹å†…åŒ–è§†è§‰æ¼”å˜è§„å¾‹ä¸è§†è¯­å¯¹é½å…³ç³»ï¼Œä¸ºä¸‹æ¸¸æœºå™¨äººæ“ä½œä»»åŠ¡æä¾›å…·å¤‡å¼ºæ³›åŒ–èƒ½åŠ›çš„ World Model åˆå§‹åŒ–æƒé‡ã€‚&lt;/p&gt;
&lt;p&gt;åœ¨å¾®è°ƒé˜¶æ®µï¼ŒGR-1 åŠ è½½é¢„è®­ç»ƒæƒé‡å¹¶æ‰©å±•è¾“å…¥åºåˆ—ï¼Œå°†æœºå™¨äººæœ¬ä½“çŠ¶æ€ï¼ˆProprioceptive Stateï¼‰ä¸è¯­è¨€ã€å›¾åƒäº¤ç»‡è¾“å…¥ï¼Œå¼•å…¥ [ACT] Token ç”¨äºå›å½’ 7-DoF æœºæ¢°è‡‚åŠ¨ä½œä¸å¤¹çˆªçŠ¶æ€ã€‚
è®­ç»ƒé‡‡ç”¨å¤šä»»åŠ¡è”åˆä¼˜åŒ–ç­–ç•¥ï¼Œåœ¨æ‰§è¡Œè¡Œä¸ºå…‹éš†ï¼ˆBehavior Cloningï¼‰å­¦ä¹ ç­–ç•¥åˆ†å¸ƒçš„åŒæ—¶ï¼Œä¿ç•™æœªæ¥å¸§é¢„æµ‹ï¼ˆVideo Predictionï¼‰ä½œä¸ºè¾…åŠ©ä»»åŠ¡ï¼Œé€šè¿‡è”åˆæœ€å°åŒ–åŠ¨ä½œå›å½’æŸå¤±ä¸å›¾åƒé‡å»ºæŸå¤±ï¼Œè¿«ä½¿ç­–ç•¥åœ¨å†³ç­–æ—¶æ˜¾å¼åˆ©ç”¨é¢„è®­ç»ƒé˜¶æ®µä¹ å¾—çš„ç‰©ç†ä¸–ç•ŒåŠ¨æ€ï¼ˆWorld Modelï¼‰ï¼Œä»è€Œå®ç°æ„ŸçŸ¥åˆ°åŠ¨ä½œçš„é«˜æ•ˆè¿ç§»ä¸å¯¹é½ã€‚&lt;/p&gt;
&lt;p&gt;GR-1 çš„ Limitation ä¹Ÿæ˜¯æ˜æ˜¾çš„ã€‚
å› ä¸ºè¦å¤„ç†é«˜ç»´å›¾åƒï¼Œæ‰€ä»¥å¯¼è‡´æ¨ç†å»¶è¿Ÿè¾ƒé«˜ã€‚
åŒæ—¶é¢„è®­ç»ƒçš„äººç±»è§†é¢‘ä¸æœºæ¢°è‡‚æ§åˆ¶ä¹‹é—´å­˜åœ¨å½¢æ€é¸¿æ²Ÿï¼ˆEmbodiment Gapï¼‰ï¼Œç›®å‰ä»…ä¾é å¾®è°ƒéšå¼å¯¹é½è€Œç¼ºä¹æ˜¾å¼çš„åŠ¨ä½œé‡å®šå‘æœºåˆ¶ã€‚&lt;/p&gt;
&lt;h2&gt;HPT&lt;/h2&gt;
&lt;p&gt;HPT ä½¿ç”¨ä¸€ç§æ¨¡å—åŒ– Token å¯¹é½æœºåˆ¶å°†å¼‚æ„æœºå™¨äººçš„ Proprioception ä¸ Vision æ˜ å°„åˆ°å…±äº«æ½œç©ºé—´åˆ°é€šç”¨ç­–ç•¥æ¶æ„ï¼Œå¹¶åœ¨å¤§è§„æ¨¡ Cross-Embodied æ•°æ®ä¸ŠéªŒè¯äº†æœºå™¨äººç­–ç•¥å­¦ä¹ çš„ Scaling Laws ä»¥åŠè¿ç§»èƒ½åŠ›ã€‚&lt;/p&gt;
&lt;p&gt;HPT é‡‡ç”¨äº†ä¸€ç§é«˜åº¦æ¨¡å—åŒ–çš„ Stem-Trunk-Head è®¾è®¡èŒƒå¼æ¥è§£å†³ Cross-Embodied éš¾é¢˜ã€‚&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://pic.hana0721.top/HPT-Stem.8z70jpnbae.webp&quot; alt=&quot;&quot;&gt;
åœ¨ Stem æ¨¡å—ä¸­ï¼Œåˆ©ç”¨ Cross-Attention å°†å¼‚æ„çš„ Proprioception ä¸ Vision å¯¹é½åˆ°ç»Ÿä¸€çš„ Embodied æ½œåœ¨è¡¨å¾ã€‚é¦–å…ˆï¼Œæœºå™¨äººçš„ Vision ä¿¡æ¯è¢«ç¼–ç æˆ Cross-Attention ä¸­çš„ K ä¸ Vï¼Œå¹¶ä¸ä¸€ç»„å¯å­¦ä¹ çš„ Q è¿›è¡Œèšåˆå¾—å‡º Vision Tokenã€‚åŒæ ·ï¼Œæœºå™¨äººçš„ Proprioception ä¹Ÿç»è¿‡ç›¸åŒçš„æ“ä½œï¼Œå¾—å‡º Proprio. Tokenã€‚ä¸åŒçš„ Embodied å¯¹åº”äº†ä¸åŒ Stemï¼Œæ˜¯åˆ†åˆ«è¿›è¡Œå­¦ä¹ çš„ã€‚&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://pic.hana0721.top/HPT.2yyuezdjdc.webp&quot; alt=&quot;&quot;&gt;
åœ¨ Trunk æ¨¡å—ä¸­ï¼Œæ‰€æœ‰ Embodied ä»»åŠ¡å…±äº«ä¸€ä¸ª Transformerï¼Œè´Ÿè´£å°† Stem å¯¹é½åçš„å¤šæ¨¡æ€ Token è¿›è¡Œæ·±åº¦èåˆå’Œæ¨ç†ã€‚æœ€ç»ˆï¼Œç»è¿‡æ± åŒ–åå¾—å‡ºæœ€ç»ˆ Latentã€‚&lt;/p&gt;
&lt;p&gt;åœ¨ Head æ¨¡å—ä¸­ï¼Œè´Ÿè´£å°† Trunk å¾—å‡º Latent è¿›è¡Œè§£ç ï¼Œè¿™é‡Œçš„è§£ç å™¨å¯ä»¥æ˜¯ MLPã€DP ä»¥åŠ ACTï¼Œå¾—å‡ºæœºå™¨äººçš„ Actionã€‚è¯·æ³¨æ„ï¼Œå¼‚æ„çš„æœºå™¨äººåˆ†åˆ«å¯¹åº”äº†ä¸åŒçš„ Headã€‚&lt;/p&gt;
&lt;p&gt;åœ¨è®­ç»ƒæ•°æ®ä¸Šï¼ŒHPT ä½¿ç”¨ OXEã€Simulation ä»¥åŠ Human Videos ç­‰ã€‚
HPT ä½¿ç”¨äº†æœ€æš´åŠ›çš„ BC æ–¹æ³•ï¼Œè¯æ˜äº†å…¶ Scaling Law çš„å­˜åœ¨ã€‚&lt;/p&gt;
&lt;h2&gt;RoboDual&lt;/h2&gt;
&lt;h2&gt;GR-2&lt;/h2&gt;
&lt;h2&gt;Humanoid Manipulation&lt;/h2&gt;
&lt;h2&gt;Surfer&lt;/h2&gt;
&lt;h2&gt;SceneVerse&lt;/h2&gt;
&lt;h2&gt;Robot See Robot Do&lt;/h2&gt;
&lt;h2&gt;ReKep&lt;/h2&gt;
&lt;h2&gt;OmniManip&lt;/h2&gt;
&lt;h2&gt;SOFAR&lt;/h2&gt;
&lt;h2&gt;PIVOT-R&lt;/h2&gt;
&lt;h2&gt;ManipGen&lt;/h2&gt;
&lt;h2&gt;DemoGen&lt;/h2&gt;
&lt;h2&gt;ArticuBot&lt;/h2&gt;
&lt;h2&gt;LAPA&lt;/h2&gt;
&lt;h2&gt;GR00T&lt;/h2&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-3.3yex1xdpri.webp"/><enclosure url="https://pic.hana0721.top/rl-note-3.3yex1xdpri.webp"/></item><item><title>RLç¬”è®°ï¼ˆ27ï¼‰ï¼šMARL æœ€åçš„æ³¢çº¹ (MAT &amp; HASAC)</title><link>https://claudiakim6827362.github.io/blog/rl-note-27</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/rl-note-27</guid><description>å¤šæ™ºèƒ½ä½“é¢†åŸŸçš„ SOTA ä¹‹ä½œï¼šè¯¦è§£ Multi-Agent Transformer (MAT) å¦‚ä½•å°†åšå¼ˆè½¬åŒ–ä¸ºåºåˆ—å»ºæ¨¡ï¼Œä»¥åŠ HASAC å¦‚ä½•ç»“åˆå¼‚æ„ç†è®ºä¸ SAC çš„æ ·æœ¬æ•ˆç‡ã€‚</description><pubDate>Mon, 05 Jan 2026 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;å¼•è¨€ï¼ˆIntroductionï¼‰&lt;/h2&gt;
&lt;p&gt;åœ¨ä¹‹å‰çš„ç¬”è®°ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°äº† MARL çš„å‘å±•è„‰ç»œï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;MAPPO&lt;/strong&gt;ï¼šOn-Policyï¼Œç¨³å®šä½†æ ·æœ¬æ•ˆç‡ä½ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HAPPO&lt;/strong&gt;ï¼šå¼•å…¥åºåˆ—æ›´æ–°ï¼Œè§£å†³äº†å¼‚æ„å’Œå•è°ƒæ€§é—®é¢˜ï¼Œä½†ä»æ˜¯ On-Policyã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Decision Transformer&lt;/strong&gt;ï¼šå°†å•æ™ºèƒ½ä½“ RL å˜æˆäº†åºåˆ—é¢„æµ‹ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;æœ¬ç« å°†ä»‹ç»ä¸¤ä¸ªé›†å¤§æˆè€…ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;MAT (Multi-Agent Transformer)&lt;/strong&gt;ï¼šå°† &quot;Transformer&quot; å’Œ &quot;åºåˆ—å†³ç­–&quot; å¼•å…¥ MARLï¼ŒæŠŠå¤šæ™ºèƒ½ä½“åšå¼ˆå˜æˆäº†ä¸€ä¸ªè‡ªå›å½’ï¼ˆAuto-Regressiveï¼‰çš„åºåˆ—ç”Ÿæˆé—®é¢˜ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HASAC (Heterogeneous-Agent SAC)&lt;/strong&gt;ï¼šå°† HAPPO çš„ &quot;åºåˆ—æ›´æ–°ç†è®º&quot; åº”ç”¨äº SACï¼Œæ‰“é€ å‡ºå…¼å…·ç†è®ºä¿è¯å’Œæé«˜æ ·æœ¬æ•ˆç‡çš„ Off-Policy ç®—æ³•ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2&gt;Multi-Agent Transformer (MAT)&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;è®ºæ–‡&lt;/strong&gt;ï¼š&lt;a href=&quot;https://arxiv.org/abs/2205.14953&quot;&gt;Multi-Agent Reinforcement Learning is a Sequence Modeling Problem&lt;/a&gt; (NeurIPS 2022)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;æ ¸å¿ƒæ€æƒ³ï¼šæŠŠâ€œå¹¶å‘â€å˜æˆâ€œä¸²è¡Œâ€&lt;/h3&gt;
&lt;p&gt;ä¼ ç»Ÿ MARLï¼ˆå¦‚ QMIX, MAPPOï¼‰å‡è®¾æ‰€æœ‰æ™ºèƒ½ä½“åœ¨åŒä¸€æ—¶åˆ»&lt;strong&gt;åŒæ—¶&lt;/strong&gt;é‡‡å–è¡ŒåŠ¨ï¼Œè”åˆåŠ¨ä½œåˆ†å¸ƒä¸º $\pi(\mathbf{a}|s) = \prod \pi(a^i|s)$ï¼ˆå‡è®¾ç‹¬ç«‹ï¼‰ã€‚&lt;/p&gt;
&lt;p&gt;MAT æå‡ºäº†ä¸€ç§é¢ è¦†æ€§çš„è§†è§’ï¼š&lt;strong&gt;è”åˆç­–ç•¥å¯ä»¥åˆ†è§£ä¸ºåºåˆ—é¢„æµ‹&lt;/strong&gt;ã€‚
åˆ©ç”¨æ¦‚ç‡é“¾å¼æ³•åˆ™ï¼Œè”åˆåŠ¨ä½œçš„æ¦‚ç‡å¯ä»¥å†™æˆï¼š
$$
\pi(\mathbf{a}|s) = \prod_{i=1}^n \pi(a^i | s, a^1, a^2, ..., a^{i-1})
$$&lt;/p&gt;
&lt;p&gt;è¿™æ„å‘³ç€ï¼šAgent 1 å…ˆåŠ¨ï¼›Agent 2 çœ‹åˆ° Agent 1 çš„åŠ¨ä½œåå†åŠ¨ï¼›Agent 3 çœ‹åˆ° 1 å’Œ 2 çš„åŠ¨ä½œåå†åŠ¨â€¦â€¦
è¿™ä¸ &lt;strong&gt;Transformer&lt;/strong&gt; çš„è‡ªå›å½’ç”Ÿæˆï¼ˆé¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ï¼‰å®Œå…¨ä¸€è‡´ï¼&lt;/p&gt;
&lt;h3&gt;æ¶æ„è®¾è®¡ï¼šEncoder-Decoder&lt;/h3&gt;
&lt;p&gt;MAT ä½¿ç”¨äº†æ ‡å‡†çš„ Transformer æ¶æ„ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Encoderï¼ˆå¤„ç†è§‚æµ‹ï¼‰&lt;/strong&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;è¾“å…¥ï¼šæ‰€æœ‰æ™ºèƒ½ä½“çš„å±€éƒ¨è§‚æµ‹åºåˆ— $(o^1, o^2, ..., o^n)$ã€‚&lt;/li&gt;
&lt;li&gt;ä½œç”¨ï¼šåˆ©ç”¨ Self-Attention æå–æ™ºèƒ½ä½“ä¹‹é—´çš„äº¤äº’ç‰¹å¾ï¼Œç”Ÿæˆè”åˆçŠ¶æ€è¡¨å¾ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Decoderï¼ˆç”ŸæˆåŠ¨ä½œï¼‰&lt;/strong&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;è¾“å…¥ï¼šEncoder çš„è¾“å‡º + ä¹‹å‰çš„æ™ºèƒ½ä½“åŠ¨ä½œåºåˆ— $(a^1, ..., a^{i-1})$ã€‚&lt;/li&gt;
&lt;li&gt;è¾“å‡ºï¼šå½“å‰æ™ºèƒ½ä½“ $i$ çš„åŠ¨ä½œæ¦‚ç‡åˆ†å¸ƒ $\pi(a^i | \dots)$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æœºåˆ¶&lt;/strong&gt;ï¼šç±»ä¼¼äº GPTï¼Œé€šè¿‡ Masked Attention ç¡®ä¿æ™ºèƒ½ä½“ $i$ åªèƒ½çœ‹åˆ°å®ƒä¹‹å‰çš„é˜Ÿå‹åŠ¨ä½œï¼Œçœ‹ä¸åˆ°æœªæ¥çš„ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;è®­ç»ƒç›®æ ‡&lt;/h3&gt;
&lt;p&gt;MAT ä½¿ç”¨ PPO çš„ç›®æ ‡å‡½æ•°è¿›è¡Œç«¯åˆ°ç«¯è®­ç»ƒã€‚
$$
L(\theta) = \min(r_t(\theta) \hat{A}_t, \text{clip}(r_t(\theta), 1-\epsilon, 1+\epsilon)\hat{A}_t)
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜åŠ¿&lt;/strong&gt;ï¼šè¿™ç§åºåˆ—åŒ–å»ºæ¨¡å¤©ç„¶åœ°è§£å†³äº†&lt;strong&gt;éå¹³ç¨³æ€§&lt;/strong&gt;é—®é¢˜ã€‚å¯¹äº Agent $i$ æ¥è¯´ï¼Œå®ƒåšå†³ç­–æ—¶ï¼Œé˜Ÿå‹ $1 \sim i-1$ çš„åŠ¨ä½œå·²ç»æ˜¯&lt;strong&gt;å·²çŸ¥&lt;/strong&gt;çš„ï¼ˆFixedï¼‰ï¼Œç¯å¢ƒä¸å†æ˜¯â€œè–›å®šè°”â€çš„ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ€§èƒ½&lt;/strong&gt;ï¼šMAT åœ¨ SMAC ç­‰åŸºå‡†æµ‹è¯•ä¸­å±•ç°äº†æƒŠäººçš„æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦å¤æ‚åè°ƒçš„ä»»åŠ¡ä¸­ï¼Œä¸”å…·æœ‰æå¼ºçš„ Zero-Shot æ³›åŒ–èƒ½åŠ›ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;Heterogeneous-Agent SAC (HASAC)&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;è®ºæ–‡&lt;/strong&gt;ï¼š&lt;a href=&quot;https://arxiv.org/abs/2109.11251&quot;&gt;Trust Region Policy Optimization in Multi-Agent Reinforcement Learning&lt;/a&gt; (ICLR 2022)
&lt;em&gt;æ³¨ï¼šHASAC æ˜¯è¯¥è®ºæ–‡æå‡ºçš„ HARL (Heterogeneous-Agent RL) æ¡†æ¶ä¸‹çš„ Off-Policy å˜ä½“ã€‚&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;æ ¸å¿ƒåŠ¨æœºï¼šæ•ˆç‡è‡³ä¸Š&lt;/h3&gt;
&lt;p&gt;HAPPO è™½ç„¶ç†è®ºå®Œç¾ï¼ˆä¿è¯å•è°ƒæå‡ï¼‰ï¼Œä½†å®ƒæ˜¯ On-Policy çš„ï¼Œæ•°æ®åˆ©ç”¨ç‡ä½ï¼Œè®­ç»ƒæ…¢ã€‚
SAC æ˜¯å•æ™ºèƒ½ä½“ä¸­æ ·æœ¬æ•ˆç‡æœ€é«˜çš„ Off-Policy ç®—æ³•ã€‚
&lt;strong&gt;HASAC = HAPPO çš„åºåˆ—æ›´æ–°ç†è®º + SAC çš„æœ€å¤§ç†µ Off-Policy æœºåˆ¶ã€‚&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;ç®—æ³•åŸç†&lt;/h3&gt;
&lt;p&gt;HASAC ç»§æ‰¿äº† HAPPO çš„ &lt;strong&gt;å¤šæ™ºèƒ½ä½“ä¼˜åŠ¿åˆ†è§£å¼•ç†&lt;/strong&gt;ï¼š
$$
A_{\boldsymbol{\pi}}^{\text{joint}}(s, \mathbf{a}) = \sum_{i=1}^n A_{\pi}^{i}(s, a^i, a^1, ..., a^{i-1})
$$&lt;/p&gt;
&lt;h3&gt;è®­ç»ƒæµç¨‹&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;éšæœºæ’åˆ—&lt;/strong&gt;ï¼šæ¯ä¸€è½®è®­ç»ƒï¼Œéšæœºæ‰“ä¹±æ™ºèƒ½ä½“æ›´æ–°é¡ºåºï¼ˆä¾‹å¦‚ $1 \to 2 \to \dots \to n$ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åºåˆ—æ›´æ–°&lt;/strong&gt;ï¼š
&lt;ul&gt;
&lt;li&gt;å¯¹äºæ™ºèƒ½ä½“ $i$ï¼Œå®ƒçš„ Critic $Q_i$ éœ€è¦è¯„ä¼°çš„æ˜¯ï¼šåœ¨é˜Ÿå‹ $1 \sim i-1$ å·²ç»æ›´æ–°äº†æ–°ç­–ç•¥ï¼Œè€Œé˜Ÿå‹ $i+1 \sim n$ è¿˜åœ¨ç”¨æ—§ç­–ç•¥çš„æƒ…å†µä¸‹çš„ä»·å€¼ã€‚&lt;/li&gt;
&lt;li&gt;ç›®æ ‡å‡½æ•°ç»“åˆäº† SAC çš„ç†µæ­£åˆ™åŒ–ï¼š
$$
J(\pi^i) = \mathbb{E}&lt;em&gt;{\mathcal{D}} \left[ Q^{\pi&lt;/em&gt;{\text{old}}}(s, a^1, ..., a^i, ..., a^n) - \alpha \log \pi^i(a^i|s) \right]
$$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å…³é”®ç‚¹&lt;/strong&gt;ï¼šåœ¨è®¡ç®— $Q$ å€¼æ—¶ï¼Œè¾“å…¥çš„åŠ¨ä½œå‘é‡ $\mathbf{a}$ æ˜¯æ··åˆçš„ï¼š
&lt;ul&gt;
&lt;li&gt;$a^{1:i-1}$ æ¥è‡ª&lt;strong&gt;å½“å‰æœ€æ–°&lt;/strong&gt;çš„ç­–ç•¥ã€‚&lt;/li&gt;
&lt;li&gt;$a^{i}$ æ˜¯å½“å‰æ­£åœ¨ä¼˜åŒ–çš„ã€‚&lt;/li&gt;
&lt;li&gt;$a^{i+1:n}$ æ¥è‡ª&lt;strong&gt;æ—§&lt;/strong&gt;ç­–ç•¥ï¼ˆReplay Buffer ä¸­çš„åŠ¨ä½œæˆ–æ—§ç­–ç•¥é‡‡æ ·ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;ä¼˜ç¼ºç‚¹&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜ç‚¹&lt;/strong&gt;ï¼š
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;æé«˜çš„æ ·æœ¬æ•ˆç‡&lt;/strong&gt;ï¼šOff-Policy æœºåˆ¶è®©å®ƒå¯ä»¥åˆ©ç”¨å†å²æ•°æ®ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å¼‚æ„å‹å¥½&lt;/strong&gt;ï¼šä¸éœ€è¦å‚æ•°å…±äº«ï¼Œé€‚åˆä¸åŒç±»å‹çš„æ™ºèƒ½ä½“åä½œã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ”¶æ•›ä¿è¯&lt;/strong&gt;ï¼šç»§æ‰¿äº† HARL çš„å•è°ƒæ€§è¯æ˜ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç¼ºç‚¹&lt;/strong&gt;ï¼šè®¡ç®—å¤æ‚åº¦è¾ƒé«˜ï¼Œå› ä¸ºéœ€è¦ä¸²è¡Œæ›´æ–°æ¯ä¸ªæ™ºèƒ½ä½“ï¼Œä¸” Critic éœ€è¦å¤„ç†æ··åˆåŠ¨ä½œè¾“å…¥ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;æ·±åº¦å¯¹æ¯”ï¼šå››å¤§å¤©ç‹&lt;/h2&gt;
&lt;p&gt;è‡³æ­¤ï¼Œæˆ‘ä»¬å·²ç»é›†é½äº† MARL é¢†åŸŸçš„å››å¤§é¡¶çº§ç®—æ³•ã€‚&lt;/p&gt;
&lt;p&gt;| ç»´åº¦ | MAPPO | HAPPO | MAT | HASAC |
| :--- | :--- | :--- | :--- | :--- |
| &lt;strong&gt;æ ¸å¿ƒæœºåˆ¶&lt;/strong&gt; | PPO + CTDE | åºåˆ—æ›´æ–° + PPO | &lt;strong&gt;Transformer + è‡ªå›å½’&lt;/strong&gt; | &lt;strong&gt;åºåˆ—æ›´æ–° + SAC&lt;/strong&gt; |
| &lt;strong&gt;ç­–ç•¥ç±»å‹&lt;/strong&gt; | On-Policy | On-Policy | On-Policy | &lt;strong&gt;Off-Policy&lt;/strong&gt; |
| &lt;strong&gt;å†³ç­–æ–¹å¼&lt;/strong&gt; | ç‹¬ç«‹ (åŒæ­¥) | ç‹¬ç«‹ (æ‰§è¡Œæ—¶) | &lt;strong&gt;åºåˆ— (ä¸²è¡Œæ‰§è¡Œ)&lt;/strong&gt; | ç‹¬ç«‹ (æ‰§è¡Œæ—¶) |
| &lt;strong&gt;åŒæ„/å¼‚æ„&lt;/strong&gt; | å¼ºä¾èµ–åŒæ„ (å‚æ•°å…±äº«) | &lt;strong&gt;å¼‚æ„å‹å¥½&lt;/strong&gt; | åŒæ„/å¼‚æ„çš†å¯ | &lt;strong&gt;å¼‚æ„å‹å¥½&lt;/strong&gt; |
| &lt;strong&gt;æ ·æœ¬æ•ˆç‡&lt;/strong&gt; | ä½ | ä½ | ä¸­ | &lt;strong&gt;é«˜&lt;/strong&gt; |
| &lt;strong&gt;é€‚ç”¨åœºæ™¯&lt;/strong&gt; | å¤§è§„æ¨¡åŒè´¨é›†ç¾¤ | å¤æ‚å¼‚æ„åä½œ | æå¤æ‚åºåˆ—å†³ç­– | éœ€è¦å¿«é€Ÿæ”¶æ•›çš„ä»»åŠ¡ |&lt;/p&gt;
&lt;h3&gt;æ€»ç»“&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;å¦‚æœä½ è¿½æ±‚&lt;strong&gt;æè‡´çš„æ€§èƒ½&lt;/strong&gt;å’Œå¯¹å¤æ‚ç­–ç•¥çš„å»ºæ¨¡èƒ½åŠ›ï¼Œ&lt;strong&gt;MAT&lt;/strong&gt; æ˜¯é¦–é€‰ï¼Œå®ƒä»£è¡¨äº† RL ä¸ LLM ç»“åˆçš„è¶‹åŠ¿ã€‚&lt;/li&gt;
&lt;li&gt;å¦‚æœä½ è¿½æ±‚&lt;strong&gt;è®­ç»ƒé€Ÿåº¦&lt;/strong&gt;å’Œ&lt;strong&gt;æ ·æœ¬åˆ©ç”¨ç‡&lt;/strong&gt;ï¼Œæˆ–è€…ä½ çš„æ™ºèƒ½ä½“æ˜¯&lt;strong&gt;å¼‚æ„&lt;/strong&gt;çš„ï¼ˆæ¯”å¦‚ä¸€ä¸ªæ— äººæœºé…åˆä¸€ä¸ªæœºæ¢°è‡‚ï¼‰ï¼Œ&lt;strong&gt;HASAC&lt;/strong&gt; æ˜¯ç›®å‰çš„æœ€å¼ºé€‰æ‹©ã€‚&lt;/li&gt;
&lt;/ul&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-4.1ziqble6oe.webp"/><enclosure url="https://pic.hana0721.top/rl-note-4.1ziqble6oe.webp"/></item><item><title>RLç¬”è®°ï¼ˆ26ï¼‰ï¼šå¼‚æ„æ™ºèƒ½ä½“ä¿¡ä»»åŒºåŸŸä¼˜åŒ– (HAPPO &amp; HATRPO)</title><link>https://claudiakim6827362.github.io/blog/rl-note-26</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/rl-note-26</guid><description>ä»ç»éªŒä¸»ä¹‰å›å½’ç†è®ºä¸¥è°¨æ€§ï¼šè¯¦è§£ HAPPO å¦‚ä½•è§£å†³ MARL ä¸­çš„å•è°ƒæå‡éš¾é¢˜ã€‚æ¶µç›–å¤šæ™ºèƒ½ä½“ä¼˜åŠ¿åˆ†è§£å¼•ç†ã€åºåˆ—æ›´æ–°æœºåˆ¶ä»¥åŠä¸ MAPPO çš„æœ¬è´¨åŒºåˆ«ã€‚</description><pubDate>Sun, 04 Jan 2026 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;å¼•è¨€ï¼ˆIntroductionï¼‰&lt;/h2&gt;
&lt;p&gt;åœ¨ä¹‹å‰çš„ç¬”è®°ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº† &lt;strong&gt;MAPPO&lt;/strong&gt;ï¼Œå®ƒç®€å•åœ°è®©æ¯ä¸ªæ™ºèƒ½ä½“è¿è¡Œ PPOï¼Œå¹¶å…±ç”¨ä¸€ä¸ªä¸­å¿ƒåŒ– Criticã€‚è™½ç„¶åœ¨å·¥ç¨‹ä¸Šå¾ˆæˆåŠŸï¼Œä½†å®ƒåœ¨ç†è®ºä¸Šå­˜åœ¨ä¸€ä¸ªå·¨å¤§çš„æ¼æ´ï¼š&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;å¤šæ™ºèƒ½ä½“æ›´æ–°å†²çª&lt;/strong&gt;ã€‚
åœ¨å•æ™ºèƒ½ä½“ä¸­ï¼ŒPPO/TRPO ä¿è¯äº†æ¯ä¸€æ­¥æ›´æ–°ï¼Œç­–ç•¥æ€§èƒ½ $J(\pi)$ éƒ½æ˜¯&lt;strong&gt;å•è°ƒä¸å‡&lt;/strong&gt;çš„ã€‚
ä½†åœ¨å¤šæ™ºèƒ½ä½“ä¸­ï¼Œå¦‚æœæ‰€æœ‰æ™ºèƒ½ä½“&lt;strong&gt;åŒæ—¶&lt;/strong&gt;æ›´æ–°ç­–ç•¥ï¼Œè¿™å°±å¥½æ¯”ä¸¤ä¸ªäººæŠ¬æ¡Œå­ï¼ŒA æƒ³å¾€å·¦ï¼ŒB æƒ³å¾€å³ï¼Œè™½ç„¶ä¸¤äººå„è‡ªè§‰å¾—è‡ªå·±çš„æ–¹å‘æ˜¯å¯¹çš„ï¼Œä½†åˆèµ·æ¥çš„ç»“æœå¯èƒ½å¯¼è‡´æ¡Œå­ç¿»å€’ï¼ˆè”åˆç­–ç•¥æ€§èƒ½ä¸‹é™ï¼‰ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;HAPPO (Heterogeneous-Agent PPO)&lt;/strong&gt; å’Œ &lt;strong&gt;HATRPO&lt;/strong&gt; çš„æ ¸å¿ƒè´¡çŒ®åœ¨äºï¼šæå‡ºäº†&lt;strong&gt;å¤šæ™ºèƒ½ä½“ä¼˜åŠ¿åˆ†è§£å¼•ç†&lt;/strong&gt;ï¼Œå¹¶æ®æ­¤è®¾è®¡äº†&lt;strong&gt;åºåˆ—æ›´æ–°&lt;/strong&gt;æ–¹æ¡ˆï¼Œåœ¨ç†è®ºä¸Šè¯æ˜äº†è”åˆç­–ç•¥çš„å•è°ƒæå‡ï¼Œç‰¹åˆ«é€‚ç”¨äº&lt;strong&gt;å¼‚æ„ï¼ˆHeterogeneousï¼‰&lt;/strong&gt; æ™ºèƒ½ä½“åœºæ™¯ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;ç†è®ºåŸºçŸ³ï¼šå¤šæ™ºèƒ½ä½“ä¼˜åŠ¿åˆ†è§£å¼•ç†&lt;/h2&gt;
&lt;p&gt;æˆ‘ä»¬å¸Œæœ›ä¼˜åŒ–è”åˆç­–ç•¥ $\boldsymbol{\pi} = (\pi^1, \pi^2, ..., \pi^n)$ ä»¥æœ€å¤§åŒ–è”åˆå›æŠ¥ $J(\boldsymbol{\pi})$ã€‚
ç±»ä¼¼äº TRPOï¼Œæˆ‘ä»¬å…³æ³¨æ–°æ—§ç­–ç•¥çš„å›æŠ¥å·® $J(\boldsymbol{\pi}&lt;em&gt;{\text{new}}) - J(\boldsymbol{\pi}&lt;/em&gt;{\text{old}})$ã€‚&lt;/p&gt;
&lt;h3&gt;ä¼˜åŠ¿åˆ†è§£å¼•ç† (Multi-Agent Advantage Decomposition Lemma)&lt;/h3&gt;
&lt;p&gt;HAPPO è¯æ˜äº†ï¼Œè”åˆç­–ç•¥çš„ä¼˜åŠ¿å‡½æ•°ï¼ˆJoint Advantageï¼‰å¯ä»¥ç²¾ç¡®åˆ†è§£ä¸ºæ¯ä¸ªæ™ºèƒ½ä½“å±€éƒ¨ä¼˜åŠ¿å‡½æ•°çš„&lt;strong&gt;ç´¯åŠ &lt;/strong&gt;ï¼Œå‰ææ˜¯è¿™äº›ä¼˜åŠ¿æ˜¯&lt;strong&gt;æŒ‰é¡ºåº&lt;/strong&gt;è®¡ç®—çš„ã€‚&lt;/p&gt;
&lt;p&gt;$$
A_{\boldsymbol{\pi}}^{\text{joint}}(s, \mathbf{a}) = \sum_{i=1}^n A_{\pi}^{i}(s, a^i, a^1, a^2, ..., a^{i-1})
$$&lt;/p&gt;
&lt;p&gt;è¿™é‡Œçš„ $A_{\pi}^{i}$ æ˜¯ç¬¬ $i$ ä¸ªæ™ºèƒ½ä½“çš„ä¼˜åŠ¿å‡½æ•°ï¼Œä½†æœ‰ä¸€ä¸ªå…³é”®ç»†èŠ‚ï¼š
å®ƒä¸ä»…ä¾èµ–äºå½“å‰çŠ¶æ€ $s$ å’ŒåŠ¨ä½œ $a^i$ï¼Œè¿˜ä¾èµ–äº&lt;strong&gt;æ’åœ¨ä»–å‰é¢çš„æ™ºèƒ½ä½“ $(a^1, a^2, ..., a^{i-1})$ çš„åŠ¨ä½œ&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;p&gt;è¿™æ„å‘³ç€ï¼šå¦‚æœæˆ‘ä»¬æŒ‰ç…§æŸç§é¡ºåº $1, 2, ..., n$ ä¾æ¬¡æ›´æ–°æ™ºèƒ½ä½“ï¼Œé‚£ä¹ˆæ•´ä½“æ€§èƒ½çš„æå‡ç­‰äºæ¯ä¸ªäººè´¡çŒ®çš„æå‡ä¹‹å’Œã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;æ ¸å¿ƒæœºåˆ¶ï¼šåºåˆ—æ›´æ–° (Sequential Update)&lt;/h2&gt;
&lt;p&gt;ä¸ºäº†åˆ©ç”¨ä¸Šè¿°å¼•ç†ï¼ŒHAPPO æŠ›å¼ƒäº† MAPPO çš„â€œåŒæ­¥æ›´æ–°â€æ¨¡å¼ï¼Œé‡‡ç”¨äº† &lt;strong&gt;åºåˆ—æ›´æ–°&lt;/strong&gt; æ¨¡å¼ã€‚&lt;/p&gt;
&lt;h3&gt;æµç¨‹&lt;/h3&gt;
&lt;p&gt;åœ¨æ¯ä¸€æ¬¡è®­ç»ƒè¿­ä»£ä¸­ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;éšæœºæ’åˆ—&lt;/strong&gt;ï¼šéšæœºç”Ÿæˆä¸€ä¸ªæ™ºèƒ½ä½“çš„æ›´æ–°é¡ºåºï¼ˆä¾‹å¦‚ï¼šAgent 3 -&gt; Agent 1 -&gt; Agent 2ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä¾æ¬¡æ›´æ–°&lt;/strong&gt;ï¼š
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Agent 3&lt;/strong&gt;ï¼šåŸºäºæ—§ç­–ç•¥ $\boldsymbol{\pi}&lt;em&gt;{\text{old}}$ è®¡ç®—è‡ªå·±çš„ä¼˜åŠ¿ï¼Œæ›´æ–°ç­–ç•¥ï¼Œå˜ä¸º $\pi^3&lt;/em&gt;{\text{new}}$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Agent 1&lt;/strong&gt;ï¼šçœ‹åˆ° Agent 3 å·²ç»æ›´æ–°äº†ï¼ˆç¯å¢ƒå˜äº†ï¼‰ï¼ŒåŸºäº $(\pi^3_{\text{new}}, \pi^1_{\text{old}}, \pi^2_{\text{old}})$ è®¡ç®—è‡ªå·±çš„ä¼˜åŠ¿ï¼Œæ›´æ–°ä¸º $\pi^1_{\text{new}}$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Agent 2&lt;/strong&gt;ï¼šçœ‹åˆ° 3 å’Œ 1 éƒ½å˜äº†ï¼ŒåŸºäº $(\pi^3_{\text{new}}, \pi^1_{\text{new}}, \pi^2_{\text{old}})$ æ›´æ–°è‡ªå·±ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å¾ªç¯ç»“æŸ&lt;/strong&gt;ï¼šæ‰€æœ‰æ™ºèƒ½ä½“æ›´æ–°å®Œæ¯•ï¼Œè¿›å…¥ä¸‹ä¸€è½®é‡‡æ ·ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;ä¸ºä»€ä¹ˆè¿™æ ·å°±ç¨³äº†ï¼Ÿ&lt;/h3&gt;
&lt;p&gt;é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯¹äºæ¯ä¸€ä¸ªæ™ºèƒ½ä½“ $i$ æ¥è¯´ï¼Œå®ƒåœ¨æ›´æ–°æ—¶ï¼Œæ’åœ¨å®ƒå‰é¢çš„é˜Ÿå‹å·²ç»æ˜¯â€œæ–°ç­–ç•¥â€äº†ï¼Œæ’åœ¨åé¢çš„è¿˜æ˜¯â€œæ—§ç­–ç•¥â€ã€‚å®ƒåªéœ€è¦åœ¨å½“å‰è¿™ä¸ª&lt;strong&gt;å›ºå®š&lt;/strong&gt;çš„ä¸Šä¸‹æ–‡ä¸­æ‰¾åˆ°æœ€ä¼˜æå‡æ–¹å‘ï¼Œå°±èƒ½ä¿è¯æ•´ä¸ªå›¢é˜Ÿçš„æ€»åˆ†æ˜¯å¢åŠ çš„ã€‚&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;ğŸ’¡ ç›´è§‰&lt;/strong&gt;ï¼š
å°±åƒå¤šäººè¿‡ç‹¬æœ¨æ¡¥ã€‚å¤§å®¶ä¸€èµ·è·‘å®¹æ˜“æŒ¤æ‰ä¸‹å»ï¼ˆåŒæ­¥æ›´æ–°ï¼‰ã€‚HAPPO çš„åšæ³•æ˜¯ï¼šç¬¬ä¸€ä¸ªäººå…ˆèµ°ç¨³ï¼Œç¬¬äºŒä¸ªäººçœ‹å‡†ç¬¬ä¸€ä¸ªäººçš„ä½ç½®å†èµ°ï¼Œä¾æ¬¡ç±»æ¨ã€‚&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2&gt;HATRPO ä¸ HAPPO&lt;/h2&gt;
&lt;p&gt;åŸºäºè¿™ä¸ªç†è®ºæ¡†æ¶ï¼Œè¡ç”Ÿå‡ºäº†ä¸¤ä¸ªç®—æ³•ã€‚å®ƒä»¬éƒ½å…±äº«åŒä¸€ä¸ª&lt;strong&gt;ä¸­å¿ƒåŒ– Critic&lt;/strong&gt; $V(s)$ã€‚&lt;/p&gt;
&lt;h3&gt;HATRPO (Trust Region)&lt;/h3&gt;
&lt;p&gt;è¿™æ˜¯ TRPO çš„å¤šæ™ºèƒ½ä½“ç‰ˆæœ¬ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç›®æ ‡&lt;/strong&gt;ï¼šæœ€å¤§åŒ–å±€éƒ¨ä¼˜åŠ¿æœŸæœ›ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;çº¦æŸ&lt;/strong&gt;ï¼šä¸¥æ ¼é™åˆ¶æ¯ä¸ªæ™ºèƒ½ä½“æ›´æ–°å‰åçš„ KL æ•£åº¦ï¼š
$$ \mathbb{E}[D_{KL}(\pi^i_{\text{old}} || \pi^i_{\text{new}})] \le \delta $$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ±‚è§£&lt;/strong&gt;ï¼šåŒæ ·éœ€è¦ä½¿ç”¨å…±è½­æ¢¯åº¦æ³•ï¼ˆCGï¼‰ï¼Œè®¡ç®—é‡è¾ƒå¤§ï¼Œä½†ç†è®ºæ€§è´¨æœ€å¼ºã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;HAPPO (Proximal Policy)&lt;/h3&gt;
&lt;p&gt;è¿™æ˜¯ PPO çš„å¤šæ™ºèƒ½ä½“ç‰ˆæœ¬ï¼Œæ›´å®ç”¨ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç›®æ ‡&lt;/strong&gt;ï¼šä½¿ç”¨ Clip æŠ€å·§æ¥æ›¿ä»£ KL çº¦æŸã€‚
å®šä¹‰æ¯”ç‡ $r_t^i(\theta) = \frac{\pi^i(a^i|s)}{\pi^i_{\text{old}}(a^i|s)}$ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š
$$
L^{HAPPO}(\theta^i) = \mathbb{E} \left[ \min \left( r_t^i(\theta) \hat{M}^i, \text{clip}\left(r_t^i(\theta), 1-\epsilon, 1+\epsilon\right) \hat{M}^i \right) \right]
$$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å…³é”®ç‚¹ $\hat{M}^i$&lt;/strong&gt;ï¼šè¿™æ˜¯&lt;strong&gt;ä¿®æ­£åçš„ä¼˜åŠ¿å‡½æ•°&lt;/strong&gt;ã€‚
åœ¨è®¡ç®— Agent $i$ çš„ä¼˜åŠ¿æ—¶ï¼Œå¿…é¡»æ‰£é™¤æ’åœ¨å®ƒå‰é¢çš„é˜Ÿå‹ $1, ..., i-1$ å·²ç»æ‹¿èµ°çš„ä¼˜åŠ¿ï¼Œç¡®ä¿ä¸é‡å¤è®¡ç®—åŠŸåŠ³ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;æ·±åº¦å¯¹æ¯”ï¼šHAPPO vs. MAPPO&lt;/h2&gt;
&lt;p&gt;è¿™ä¸¤ä¸ªç®—æ³•éå¸¸ç›¸ä¼¼ï¼Œéƒ½æ˜¯ PPO + CTDEï¼Œå¾ˆå®¹æ˜“æ··æ·†ã€‚&lt;/p&gt;
&lt;p&gt;| ç»´åº¦ | MAPPO (Multi-Agent PPO) | HAPPO (Heterogeneous-Agent PPO) |
| :--- | :--- | :--- |
| &lt;strong&gt;æ›´æ–°æ–¹å¼&lt;/strong&gt; | &lt;strong&gt;åŒæ­¥æ›´æ–° (Simultaneous)&lt;/strong&gt; | &lt;strong&gt;åºåˆ—æ›´æ–° (Sequential)&lt;/strong&gt; |
| &lt;strong&gt;ç†è®ºä¿è¯&lt;/strong&gt; | æ— å•è°ƒæå‡ä¿è¯ (å¯èƒ½éœ‡è¡) | &lt;strong&gt;æœ‰å•è°ƒæå‡ä¿è¯&lt;/strong&gt; |
| &lt;strong&gt;å‚æ•°å…±äº«&lt;/strong&gt; | å¼ºçƒˆä¾èµ– (Parameter Sharing) | &lt;strong&gt;ä¸éœ€è¦&lt;/strong&gt; (å¤©ç”Ÿæ”¯æŒå¼‚æ„) |
| &lt;strong&gt;ä¼˜åŠ¿è®¡ç®—&lt;/strong&gt; | $A(s, a^i)$ (å‡è®¾é˜Ÿå‹ä¸å˜) | $A(s, a^i, a^1, ..., a^{i-1})$ (è€ƒè™‘é˜Ÿå‹æ›´æ–°) |
| &lt;strong&gt;é€‚ç”¨åœºæ™¯&lt;/strong&gt; | åŒè´¨æ™ºèƒ½ä½“ (å¦‚æ˜Ÿé™…äº‰éœ¸å°ç‹—æµ·) | &lt;strong&gt;å¼‚æ„æ™ºèƒ½ä½“&lt;/strong&gt; (å¦‚ç‰§ç¾ŠçŠ¬ä¸ç¾Šã€ä¸åŒç±»å‹çš„æœºå™¨äºº) |
| &lt;strong&gt;è®¡ç®—é‡&lt;/strong&gt; | è¾ƒå° | ç¨å¤§ (å› ä¸ºè¦ä¸²è¡Œè®¡ç®—) |&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;æ€»ç»“&lt;/h2&gt;
&lt;p&gt;HAPPO ç³»åˆ—ç®—æ³•åœ¨ MARL é¢†åŸŸå…·æœ‰é‡è¦çš„ç†è®ºåœ°ä½ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;è§£å†³äº† Heterogeneous (å¼‚æ„) é—®é¢˜&lt;/strong&gt;ï¼šä»¥å‰çš„ç®—æ³•ï¼ˆå¦‚ QMIX, MAPPOï¼‰é€šå¸¸å‡è®¾æ™ºèƒ½ä½“å…±äº«å‚æ•°ä»¥åŠ é€Ÿæ”¶æ•›ã€‚HAPPO è¯æ˜äº†å³ä½¿æ¯ä¸ªæ™ºèƒ½ä½“ç»“æ„å®Œå…¨ä¸åŒï¼ˆå¼‚æ„ï¼‰ï¼Œåªè¦æŒ‰é¡ºåºæ›´æ–°ï¼Œä¹Ÿèƒ½é«˜æ•ˆåä½œã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è§£å†³äº† Trust Region é—®é¢˜&lt;/strong&gt;ï¼šå®ƒå°†å•æ™ºèƒ½ä½“çš„â€œä¿¡ä»»åŒºåŸŸâ€æ¦‚å¿µæˆåŠŸæ¨å¹¿åˆ°äº†å¤šæ™ºèƒ½ä½“ï¼Œè§£å†³äº†å¤šæ™ºèƒ½ä½“åŒæ—¶æ›´æ–°å¯¼è‡´çš„&lt;strong&gt;ç¯å¢ƒéå¹³ç¨³&lt;/strong&gt;å’Œ&lt;strong&gt;ä¿¡åº¦åˆ†é…&lt;/strong&gt;éš¾é¢˜ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;å¦‚æœä½ é¢å¯¹çš„ä»»åŠ¡ä¸­ï¼Œæ™ºèƒ½ä½“å„ä¸ç›¸åŒï¼ˆä¾‹å¦‚ä¸€ä¸ªæ— äººæœºé…åˆä¸€ä¸ªåœ°é¢è½¦ï¼‰ï¼Œä¸”åä½œæå…¶å¤æ‚ï¼ŒHAPPO å¾€å¾€æ¯” MAPPO è¡¨ç°æ›´ç¨³å¥ã€‚&lt;/p&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-4.1ziqble6oe.webp"/><enclosure url="https://pic.hana0721.top/rl-note-4.1ziqble6oe.webp"/></item><item><title>claude ä¸­ä½¿ç”¨ GLM</title><link>https://claudiakim6827362.github.io/blog/paper-reading-eba1</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/paper-reading-eba1</guid><description>claude ä¸­ä½¿ç”¨ GLM</description><pubDate>Fri, 26 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;blockquote&gt;
&lt;p&gt;å‚è€ƒï¼š
é‡ç‚¹å‚è€ƒå®˜æ–¹ï¼š&lt;a href=&quot;https://claude.ai/docs/code&quot;&gt;claude code å®˜æ–¹æ–‡æ¡£&lt;/a&gt;, &lt;a href=&quot;https://docs.bigmodel.cn/cn/guide/develop/claude&quot;&gt;GLM å®˜æ–¹æ–‡æ¡£&lt;/a&gt;
ç¬¬ä¸‰æ–¹ï¼š&lt;a href=&quot;https://zhuanlan.zhihu.com/p/1957370685748938170&quot;&gt;claude code + GLMï¼Œä¿å§†çº§é…ç½®æ•™ç¨‹&lt;/a&gt;, &lt;a href=&quot;https://lutaonan.com/blog/glm-with-claude-code/&quot;&gt;åœ¨Claude Codeä¸­ä½¿ç”¨GLM 4.6çš„ä½“éªŒ&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;ä½¿ç”¨ Homebrew å®‰è£… claude code&lt;/p&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-3.3yex1xdpri.webp"/><enclosure url="https://pic.hana0721.top/rl-note-3.3yex1xdpri.webp"/></item><item><title>RLç¬”è®°ï¼ˆ25ï¼‰ï¼šå¤šæ™ºèƒ½ä½“ç­–ç•¥æ¢¯åº¦ (MADDPG &amp; MAPPO)</title><link>https://claudiakim6827362.github.io/blog/rl-note-25</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/rl-note-25</guid><description>ä»è¿ç»­æ§åˆ¶åˆ°ç¦»æ•£åšå¼ˆï¼šè¯¦è§£ CTDE æ¶æ„åœ¨ Actor-Critic ä¸­çš„åº”ç”¨ã€‚æ¶µç›– MADDPG çš„å¤šé¢æ‰‹ Critic è®¾è®¡ä¸ MAPPO çš„å·¥ç¨‹åŒ–èƒœåˆ©ã€‚</description><pubDate>Sat, 03 Jan 2026 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;å¼•è¨€ï¼šActor-Critic çš„ç¾¤ä½“è¿›åŒ–&lt;/h2&gt;
&lt;p&gt;æˆ‘ä»¬åœ¨ä¹‹å‰çš„ç¬”è®°ä¸­å­¦ä¹ äº† &lt;strong&gt;CTDE (ä¸­å¿ƒåŒ–è®­ç»ƒï¼Œåˆ†å¸ƒå¼æ‰§è¡Œ)&lt;/strong&gt; çš„æ€æƒ³ã€‚åœ¨ Value-Based æ–¹æ³•ï¼ˆå¦‚ QMIXï¼‰ä¸­ï¼ŒCTDE ä½“ç°åœ¨å°† $Q_{tot}$ åˆ†è§£ä¸º $Q_i$ã€‚&lt;/p&gt;
&lt;p&gt;è€Œåœ¨ &lt;strong&gt;Actor-Critic&lt;/strong&gt; æ¶æ„ä¸­ï¼ŒCTDE çš„å®ç°æ›´åŠ ç›´è§‚ä¸”çµæ´»ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Actor (ç­–ç•¥)&lt;/strong&gt;ï¼šå¿…é¡»æ˜¯&lt;strong&gt;å±€éƒ¨&lt;/strong&gt;çš„ ($\pi(a_i|o_i)$)ï¼Œå› ä¸ºæ‰§è¡Œæ—¶åªèƒ½é è‡ªå·±ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Critic (ä»·å€¼)&lt;/strong&gt;ï¼šå¿…é¡»æ˜¯&lt;strong&gt;å…¨å±€&lt;/strong&gt;çš„ ($Q(s, \mathbf{a})$ æˆ– $V(s)$)ï¼Œå› ä¸ºè®­ç»ƒæ—¶æˆ‘ä»¬å¯ä»¥åˆ©ç”¨ä¸Šå¸è§†è§’æ¥æ›´å‡†åœ°è¯„ä¼°å±€åŠ¿ï¼Œä»è€ŒæŒ‡å¯¼ Actorã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;æœ¬ç« å°†ä»‹ç»è¿™ä¸€èŒƒå¼ä¸‹çš„ä¸¤ä¸ªé‡Œç¨‹ç¢‘ç®—æ³•ï¼šé’ˆå¯¹è¿ç»­åŠ¨ä½œçš„ &lt;strong&gt;MADDPG&lt;/strong&gt; å’Œç›®å‰æœ€å¼ºçš„ Baseline &lt;strong&gt;MAPPO&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;MADDPG (Multi-Agent DDPG)&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;è®ºæ–‡&lt;/strong&gt;ï¼š&lt;a href=&quot;https://arxiv.org/abs/1706.02275&quot;&gt;Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;MADDPG æ˜¯ DDPG ç®—æ³•åœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸‹çš„è‡ªç„¶å»¶ä¼¸ï¼Œç”± OpenAI åœ¨ 2017 å¹´æå‡ºã€‚å®ƒä¸»è¦è§£å†³äº†&lt;strong&gt;éå¹³ç¨³æ€§&lt;/strong&gt;é—®é¢˜ã€‚&lt;/p&gt;
&lt;h3&gt;æ ¸å¿ƒæ€æƒ³ï¼šCritic çŸ¥é“ä¸€åˆ‡&lt;/h3&gt;
&lt;p&gt;åœ¨ç‹¬ç«‹å­¦ä¹ ï¼ˆIndependent DDPGï¼‰ä¸­ï¼ŒCritic åªè¾“å…¥ $(o_i, a_i)$ã€‚å½“é˜Ÿå‹ $j$ çš„ç­–ç•¥ $\pi_j$ æ”¹å˜æ—¶ï¼Œç¯å¢ƒå¯¹ $i$ æ¥è¯´å°±å˜äº†ï¼Œå¯¼è‡´ Critic éœ‡è¡ã€‚&lt;/p&gt;
&lt;p&gt;MADDPG æå‡ºï¼š&lt;strong&gt;Critic åº”è¯¥è¾“å…¥æ‰€æœ‰äººçš„åŠ¨ä½œ&lt;/strong&gt;ã€‚
$$ Q_i^{\boldsymbol{\pi}}(s, a_1, \dots, a_N) $$
åªè¦è¾“å…¥äº†è”åˆåŠ¨ä½œ $\mathbf{a} = (a_1, \dots, a_N)$ï¼Œç¯å¢ƒçš„çŠ¶æ€è½¬ç§» $P(s&apos;|s, \mathbf{a})$ å°±æ˜¯ç”±ç‰©ç†è§„å¾‹å†³å®šçš„ï¼Œæ˜¯&lt;strong&gt;å¹³ç¨³ (Stationary)&lt;/strong&gt; çš„ã€‚&lt;/p&gt;
&lt;h3&gt;æ¶æ„è®¾è®¡&lt;/h3&gt;
&lt;p&gt;å¯¹äº $N$ ä¸ªæ™ºèƒ½ä½“ï¼Œæ¯ä¸ªæ™ºèƒ½ä½“ $i$ ç»´æŠ¤ä¸¤ä¸ªç½‘ç»œï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Actor $\mu_{\theta_i}(o_i)$&lt;/strong&gt;ï¼š
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;è¾“å…¥&lt;/strong&gt;ï¼šä»…å±€éƒ¨è§‚æµ‹ $o_i$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è¾“å‡º&lt;/strong&gt;ï¼šç¡®å®šæ€§åŠ¨ä½œ $a_i$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç‰¹ç‚¹&lt;/strong&gt;ï¼šæ‰§è¡Œæ—¶å®Œå…¨ç‹¬ç«‹ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Critic $Q_{\phi_i}(s, a_1, \dots, a_N)$&lt;/strong&gt;ï¼š
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;è¾“å…¥&lt;/strong&gt;ï¼šå…¨å±€çŠ¶æ€ $s$ï¼ˆæˆ–æ‰€æœ‰äººçš„è§‚æµ‹ï¼‰ + &lt;strong&gt;æ‰€æœ‰äººçš„åŠ¨ä½œ&lt;/strong&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è¾“å‡º&lt;/strong&gt;ï¼šæ ‡é‡ Q å€¼ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç‰¹ç‚¹&lt;/strong&gt;ï¼šä»…åœ¨è®­ç»ƒæ—¶ä½¿ç”¨ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;è®­ç»ƒæµç¨‹&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Critic æ›´æ–°&lt;/strong&gt;ï¼šæœ€å°åŒ–è´å°”æ›¼è¯¯å·®ã€‚
$$ y = r_i + \gamma Q_i&apos;(s&apos;, a&apos;_1, \dots, a&apos;&lt;em&gt;N)|&lt;/em&gt;{a&apos;_j = \mu&apos;_j(o&apos;_j)} $$
æ³¨æ„ï¼šè®¡ç®—ç›®æ ‡å€¼æ—¶ï¼Œéœ€è¦ç”¨åˆ°&lt;strong&gt;æ¯ä¸ªæ™ºèƒ½ä½“çš„ Target Actor&lt;/strong&gt; æ¥é¢„æµ‹ä¸‹ä¸€æ­¥åŠ¨ä½œã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Actor æ›´æ–°&lt;/strong&gt;ï¼šç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦ã€‚
$$ \nabla_{\theta_i} J = \mathbb{E} [\nabla_{a_i} Q_i(s, a_1, \dots, a_N)|&lt;em&gt;{a_i=\mu_i(o_i)} \cdot \nabla&lt;/em&gt;{\theta_i} \mu_i(o_i)] $$
æ³¨æ„ï¼šCritic å¯¹ $a_i$ æ±‚å¯¼ï¼Œå‘Šè¯‰ Actor $i$ å¦‚ä½•è°ƒæ•´åŠ¨ä½œèƒ½æé«˜é›†ä½“ï¼ˆæˆ–ä¸ªäººï¼‰æ”¶ç›Šã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;ä¼˜ç¼ºç‚¹&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜ç‚¹&lt;/strong&gt;ï¼šå¯ä»¥å¤„ç†è¿ç»­åŠ¨ä½œï¼›é€‚ç”¨äºåˆä½œã€ç«äº‰æˆ–æ··åˆä»»åŠ¡ï¼ˆæ¯ä¸ª Critic å¯ä»¥æœ€å¤§åŒ–ä¸åŒçš„å¥–åŠ± $r_i$ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç¼ºç‚¹&lt;/strong&gt;ï¼šCritic çš„è¾“å…¥ç»´åº¦éšäººæ•°çº¿æ€§å¢é•¿ï¼Œéš¾ä»¥æ‰©å±•åˆ°å¤§è§„æ¨¡é›†ç¾¤ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;MAPPO (Multi-Agent PPO)&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;è®ºæ–‡&lt;/strong&gt;ï¼š&lt;a href=&quot;https://arxiv.org/abs/2103.01955&quot;&gt;The Surprising Effectiveness of PPO in Cooperative Multi-Agent Games&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;é•¿æœŸä»¥æ¥ï¼Œäººä»¬è®¤ä¸º Off-Policyï¼ˆå¦‚ MADDPG/QMIXï¼‰åœ¨ MARL ä¸­æ›´é«˜æ•ˆã€‚ä½† MAPPO (2021) è¯æ˜ï¼š&lt;strong&gt;åªè¦è°ƒå‚å¾—å½“ï¼Œç®€å•çš„ On-Policy PPO ä¹Ÿèƒ½åŠæ‰“å¤æ‚çš„ Off-Policy ç®—æ³•ã€‚&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;æ ¸å¿ƒæ€æƒ³ï¼šCentralized Value Function&lt;/h3&gt;
&lt;p&gt;MAPPO çš„ç»“æ„æå…¶ç®€å•ï¼Œå°±æ˜¯ PPO + CTDEã€‚
å®ƒä¸ IPPOï¼ˆç‹¬ç«‹ PPOï¼‰å”¯ä¸€çš„åŒºåˆ«åœ¨äº &lt;strong&gt;Critic&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;IPPO Critic&lt;/strong&gt;: $V(o_i)$ â€”â€” åªçœ‹è‡ªå·±ï¼Œä¸ä»…è§†é‡çª„ï¼Œè€Œä¸”å—é˜Ÿå‹ç­–ç•¥å˜åŒ–å¹²æ‰°ä¸¥é‡ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MAPPO Critic&lt;/strong&gt;: $V(s)$ â€”â€” &lt;strong&gt;çœ‹å…¨å±€&lt;/strong&gt;ã€‚Critic å­¦ä¹ çš„æ˜¯å…¨å±€çŠ¶æ€ä»·å€¼å‡½æ•°ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;ä¸ºä»€ä¹ˆ $V(s)$ æ¯” $Q(s, \mathbf{a})$ å¥½ï¼Ÿ&lt;/h3&gt;
&lt;p&gt;MADDPG ä½¿ç”¨ $Q(s, \mathbf{a})$ï¼Œè¿™éœ€è¦è¾“å…¥å·¨å¤§çš„è”åˆåŠ¨ä½œç©ºé—´ã€‚
MAPPO ä½¿ç”¨ $V(s)$ æ¥è®¡ç®—ä¼˜åŠ¿å‡½æ•°ï¼š
$$ \hat{A}&lt;em&gt;i(t) = \sum (\gamma \lambda)^l (r&lt;/em&gt;{i, t+l} + \gamma V(s_{t+1+l}) - V(s_{t+l})) $$ã€‚
$V(s)$ ä¸éœ€è¦è¾“å…¥åŠ¨ä½œï¼Œç»´åº¦ä½ï¼Œè®­ç»ƒæ›´å®¹æ˜“æ”¶æ•›ã€‚&lt;/p&gt;
&lt;h3&gt;æˆåŠŸçš„å…³é”®ï¼šå·¥ç¨‹æŠ€å·§ (Implementation Matters)&lt;/h3&gt;
&lt;p&gt;MAPPO çš„æˆåŠŸä¸ä»…ä»…åœ¨äºç®—æ³•ï¼Œæ›´åœ¨äº 5 ä¸ªå…³é”®çš„å·¥ç¨‹å®è·µï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;è¾“å…¥ç‰¹å¾å¤„ç†&lt;/strong&gt;ï¼šå°† Agent ID ä½œä¸º One-hot å‘é‡æ‹¼æ¥åˆ°çŠ¶æ€ä¸­ï¼ˆåœ¨å‚æ•°å…±äº«æ—¶åŒºåˆ†ä¸åŒä¸ªä½“ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å‚æ•°å…±äº« (Parameter Sharing)&lt;/strong&gt;ï¼šæ‰€æœ‰æ™ºèƒ½ä½“å…±ç”¨ä¸€ä¸ª Actor å’Œä¸€ä¸ª Critic ç½‘ç»œï¼ˆé€‚ç”¨äºåŒè´¨æ™ºèƒ½ä½“ï¼‰ï¼Œæå¤§åŠ é€Ÿæ”¶æ•›ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PopArt&lt;/strong&gt;ï¼šå¯¹ Critic çš„ç›®æ ‡å€¼ï¼ˆValue Targetï¼‰è¿›è¡Œ&lt;strong&gt;å½’ä¸€åŒ–&lt;/strong&gt;ï¼Œå¤„ç†å¥–åŠ±å°ºåº¦å·®å¼‚å¤§çš„é—®é¢˜ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ•°æ®å¹¶è¡Œ&lt;/strong&gt;ï¼šä½¿ç”¨å¤šä¸ªå¹¶è¡Œç¯å¢ƒæ”¶é›†æ•°æ®ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è£å‰ª (Clipping)&lt;/strong&gt;ï¼šPPO æœ¬èº«çš„ Clip æœºåˆ¶æœ‰æ•ˆé˜²æ­¢äº†éå¹³ç¨³ç¯å¢ƒä¸‹çš„ç­–ç•¥å´©å¡Œã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2&gt;æ·±åº¦å¯¹æ¯”ï¼šMADDPG vs. MAPPO&lt;/h2&gt;
&lt;p&gt;| ç»´åº¦ | MADDPG | MAPPO |
| :--- | :--- | :--- |
| &lt;strong&gt;åŸºç¡€ç®—æ³•&lt;/strong&gt; | DDPG (Off-Policy) | PPO (On-Policy) |
| &lt;strong&gt;ç­–ç•¥ç±»å‹&lt;/strong&gt; | ç¡®å®šæ€§ ($\mu(o)$) | éšæœºæ€§ ($\pi(a|o)$) |
| &lt;strong&gt;åŠ¨ä½œç©ºé—´&lt;/strong&gt; | &lt;strong&gt;è¿ç»­&lt;/strong&gt; (æ“…é•¿) | è¿ç»­ &amp;#x26; ç¦»æ•£ (éƒ½æ“…é•¿) |
| &lt;strong&gt;Critic å½¢å¼&lt;/strong&gt; | $Q(s, a_1, \dots, a_N)$ | $V(s)$ |
| &lt;strong&gt;é€šä¿¡éœ€æ±‚&lt;/strong&gt; | è®­ç»ƒæ—¶éœ€çŸ¥æ™“ä»–äººåŠ¨ä½œ | è®­ç»ƒæ—¶éœ€çŸ¥æ™“å…¨å±€çŠ¶æ€ |
| &lt;strong&gt;æ ·æœ¬æ•ˆç‡&lt;/strong&gt; | è¾ƒé«˜ (Replay Buffer) | è¾ƒä½ (éœ€å¤§é‡é‡‡æ ·) |
| &lt;strong&gt;ç¨³å®šæ€§&lt;/strong&gt; | è¾ƒå·® (è¶…å‚æ•°æ•æ„Ÿ) | &lt;strong&gt;æé«˜&lt;/strong&gt; (é²æ£’æ€§å¼º) |
| &lt;strong&gt;SOTA è¡¨ç°&lt;/strong&gt; | æ—©æœŸåŸºå‡† | ç›®å‰ SMAC ç­‰ç¯å¢ƒçš„ä¸»æµå¼ºåŸºå‡† |&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;æ€»ç»“&lt;/h2&gt;
&lt;p&gt;å¤šæ™ºèƒ½ä½“ç­–ç•¥æ–¹æ³•çš„å‘å±•ç»å†äº†ä»â€œå„è‡ªä¸ºæˆ˜â€åˆ°â€œå…¨å±€ååŒâ€çš„è¿‡ç¨‹ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;MADDPG&lt;/strong&gt; è§£å†³äº†è¿ç»­åŠ¨ä½œä¸‹çš„å¤šæ™ºèƒ½ä½“åšå¼ˆé—®é¢˜ï¼Œé€šè¿‡å°†â€œé˜Ÿå‹çš„åŠ¨ä½œâ€æ˜¾å¼è¾“å…¥ Criticï¼Œåœ¨æ•°å­¦ä¸Šæ¢å¤äº†å¹³ç¨³æ€§ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MAPPO&lt;/strong&gt; åˆ™å±•ç¤ºäº†â€œå¤§é“è‡³ç®€â€çš„åŠ›é‡ï¼Œè¯æ˜äº†é€šè¿‡å¼•å…¥å…¨å±€ä»·å€¼å‡½æ•° $V(s)$ å¹¶é…åˆä¼˜ç§€çš„å·¥ç¨‹å®ç°ï¼ŒOn-Policy ç®—æ³•ä¹Ÿèƒ½åœ¨å¤æ‚çš„åä½œä»»åŠ¡ä¸­è¾¾åˆ° SOTA æ°´å¹³ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;è‡³æ­¤ï¼Œæˆ‘ä»¬å·²ç»æ¶µç›–äº† MARL çš„ä¸¤å¤§ä¸»æµæµæ´¾ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Value-Based&lt;/strong&gt;: QMIX, QPLEX (é€‚åˆç¦»æ•£åŠ¨ä½œï¼Œå¼ºæ˜¾å¼åä½œ)ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Policy-Based&lt;/strong&gt;: MADDPG, MAPPO (é€‚åˆè¿ç»­åŠ¨ä½œï¼Œé€šç”¨æ€§å¼º)ã€‚&lt;/li&gt;
&lt;/ol&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-4.1ziqble6oe.webp"/><enclosure url="https://pic.hana0721.top/rl-note-4.1ziqble6oe.webp"/></item><item><title>RLç¬”è®°ï¼ˆ24ï¼‰ï¼šè¶…è¶Šå•è°ƒæ€§ (QTRAN, WQMIX, QPLEX)</title><link>https://claudiakim6827362.github.io/blog/rl-note-24</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/rl-note-24</guid><description>æ‰“ç ´ QMIX çš„æ·é”ï¼šè¯¦è§£ QTRANã€Weighted QMIX å’Œ QPLEX å¦‚ä½•çªç ´å•è°ƒæ€§çº¦æŸã€‚æ¶µç›–è½¯çº¦æŸæ¾å¼›ã€éå¯¹ç§°åŠ æƒæŠ•å½±åŠå¯¹å¶å¯¹å†³æ¶æ„çš„å®Œå…¨è¡¨è¾¾èƒ½åŠ›è¯æ˜ã€‚</description><pubDate>Fri, 02 Jan 2026 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;å¼•è¨€ï¼ˆIntroductionï¼‰&lt;/h2&gt;
&lt;p&gt;åœ¨ä¸Šä¸€ç« ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº† &lt;strong&gt;QMIX&lt;/strong&gt;ï¼Œå®ƒé€šè¿‡å¼ºåˆ¶æ··åˆç½‘ç»œçš„æƒé‡éè´Ÿï¼Œå®ç°äº†å¯¹ IGM åŸåˆ™çš„å•è°ƒæ€§è¿‘ä¼¼ã€‚
ç„¶è€Œï¼Œå•è°ƒæ€§æ˜¯ä¸€ä¸ª&lt;strong&gt;å……åˆ†éå¿…è¦æ¡ä»¶&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å±€é™æ€§&lt;/strong&gt;ï¼šQMIX æ— æ³•è¡¨ç¤ºéå•è°ƒçš„åä½œä»»åŠ¡ï¼ˆä¾‹å¦‚ï¼šæ™ºèƒ½ä½“ A å’Œ B å¿…é¡»åŒæ—¶åšåŠ¨ä½œ X æ‰èƒ½å¾—åˆ†ï¼Œå•ç‹¬åšåè€Œæ‰£åˆ†ã€‚è¿™ç§â€œå¼‚æˆ–â€é€»è¾‘è¿åäº†å•è°ƒæ€§ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æŒ‘æˆ˜&lt;/strong&gt;ï¼šæˆ‘ä»¬éœ€è¦ä¸€ç§æ–¹æ³•ï¼Œæ—¢èƒ½æ»¡è¶³ IGM åŸåˆ™ï¼ˆä¿è¯åˆ†å¸ƒå¼æ‰§è¡Œï¼‰ï¼Œåˆèƒ½è¦†ç›–&lt;strong&gt;æ‰€æœ‰&lt;/strong&gt;å¯èƒ½çš„è”åˆä»·å€¼å‡½æ•°ç©ºé—´ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;æœ¬ç« å°†ä»‹ç»ä¸‰ç§è¯•å›¾çªç ´ QMIX å¤©èŠ±æ¿çš„è¿›é˜¶ç®—æ³•ï¼š&lt;strong&gt;QTRAN&lt;/strong&gt;ï¼ˆåŸºäºå˜æ¢ï¼‰ã€&lt;strong&gt;WQMIX&lt;/strong&gt;ï¼ˆåŸºäºåŠ æƒï¼‰å’Œ &lt;strong&gt;QPLEX&lt;/strong&gt;ï¼ˆåŸºäºä¼˜åŠ¿å‡½æ•°ï¼‰ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;QTRAN: Learning to Factorize with Transformation&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;è®ºæ–‡&lt;/strong&gt;ï¼š&lt;a href=&quot;https://arxiv.org/abs/1905.05408&quot;&gt;QTRAN: Learning to Factorize with Transformation for Cooperative MARL&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;æ ¸å¿ƒæ€æƒ³ï¼šå˜æ¢ä¸æ¾å¼›&lt;/h3&gt;
&lt;p&gt;QTRAN è®¤ä¸ºï¼Œç›´æ¥å­¦ä¹ ä¸€ä¸ªæ»¡è¶³ IGM çš„ $Q_{tot}$ å¤ªéš¾äº†ã€‚
ä¸å¦‚æˆ‘ä»¬å°† $Q_{tot}$ æ‹†è§£ä¸ºä¸¤éƒ¨åˆ†ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;$Q&apos;_{tot}$&lt;/strong&gt;ï¼šä¸€ä¸ªæ˜“äºåˆ†è§£çš„éƒ¨åˆ†ï¼ˆå¦‚ VDN çš„æ±‚å’Œå½¢å¼ï¼‰ï¼Œç”¨äºæŒ‡å¯¼åŠ¨ä½œé€‰æ‹©ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;$V_{tot}$&lt;/strong&gt;ï¼šä¸€ä¸ªçŠ¶æ€ä»·å€¼ä¿®æ­£é¡¹ï¼Œç”¨äºè¡¥è¶³æ®‹å·®ï¼Œç¡®ä¿é€¼è¿‘çœŸå®çš„ $Q^*$ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;æ•°å­¦æ„é€ &lt;/h3&gt;
&lt;p&gt;æˆ‘ä»¬å®šä¹‰å˜æ¢åçš„ç›®æ ‡å‡½æ•°ï¼š
$$
Q_{tot}(s, \mathbf{u}) \approx Q&apos;&lt;em&gt;{tot}(s, \mathbf{u}) + V&lt;/em&gt;{tot}(s, \mathbf{u})
$$
å…¶ä¸­ $Q&apos;&lt;em&gt;{tot}(s, \mathbf{u}) = \sum&lt;/em&gt;{i=1}^n Q_i(u_i)$ æ˜¯æˆ‘ä»¬å®é™…ç”¨æ¥é€‰åŠ¨ä½œçš„å‡½æ•°ã€‚&lt;/p&gt;
&lt;p&gt;ä¸ºäº†ä¿è¯ $\arg\max Q&apos;&lt;em&gt;{tot} = \arg\max Q&lt;/em&gt;{tot}$ï¼ˆIGM åŸåˆ™ï¼‰ï¼ŒQTRAN æ¨å¯¼å‡ºäº†ä¸€ç»„å……åˆ†æ¡ä»¶ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;æœ€ä¼˜åŠ¨ä½œä¸€è‡´æ€§&lt;/strong&gt;ï¼šåœ¨æœ€ä¼˜åŠ¨ä½œ $\bar{\mathbf{u}}$ å¤„ï¼Œä¸¤è€…ç›¸ç­‰ã€‚
$$ Q&apos;&lt;em&gt;{tot}(\bar{\mathbf{u}}) - Q&lt;/em&gt;{tot}(\bar{\mathbf{u}}) + V_{tot}(\bar{\mathbf{u}}) = 0 $$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;éæœ€ä¼˜åŠ¨ä½œç•Œé™&lt;/strong&gt;ï¼šåœ¨éæœ€ä¼˜åŠ¨ä½œ $\mathbf{u}$ å¤„ï¼Œ$Q&apos;&lt;em&gt;{tot}$ ä¸ä¼šâ€œç¯¡ä½â€ã€‚
$$ Q&apos;&lt;/em&gt;{tot}(\mathbf{u}) - Q_{tot}(\mathbf{u}) + V_{tot}(\mathbf{u}) \ge 0 $$&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;æŸå¤±å‡½æ•°è®¾è®¡&lt;/h3&gt;
&lt;p&gt;QTRAN å°†ä¸Šè¿°ç¡¬çº¦æŸè½¬åŒ–ä¸ºè½¯æŸè€—ï¼ˆSoft Constraintsï¼‰åŠ å…¥è®­ç»ƒï¼š
$$
L_{opt} = (Q&apos;&lt;em&gt;{tot}(\bar{\mathbf{u}}) - y&lt;/em&gt;{target})^2 + \lambda \sum_{\mathbf{u} \in \mathcal{U}, \mathbf{u} \ne \bar{\mathbf{u}}} (Q&apos;&lt;em&gt;{tot}(\mathbf{u}) - Q&lt;/em&gt;{tot}(\mathbf{u}) + V_{tot}(\mathbf{u}))^2
$$&lt;/p&gt;
&lt;h3&gt;æ€»ç»“&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜ç‚¹&lt;/strong&gt;ï¼šç†è®ºä¸Šå…·æœ‰å®Œå…¨çš„è¡¨è¾¾èƒ½åŠ› (Full Expressiveness)ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç¼ºç‚¹&lt;/strong&gt;ï¼šå®é™…è®­ç»ƒä¸­ï¼Œè½¯çº¦æŸå¾ˆéš¾è¢«å®Œç¾æ»¡è¶³ï¼Œä¸”è®¡ç®—é‡å·¨å¤§ï¼ˆæ¶‰åŠæ‰€æœ‰åŠ¨ä½œç©ºé—´çš„æ±‚å’Œï¼‰ã€‚åœ¨å¤æ‚ä»»åŠ¡ä¸Šè¡¨ç°å¾€å¾€ä¸å¦‚ QMIXã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;Weighted QMIX (WQMIX)&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;è®ºæ–‡&lt;/strong&gt;ï¼š&lt;a href=&quot;https://arxiv.org/abs/2006.10800&quot;&gt;Weighted QMIX: Expanding Monotonic Value Function Factorisation&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;æ ¸å¿ƒæ€æƒ³ï¼šéå¯¹ç§°åŠ æƒ&lt;/h3&gt;
&lt;p&gt;WQMIX æŒ‡å‡º QMIX çš„æ ¸å¿ƒé—®é¢˜æ˜¯ &lt;strong&gt;ç›¸å¯¹è¿‡æ³›åŒ– (Relative Overgeneralization)&lt;/strong&gt;ï¼šä¸ºäº†æ‹ŸåˆæŸäº›éæœ€ä¼˜çš„ä½åˆ†åŠ¨ä½œï¼Œæ¨¡å‹è¢«è¿«æ‹‰ä½äº†æœ€ä¼˜åŠ¨ä½œçš„ Q å€¼ã€‚&lt;/p&gt;
&lt;p&gt;WQMIX æå‡ºï¼š&lt;strong&gt;æˆ‘ä»¬å…¶å®ä¸åœ¨ä¹éæœ€ä¼˜åŠ¨ä½œçš„ Q å€¼å‡†ä¸å‡†ï¼Œæˆ‘ä»¬åªåœ¨ä¹æœ€ä¼˜åŠ¨ä½œçš„ Q å€¼å‡†ä¸å‡†ã€‚&lt;/strong&gt;
å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ç»™æœ€ä¼˜æ ·æœ¬èµ‹äºˆæé«˜çš„æƒé‡ã€‚&lt;/p&gt;
&lt;h3&gt;ç®—æ³•æ¶æ„&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;æ— é™åˆ¶ç½‘ç»œ $\hat{Q}^*$&lt;/strong&gt;ï¼šä½¿ç”¨ä¸€ä¸ªæ™®é€šçš„å‰é¦ˆç½‘ç»œï¼ˆä¸åŠ ç»å¯¹å€¼çº¦æŸï¼‰æ¥ä¼°è®¡çœŸå®çš„è”åˆ Q å€¼ã€‚è¿™ä¿è¯äº†è¡¨è¾¾èƒ½åŠ›ï¼Œä½†ä¸æ»¡è¶³ IGMã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å•è°ƒç½‘ç»œ $Q_{tot}$&lt;/strong&gt;ï¼šä½¿ç”¨æ ‡å‡†çš„ QMIX ç»“æ„ï¼ˆæ»¡è¶³ IGMï¼‰ï¼Œç”¨æ¥åšç­–ç•¥æ‰§è¡Œã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åŠ æƒæŠ•å½±&lt;/strong&gt;ï¼šé€šè¿‡åŠ æƒ Loss å¼ºè¡Œè®© $Q_{tot}$ å»é€¼è¿‘ $\hat{Q}^*$ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;æŸå¤±å‡½æ•°&lt;/h3&gt;
&lt;p&gt;$$
\mathcal{L} = \sum_{i=1}^b w(s, \mathbf{u}) \left( \hat{Q}^*(s, \mathbf{u}) - Q_{tot}(s, \mathbf{u}) \right)^2
$$
æƒé‡å‡½æ•° $w$ çš„è®¾è®¡ä½“ç°äº†&lt;strong&gt;ä¹è§‚ä¸»ä¹‰&lt;/strong&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å¦‚æœ $\hat{Q}^*$ è®¤ä¸ºå½“å‰åŠ¨ä½œå¾ˆå¥½çš„ï¼ˆå¯èƒ½æ˜¯æ½œåœ¨çš„æœ€ä¼˜è§£ï¼‰ï¼Œç»™å¤§æƒé‡ $w=1$ã€‚&lt;/li&gt;
&lt;li&gt;å¦‚æœ $\hat{Q}^*$ è®¤ä¸ºå½“å‰åŠ¨ä½œå¾ˆå·®ï¼Œç»™å°æƒé‡ $w=\alpha \ll 1$ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;è¿™ä½¿å¾— $Q_{tot}$ å³ä½¿å—é™äºå•è°ƒæ€§ï¼Œä¹Ÿä¼šä¼˜å…ˆä¿è¯åœ¨æœ€ä¼˜åŠ¨ä½œé™„è¿‘çš„å½¢çŠ¶æ˜¯æ­£ç¡®çš„ï¼Œä»è€Œçªç ´äº†ç»“æ„ç“¶é¢ˆã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;QPLEX: Duplex Dueling Multi-Agent Q-Learning&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;è®ºæ–‡&lt;/strong&gt;ï¼š&lt;a href=&quot;https://arxiv.org/abs/2008.01062&quot;&gt;QPLEX: Duplex Dueling Multi-Agent Q-Learning&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;æ ¸å¿ƒæ€æƒ³ï¼šåŸºäºä¼˜åŠ¿çš„ IGM&lt;/h3&gt;
&lt;p&gt;QPLEX æ˜¯ç›®å‰çš„ SOTA æ–¹æ³•ä¹‹ä¸€ã€‚å®ƒå€Ÿé‰´äº† Dueling DQN çš„æ€æƒ³ï¼ŒæŒ‡å‡º IGM åŸåˆ™å…¶å®åªå…³ä¹ &lt;strong&gt;ä¼˜åŠ¿å‡½æ•° (Advantage)&lt;/strong&gt;ï¼Œä¸çŠ¶æ€ä»·å€¼ $V(s)$ æ— å…³ã€‚&lt;/p&gt;
&lt;p&gt;$$ Q_{tot}(s, \mathbf{u}) = V_{tot}(s) + A_{tot}(s, \mathbf{u}) $$&lt;/p&gt;
&lt;p&gt;åªè¦ä¿è¯ $A_{tot}$ å’Œå±€éƒ¨ $A_i$ åœ¨â€œæ­£è´Ÿå·â€ä¸Šçš„ä¸€è‡´æ€§ï¼Œå°±èƒ½æ»¡è¶³ IGMï¼Œè€Œä¸éœ€è¦é™åˆ¶æƒé‡çš„æ­£è´Ÿã€‚&lt;/p&gt;
&lt;h3&gt;æ•°å­¦æ„é€ &lt;/h3&gt;
&lt;p&gt;QPLEX æ„é€ äº†å¦‚ä¸‹å½¢å¼çš„è”åˆä¼˜åŠ¿å‡½æ•°ï¼š
$$
A_{tot}(s, \mathbf{u}) = \sum_{i=1}^n \lambda_i(s, \mathbf{u}) A_i(s, u_i)
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å…³é”®ç‚¹ï¼šåªè¦ç³»æ•° $\lambda_i(s, \mathbf{u}) &gt; 0$ï¼Œé‚£ä¹ˆ $A_{tot}$ çš„ç¬¦å·å°±ç”± $A_i$ å†³å®šã€‚
&lt;ul&gt;
&lt;li&gt;å¦‚æœæ‰€æœ‰ $u_i$ éƒ½æ˜¯å±€éƒ¨æœ€ä¼˜ï¼ˆ$A_i=0$ï¼‰ï¼Œé‚£ä¹ˆ $A_{tot}=0$ï¼ˆå…¨å±€æœ€ä¼˜ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;å¦‚æœæœ‰ä»»ä½•ä¸€ä¸ª $u_i$ ä¸æ˜¯æœ€ä¼˜ï¼ˆ$A_i &amp;#x3C; 0$ï¼‰ï¼Œé‚£ä¹ˆ $A_{tot} &amp;#x3C; 0$ï¼ˆå…¨å±€éæœ€ä¼˜ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;ç½‘ç»œæ¶æ„&lt;/h3&gt;
&lt;p&gt;QPLEX ä½¿ç”¨ &lt;strong&gt;å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ (Multi-Head Attention)&lt;/strong&gt; æ¥åŠ¨æ€ç”Ÿæˆæƒé‡ $\lambda_i$ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;è¿™ä¸ä»…ä¿è¯äº† $\lambda_i &gt; 0$ï¼Œè¿˜èµ‹äºˆäº†æ¨¡å‹æ ¹æ®å½“å‰çŠ¶æ€åŠ¨æ€è°ƒæ•´æ¯ä¸ªæ™ºèƒ½ä½“æƒé‡çš„èƒ½åŠ›ã€‚&lt;/li&gt;
&lt;li&gt;é€šè¿‡è¿™ç§ä¸¥æ ¼çš„æ•°å­¦æ„é€ ï¼ŒQPLEX åœ¨ç†è®ºä¸Šå®ç°äº†&lt;strong&gt;å®Œå…¨è¡¨è¾¾èƒ½åŠ›&lt;/strong&gt;ï¼ŒåŒæ—¶ä¿ç•™äº† VDN èˆ¬é«˜æ•ˆçš„è®¡ç®—æ•ˆç‡ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;æ€»ç»“ä¸å¯¹æ¯”&lt;/h2&gt;
&lt;p&gt;| ç®—æ³• | æ ¸å¿ƒæœºåˆ¶ | è¡¨è¾¾èƒ½åŠ› | IGM ä¿è¯ | è®¡ç®—å¤æ‚åº¦ |
| :--- | :--- | :--- | :--- | :--- |
| &lt;strong&gt;QMIX&lt;/strong&gt; | å•è°ƒæ€§çº¦æŸ (æƒé‡ $&gt;0$) | å—é™ (å•è°ƒç±») | ä¸¥æ ¼ | ä½ |
| &lt;strong&gt;QTRAN&lt;/strong&gt; | è½¯çº¦æŸæ¾å¼› + ç½šé¡¹ | å®Œå…¨ | è¿‘ä¼¼ (è½¯çº¦æŸ) | æé«˜ |
| &lt;strong&gt;WQMIX&lt;/strong&gt; | åŒç½‘ç»œ + éå¯¹ç§°åŠ æƒ | è¿‘ä¼¼å®Œå…¨ | ä¸¥æ ¼ (æŠ•å½±å) | ä¸­ |
| &lt;strong&gt;QPLEX&lt;/strong&gt; | ä¼˜åŠ¿åˆ†è§£ + æ³¨æ„åŠ›æƒé‡ | &lt;strong&gt;å®Œå…¨&lt;/strong&gt; | &lt;strong&gt;ä¸¥æ ¼ (æ•°å­¦æ„é€ )&lt;/strong&gt; | ä¸­ |&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;æ¼”è¿›è„‰ç»œ&lt;/strong&gt;ï¼š
ä» QMIX çš„â€œå‰Šè¶³é€‚å±¥â€ï¼ˆä¸ºäº† IGM ç‰ºç‰²è¡¨è¾¾èƒ½åŠ›ï¼‰ï¼Œåˆ° QPLEX çš„â€œé‡ä½“è£è¡£â€ï¼ˆé€šè¿‡ç²¾å·§çš„æ•°å­¦æ„é€ åŒæ—¶å®ç° IGM å’Œå®Œå…¨è¡¨è¾¾èƒ½åŠ›ï¼‰ï¼Œå€¼åˆ†è§£ç®—æ³•åœ¨ MARL é¢†åŸŸå·²ç»å‘å±•å¾—ç›¸å½“æˆç†Ÿã€‚&lt;/p&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-4.1ziqble6oe.webp"/><enclosure url="https://pic.hana0721.top/rl-note-4.1ziqble6oe.webp"/></item><item><title>RLç¬”è®°ï¼ˆ23ï¼‰ï¼šå¤šæ™ºèƒ½ä½“å€¼åˆ†è§£ (VDN &amp; QMIX)</title><link>https://claudiakim6827362.github.io/blog/rl-note-23</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/rl-note-23</guid><description>å¦‚ä½•åœ¨ä¸ç‰ºç‰²ç‹¬ç«‹å†³ç­–èƒ½åŠ›çš„å‰æä¸‹ï¼Œå®ç°å¤æ‚çš„åä½œï¼Ÿè¯¦è§£å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ä¸­çš„å€¼åˆ†è§£æµæ´¾ã€‚æ¶µç›– IGM åŸåˆ™ã€VDN çš„çº¿æ€§åˆ†è§£ä¸ QMIX çš„å•è°ƒæ€§çº¦æŸè®¾è®¡ã€‚</description><pubDate>Thu, 01 Jan 2026 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;å¼•è¨€ï¼ˆIntroductionï¼‰&lt;/h2&gt;
&lt;p&gt;åœ¨ä¸Šä¸€ç¯‡ç¬”è®°ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº† MARL çš„ä¸¤ç§æç«¯ï¼š&lt;strong&gt;JALï¼ˆå®Œå…¨ä¸­å¿ƒåŒ–ï¼‰&lt;/strong&gt; ç†è®ºå®Œç¾ä½†ä¸å¯è®¡ç®—ï¼Œ&lt;strong&gt;IPPOï¼ˆå®Œå…¨ç‹¬ç«‹ï¼‰&lt;/strong&gt; è®¡ç®—ç®€å•ä½†ç†è®ºæœ‰æ¯’ã€‚&lt;/p&gt;
&lt;p&gt;æˆ‘ä»¬éœ€è¦ä¸€ç§æŠ˜ä¸­æ–¹æ¡ˆï¼š&lt;strong&gt;CTDEï¼ˆä¸­å¿ƒåŒ–è®­ç»ƒï¼Œåˆ†å¸ƒå¼æ‰§è¡Œï¼‰&lt;/strong&gt;ã€‚
å¯¹äº Value-Based æ–¹æ³•æ¥è¯´ï¼ŒCTDE çš„æ ¸å¿ƒæŒ‘æˆ˜åœ¨äºï¼š&lt;strong&gt;å¦‚ä½•åˆ©ç”¨å…¨å±€ $Q_{tot}$ æ¥æŒ‡å¯¼å±€éƒ¨ $Q_i$ çš„æ›´æ–°ï¼ŒåŒæ—¶ç¡®ä¿å±€éƒ¨è´ªå©ªå†³ç­–èƒ½å¯¼è‡´å…¨å±€æœ€ä¼˜ï¼Ÿ&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;è¿™å°±æ˜¯ &lt;strong&gt;å€¼åˆ†è§£ (Value Decomposition)&lt;/strong&gt; ç®—æ³•çš„æ ¸å¿ƒä½¿å‘½ã€‚æœ¬ç« å°†ä»‹ç»è¿™ä¸€æµæ´¾çš„å¼€å±±ä¹‹ä½œ &lt;strong&gt;VDN&lt;/strong&gt; å’Œç»å…¸ä¹‹ä½œ &lt;strong&gt;QMIX&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;ç†è®ºåŸºçŸ³ï¼šDec-POMDP ä¸ IGM&lt;/h2&gt;
&lt;h3&gt;é—®é¢˜å½¢å¼åŒ–ï¼šDec-POMDP&lt;/h3&gt;
&lt;p&gt;æˆ‘ä»¬å°†å¤šæ™ºèƒ½ä½“åä½œä»»åŠ¡å»ºæ¨¡ä¸º &lt;strong&gt;å»ä¸­å¿ƒåŒ–éƒ¨åˆ†å¯è§‚æµ‹é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ (Dec-POMDP)&lt;/strong&gt;ã€‚
å…ƒç»„å®šä¹‰ä¸º $G = \langle \mathcal{S}, N, U, P, R, Z, O, \gamma \rangle$ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$s \in \mathcal{S}$ï¼šå…¨å±€çŠ¶æ€ã€‚&lt;/li&gt;
&lt;li&gt;$u_i \in U$ï¼šæ™ºèƒ½ä½“ $i$ çš„åŠ¨ä½œï¼Œè”åˆåŠ¨ä½œ $\mathbf{u} \in U^n$ã€‚&lt;/li&gt;
&lt;li&gt;$z_i \in Z$ï¼šæ™ºèƒ½ä½“ $i$ çš„å±€éƒ¨è§‚æµ‹ã€‚&lt;/li&gt;
&lt;li&gt;$\tau_i$ï¼šåŠ¨ä½œ-è§‚æµ‹å†å²ï¼ˆå› ä¸ºæ˜¯éƒ¨åˆ†å¯è§‚æµ‹ï¼Œæ™ºèƒ½ä½“éœ€è¦è®°ä½å†å²ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;$Q_{tot}(s, \mathbf{u})$ï¼šå…¨å±€è”åˆä»·å€¼å‡½æ•°ï¼Œä»£è¡¨é›†ä½“çš„åˆ©ç›Šã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;æ ¸å¿ƒåŸåˆ™ï¼šIGM (Individual-Global-Max)&lt;/h3&gt;
&lt;p&gt;ä¸ºäº†ä¿è¯â€œåˆ†å¸ƒå¼æ‰§è¡Œâ€çš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬å¿…é¡»ç¡®ä¿ï¼š&lt;strong&gt;å½“æ¯ä¸ªæ™ºèƒ½ä½“éƒ½æœ€å¤§åŒ–è‡ªå·±çš„å±€éƒ¨åˆ©ç›Š $Q_i$ æ—¶ï¼Œé›†ä½“çš„åˆ©ç›Š $Q_{tot}$ ä¹ŸåŒæ—¶è¢«æœ€å¤§åŒ–ã€‚&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;è¿™è¢«ç§°ä¸º &lt;strong&gt;IGM åŸåˆ™&lt;/strong&gt;ï¼Œæ•°å­¦è¡¨è¾¾ä¸ºï¼š
$$
\arg\max_{\mathbf{u}} Q_{tot}(\boldsymbol{\tau}, \mathbf{u}) =
\begin{pmatrix}
\arg\max_{u_1} Q_1(\tau_1, u_1) \
\vdots \
\arg\max_{u_n} Q_n(\tau_n, u_n)
\end{pmatrix}
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç›´è§‰&lt;/strong&gt;ï¼šå°±åƒä¸€æ”¯ç†æƒ³çš„è¶³çƒé˜Ÿï¼Œå¦‚æœå‰é”‹æ‹¼å‘½è¿›çƒï¼ˆå±€éƒ¨æœ€ä¼˜ï¼‰ï¼Œåå«æ‹¼å‘½é˜²å®ˆï¼ˆå±€éƒ¨æœ€ä¼˜ï¼‰ï¼Œé‚£ä¹ˆæ•´æ”¯çƒé˜Ÿçš„èƒœç‡ï¼ˆå…¨å±€æœ€ä¼˜ï¼‰ä¹Ÿåº”è¯¥æ˜¯æœ€é«˜çš„ã€‚å¦‚æœæ»¡è¶³ IGMï¼Œæˆ‘ä»¬å°±ä¸éœ€è¦å¤æ‚çš„åè°ƒé€šä¿¡ï¼Œå„è‡ªä¸ºæˆ˜å³å¯ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;VDN (Value-Decomposition Networks)&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;è®ºæ–‡&lt;/strong&gt;ï¼š&lt;a href=&quot;https://arxiv.org/abs/1706.05296&quot;&gt;Value-Decomposition Networks For Cooperative Multi-Agent Learning&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;VDN&lt;/strong&gt; æ˜¯å€¼åˆ†è§£é¢†åŸŸçš„å¥ åŸºä¹‹ä½œã€‚å®ƒçš„æ€è·¯éå¸¸ç®€å•ç²—æš´ï¼šå‡è®¾å…¨å±€ä»·å€¼å°±æ˜¯å±€éƒ¨ä»·å€¼çš„&lt;strong&gt;ç›´æ¥åŠ å’Œ&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;h3&gt;æ ¸å¿ƒå‡è®¾&lt;/h3&gt;
&lt;p&gt;$$
Q_{tot}(\boldsymbol{\tau}, \mathbf{u}) = \sum_{i=1}^n Q_i(\tau_i, u_i; \theta_i)
$$&lt;/p&gt;
&lt;h3&gt;è®­ç»ƒä¸æ‰§è¡Œ&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;è®­ç»ƒæ—¶&lt;/strong&gt;ï¼šæˆ‘ä»¬æœ€å°åŒ– $Q_{tot}$ ä¸çœŸå®å›æŠ¥çš„ TD è¯¯å·®ï¼š
$$ \mathcal{L}(\theta) = \left( r + \gamma \max_{\mathbf{u}&apos;} Q_{tot}(\boldsymbol{\tau}&apos;, \mathbf{u}&apos;; \theta^-) - Q_{tot}(\boldsymbol{\tau}, \mathbf{u}; \theta) \right)^2 $$
æ³¨æ„ï¼šè¿™é‡Œçš„ $\max_{\mathbf{u}&apos;} Q_{tot}$ å¯ä»¥å¾ˆå®¹æ˜“è®¡ç®—ï¼Œå› ä¸º $\max \sum Q_i = \sum \max Q_i$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ‰§è¡Œæ—¶&lt;/strong&gt;ï¼šæ¯ä¸ªæ™ºèƒ½ä½“åªéœ€é€‰æ‹© $u_i^* = \arg\max_{u_i} Q_i$ï¼Œå³å¯ä¿è¯é€‰æ‹©äº†å…¨å±€æœ€ä¼˜åŠ¨ä½œã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;å±€é™æ€§&lt;/h3&gt;
&lt;p&gt;VDN æ»¡è¶³ IGM åŸåˆ™ï¼Œä½†&lt;strong&gt;æ±‚å’Œ&lt;/strong&gt;çš„å‡è®¾å¤ªå¼ºäº†ã€‚å®ƒé™åˆ¶äº† $Q_{tot}$ åªèƒ½è¡¨ç¤ºå±€éƒ¨ä»·å€¼çš„çº¿æ€§ç»„åˆï¼Œæ— æ³•å¤„ç†å¤æ‚çš„éçº¿æ€§åä½œï¼ˆä¾‹å¦‚ï¼šåªæœ‰å½“ A å’Œ B åŒæ—¶åšæŸäº‹æ—¶ï¼Œå¥–åŠ±æ‰ä¼šæš´å¢ï¼‰ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;QMIX&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;è®ºæ–‡&lt;/strong&gt;ï¼š&lt;a href=&quot;https://arxiv.org/abs/1803.11485&quot;&gt;QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;QMIX&lt;/strong&gt; æ”¾å®½äº† VDN çš„é™åˆ¶ã€‚å®ƒæŒ‡å‡ºï¼Œè¦æ»¡è¶³ IGM åŸåˆ™ï¼Œå¹¶ä¸éœ€è¦ä¸¥æ ¼çš„çº¿æ€§æ±‚å’Œï¼Œåªéœ€è¦æ»¡è¶³ &lt;strong&gt;å•è°ƒæ€§çº¦æŸ (Monotonicity Constraint)&lt;/strong&gt; å³å¯ã€‚&lt;/p&gt;
&lt;h3&gt;æ ¸å¿ƒå‡è®¾&lt;/h3&gt;
&lt;p&gt;$$
\frac{\partial Q_{tot}}{\partial Q_i} \ge 0, \quad \forall i \in {1, \dots, n}
$$
å³ï¼š&lt;strong&gt;å±€éƒ¨ä»·å€¼ $Q_i$ è¶Šé«˜ï¼Œå…¨å±€ä»·å€¼ $Q_{tot}$ ä¹Ÿå°±è¶Šé«˜ã€‚&lt;/strong&gt;
åªè¦æ»¡è¶³è¿™ä¸ªæ¡ä»¶ï¼Œ$\arg\max Q_{tot}$ å°±ä¸€å®šç­‰ä»·äº $\arg\max Q_i$ çš„ç»„åˆã€‚&lt;/p&gt;
&lt;h3&gt;ç½‘ç»œæ¶æ„&lt;/h3&gt;
&lt;p&gt;QMIX ä½¿ç”¨ä¸€ä¸ª &lt;strong&gt;æ··åˆç½‘ç»œ (Mixing Network)&lt;/strong&gt; æ¥æ‹Ÿåˆ $Q_{tot}$ï¼Œå®ƒä»¥æ‰€æœ‰ $Q_i$ ä¸ºè¾“å…¥ï¼Œä»¥ $Q_{tot}$ ä¸ºè¾“å‡ºã€‚
ä¸ºäº†ä¿è¯å•è°ƒæ€§ï¼ˆæƒé‡éè´Ÿï¼‰ï¼ŒQMIX å¼•å…¥äº†ä¸€ä¸ª &lt;strong&gt;è¶…ç½‘ç»œ (Hypernetwork)&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Agent Network&lt;/strong&gt;: è¾“å…¥å±€éƒ¨è§‚æµ‹ $\tau_i$ï¼Œè¾“å‡º $Q_i$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mixing Network&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;è¿™æ˜¯ä¸€ä¸ªå‰é¦ˆç¥ç»ç½‘ç»œï¼Œè¾“å…¥æ˜¯ ${Q_1, \dots, Q_n}$ï¼Œè¾“å‡ºæ˜¯ $Q_{tot}$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å…³é”®ç‚¹&lt;/strong&gt;ï¼šè¿™ä¸ªç½‘ç»œçš„&lt;strong&gt;æƒé‡ (Weights)&lt;/strong&gt; æ˜¯ç”± Hypernetwork ç”Ÿæˆçš„ï¼Œä¸”è¢«å¼ºåˆ¶å–ç»å¯¹å€¼ï¼ˆä¿è¯éè´Ÿï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hypernetwork&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;è¾“å…¥æ˜¯å…¨å±€çŠ¶æ€ $s$ã€‚&lt;/li&gt;
&lt;li&gt;è¾“å‡ºæ˜¯ Mixing Network çš„æƒé‡ $W$ å’Œåç½® $b$ã€‚&lt;/li&gt;
&lt;li&gt;å…¬å¼ï¼š$W_{mix} = | \text{Hyper}(s) |$ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;é€šè¿‡è¿™ç§è®¾è®¡ï¼ŒQMIX å®ç°äº†ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;éçº¿æ€§èƒ½åŠ›&lt;/strong&gt;ï¼šMixing Network å¯ä»¥æ˜¯å¤æ‚çš„éçº¿æ€§å‡½æ•°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;çŠ¶æ€ä¾èµ–&lt;/strong&gt;ï¼šå…¨å±€çŠ¶æ€ $s$ å†³å®šäº†æ··åˆçš„æ–¹å¼ï¼ˆä¾‹å¦‚åœ¨æŸäº›çŠ¶æ€ä¸‹ï¼Œ$Q_1$ æ›´é‡è¦ï¼›åœ¨å¦ä¸€äº›çŠ¶æ€ä¸‹ï¼Œ$Q_2$ æ›´é‡è¦ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å•è°ƒæ€§ä¿è¯&lt;/strong&gt;ï¼šç”±äºæƒé‡æ’ä¸ºæ­£ï¼Œæ··åˆç½‘ç»œå¯¹è¾“å…¥ $Q_i$ ä¿æŒå•è°ƒé€’å¢ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;æŸå¤±å‡½æ•°&lt;/h3&gt;
&lt;p&gt;QMIX çš„è®­ç»ƒä¹Ÿæ˜¯æ ‡å‡†çš„ DQN é£æ ¼ï¼š
$$
\mathcal{L}(\theta) = \left( r + \gamma Q_{tot}(\boldsymbol{\tau}&apos;, s&apos;, \mathbf{u}&lt;em&gt;{max}&apos;; \theta^-) - Q&lt;/em&gt;{tot}(\boldsymbol{\tau}, s, \mathbf{u}; \theta) \right)^2
$$
å…¶ä¸­ $\mathbf{u}_{max}&apos;$ æ˜¯é€šè¿‡å„ä¸ª $Q_i$ è´ªå©ªé€‰å‡ºçš„åŠ¨ä½œç»„åˆã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;æ€»ç»“ä¸å¯¹æ¯”&lt;/h2&gt;
&lt;p&gt;| ç»´åº¦ | VDN | QMIX |
| :--- | :--- | :--- |
| &lt;strong&gt;åˆ†è§£æ–¹å¼&lt;/strong&gt; | çº¿æ€§æ±‚å’Œ | éçº¿æ€§æ··åˆ |
| &lt;strong&gt;IGM ä¿è¯&lt;/strong&gt; | æ˜¯ (Sum) | æ˜¯ (Monotonicity) |
| &lt;strong&gt;å…¨å±€ä¿¡æ¯åˆ©ç”¨&lt;/strong&gt; | æ—  (ä»…é€šè¿‡åå‘ä¼ æ’­éšå¼åˆ©ç”¨) | &lt;strong&gt;æœ‰ (Hypernetwork è¾“å…¥ $s$)&lt;/strong&gt; |
| &lt;strong&gt;è¡¨è¾¾èƒ½åŠ›&lt;/strong&gt; | å¼± (ä»…é™çº¿æ€§å…³ç³») | &lt;strong&gt;å¼º (å•è°ƒéçº¿æ€§å…³ç³»)&lt;/strong&gt; |
| &lt;strong&gt;é€‚ç”¨åœºæ™¯&lt;/strong&gt; | ç®€å•åä½œ | å¤æ‚éçº¿æ€§åä½œ (å¦‚é›†ç«æ”»å‡») |&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;QMIX çš„åœ°ä½&lt;/strong&gt;ï¼š
å®ƒæ˜¯ MARL é¢†åŸŸæœ€ç»å…¸çš„ç®—æ³•ä¹‹ä¸€ã€‚è™½ç„¶å®ƒåªèƒ½å¤„ç†æ»¡è¶³å•è°ƒæ€§å‡è®¾çš„ä»»åŠ¡ï¼ˆæœ‰äº›ä»»åŠ¡å¯èƒ½å±€éƒ¨æœ€ä¼˜ä¸ç­‰äºå…¨å±€æœ€ä¼˜ï¼‰ï¼Œä½†åœ¨ã€Šæ˜Ÿé™…äº‰éœ¸ã€‹(SMAC) ç­‰ä¸»æµæµ‹è¯•å¹³å°ä¸Šï¼ŒQMIX åŠå…¶å˜ä½“é•¿æœŸå æ®ç»Ÿæ²»åœ°ä½ã€‚&lt;/p&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-4.1ziqble6oe.webp"/><enclosure url="https://pic.hana0721.top/rl-note-4.1ziqble6oe.webp"/></item><item><title>RLç¬”è®°ï¼ˆ22ï¼‰ï¼šåˆå…¥å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹  (MARL)</title><link>https://claudiakim6827362.github.io/blog/rl-note-22</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/rl-note-22</guid><description>MARL çš„ä¸¤ä¸ªæç«¯ï¼šè¯¦è§£è”åˆåŠ¨ä½œå­¦ä¹  (JAL) ä¸ç‹¬ç«‹å­¦ä¹  (Independent RL)ã€‚æ·±åº¦åˆ†æâ€œç»´åº¦ç¾éš¾â€ä¸â€œç¯å¢ƒéå¹³ç¨³æ€§â€è¿™å¯¹æ ¸å¿ƒçŸ›ç›¾ã€‚</description><pubDate>Wed, 31 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;å¼•è¨€ï¼ˆIntroductionï¼‰&lt;/h2&gt;
&lt;p&gt;åœ¨ä¹‹å‰çš„ 19 ç¯‡ç¬”è®°ä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶çš„éƒ½æ˜¯ &lt;strong&gt;å•æ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹  (Single-Agent RL)&lt;/strong&gt;ã€‚
ä½†åœ¨ç°å®ä¸–ç•Œä¸­ï¼Œä»»åŠ¡å¾€å¾€æ¶‰åŠå¤šä¸ªä¸ªä½“ã€‚&lt;strong&gt;å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹  (MARL)&lt;/strong&gt; å°†é—®é¢˜æ‰©å±•åˆ°äº†éšæœºåšå¼ˆï¼ˆStochastic Gamesï¼‰çš„é¢†åŸŸã€‚&lt;/p&gt;
&lt;p&gt;åœ¨è¿›å…¥å¤æ‚çš„ SOTA ç®—æ³•ä¹‹å‰ï¼Œæˆ‘ä»¬å¿…é¡»å…ˆç†è§£è§£å†³ MARL é—®é¢˜çš„ä¸¤ç§&lt;strong&gt;æœ€æœ´ç´ ã€æœ€æç«¯&lt;/strong&gt;çš„æ€è·¯ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;å®Œå…¨ä¸­å¿ƒåŒ– (JAL)&lt;/strong&gt;ï¼šæŠŠæ‰€æœ‰äººçœ‹ä½œä¸€ä¸ªäººã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å®Œå…¨å»ä¸­å¿ƒåŒ– (IPPO)&lt;/strong&gt;ï¼šæŠŠé˜Ÿå‹çœ‹ä½œç©ºæ°”ï¼ˆæˆ–ç¯å¢ƒå™ªå£°ï¼‰ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;è¿™ä¸¤ç§æ€è·¯åˆ†åˆ«å¯¹åº”äº† MARL çš„ä¸¤å¤§æ ¸å¿ƒéš¾é¢˜ï¼š&lt;strong&gt;ç»´åº¦ç¾éš¾&lt;/strong&gt; ä¸ &lt;strong&gt;éå¹³ç¨³æ€§&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;ç†è®ºæ¨¡å‹ï¼šéšæœºåšå¼ˆ&lt;/h2&gt;
&lt;p&gt;å®šä¹‰ä¸ºä¸€ä¸ªå…ƒç»„ $(N, \mathcal{S}, \mathcal{A}, \mathcal{P}, \mathcal{R}, \gamma)$ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$N$ï¼šæ™ºèƒ½ä½“æ•°é‡ã€‚&lt;/li&gt;
&lt;li&gt;$\mathcal{S}$ï¼šå…¨å±€çŠ¶æ€ç©ºé—´ã€‚&lt;/li&gt;
&lt;li&gt;$\mathcal{A} = \mathcal{A}_1 \times \dots \times \mathcal{A}_N$ï¼š&lt;strong&gt;è”åˆåŠ¨ä½œç©ºé—´ (Joint Action Space)&lt;/strong&gt;ã€‚
&lt;ul&gt;
&lt;li&gt;çŠ¶æ€è½¬ç§»å–å†³äºæ‰€æœ‰äººçš„åŠ¨ä½œç»„åˆ $\mathbf{a} = (a_1, \dots, a_N)$ã€‚&lt;/li&gt;
&lt;li&gt;å³ $s&apos; \sim \mathcal{P}(\cdot | s, \mathbf{a})$ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;æç«¯ä¸€ï¼šè”åˆåŠ¨ä½œå­¦ä¹  (JAL)&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Joint Action Learning (JAL)&lt;/strong&gt; ä»£è¡¨äº† &lt;strong&gt;å®Œå…¨ä¸­å¿ƒåŒ– (Fully Centralized)&lt;/strong&gt; çš„æ€è·¯ã€‚&lt;/p&gt;
&lt;h3&gt;æ ¸å¿ƒæ€æƒ³&lt;/h3&gt;
&lt;p&gt;æ—¢ç„¶ç¯å¢ƒå—æ‰€æœ‰äººçš„åŠ¨ä½œ $\mathbf{a}$ å½±å“ï¼Œé‚£æˆ‘ä»¬å°±æ„å»ºä¸€ä¸ªæ‹¥æœ‰ä¸Šå¸è§†è§’çš„ &lt;strong&gt;â€œè¶…çº§æ™ºèƒ½ä½“â€ (Super Agent)&lt;/strong&gt;ï¼Œå®ƒæ¥æ”¶å…¨å±€çŠ¶æ€ $s$ï¼Œç›´æ¥è¾“å‡ºè”åˆåŠ¨ä½œ $\mathbf{a}$ æ¥æ§åˆ¶æ‰€æœ‰å•ä½ã€‚&lt;/p&gt;
&lt;h3&gt;æ–¹æ³•&lt;/h3&gt;
&lt;p&gt;ç›´æ¥å¥—ç”¨æ ‡å‡†çš„ PPO ç®—æ³•ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;è¾“å…¥ï¼š$s$&lt;/li&gt;
&lt;li&gt;è¾“å‡ºï¼š$\mathbf{a} = (a_1, a_2, \dots, a_N)$&lt;/li&gt;
&lt;li&gt;ç­–ç•¥ï¼š$\Pi_\theta(\mathbf{a} | s)$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;ç†è®ºåˆ†æ&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜åŠ¿ï¼šç¯å¢ƒå¹³ç¨³&lt;/strong&gt;ã€‚
å¯¹äºè¿™ä¸ªè¶…çº§æ™ºèƒ½ä½“æ¥è¯´ï¼Œå¤–ç•Œç¯å¢ƒæ˜¯é™æ­¢çš„ï¼ˆStationaryï¼‰ï¼Œå› ä¸ºæ²¡æœ‰â€œå…¶ä»–äººâ€åœ¨å¹²æ‰°å®ƒã€‚å› æ­¤ï¼Œé©¬å°”å¯å¤«æ€§è´¨æˆç«‹ï¼ŒRL çš„æ”¶æ•›æ€§ç†è®ºä¾ç„¶æœ‰æ•ˆã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è‡´å‘½ç¼ºé™·ï¼šç»´åº¦ç¾éš¾ (Curse of Dimensionality)&lt;/strong&gt;ã€‚
å‡è®¾æ¯ä¸ªæ™ºèƒ½ä½“æœ‰ $|A|$ ä¸ªåŠ¨ä½œï¼Œå…±æœ‰ $N$ ä¸ªæ™ºèƒ½ä½“ã€‚è”åˆåŠ¨ä½œç©ºé—´çš„å¤§å°ä¸º $|A|^N$ã€‚
&lt;ul&gt;
&lt;li&gt;$|A|=5, N=10 \Rightarrow 5^{10} \approx 9,765,625$ã€‚&lt;/li&gt;
&lt;li&gt;è¾“å‡ºå±‚éœ€è¦é¢„æµ‹è¿‘ä¸€åƒä¸‡ä¸ªæ¦‚ç‡å€¼ï¼Œè¿™åœ¨è®¡ç®—ä¸Šæ˜¯ä¸å¯è¡Œçš„ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;æç«¯äºŒï¼šç‹¬ç«‹å­¦ä¹  (Independent RL / IPPO)&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Independent PPO (IPPO)&lt;/strong&gt; ä»£è¡¨äº† &lt;strong&gt;å®Œå…¨å»ä¸­å¿ƒåŒ– (Fully Decentralized)&lt;/strong&gt; çš„æ€è·¯ã€‚&lt;/p&gt;
&lt;h3&gt;æ ¸å¿ƒæ€æƒ³&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;â€œæŠŠé˜Ÿå‹å½“ç©ºæ°”â€&lt;/strong&gt;ã€‚
æ¯ä¸ªæ™ºèƒ½ä½“ $i$ éƒ½æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„ä¸ªä½“ï¼Œå®ƒåªå…³å¿ƒè‡ªå·±çš„è§‚æµ‹ $o_i$ å’Œå¥–åŠ± $r_i$ã€‚å®ƒæŠŠæ‰€æœ‰â€œå…¶ä»–æ™ºèƒ½ä½“â€éƒ½è§†ä¸º&lt;strong&gt;ç¯å¢ƒçš„ä¸€éƒ¨åˆ†&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;h3&gt;æ–¹æ³•&lt;/h3&gt;
&lt;p&gt;åŒæ—¶è¿è¡Œ $N$ ä¸ªç‹¬ç«‹çš„ PPO ç®—æ³•ï¼ˆå‚æ•°å¯ä»¥å…±äº«ï¼Œä¹Ÿå¯ä»¥ä¸å…±äº«ï¼‰ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å¯¹äºæ™ºèƒ½ä½“ $i$ï¼š
&lt;ul&gt;
&lt;li&gt;è¾“å…¥ï¼šå±€éƒ¨è§‚æµ‹ $o_i$&lt;/li&gt;
&lt;li&gt;è¾“å‡ºï¼šç‹¬ç«‹åŠ¨ä½œ $a_i$&lt;/li&gt;
&lt;li&gt;ç­–ç•¥ï¼š$\pi_{\theta_i}(a_i | o_i)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;ç†è®ºåˆ†æ&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜åŠ¿ï¼šçº¿æ€§æ‰©å±•&lt;/strong&gt;ã€‚
è®¡ç®—å¤æ‚åº¦éšäººæ•° $N$ çº¿æ€§å¢é•¿ã€‚æ— è®ºæœ‰å¤šå°‘äººï¼Œæ¯ä¸ªç½‘ç»œåªè¾“å‡º $|A|$ ä¸ªæ¦‚ç‡ã€‚è¿™å®Œç¾è§£å†³äº†ç»´åº¦ç¾éš¾ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è‡´å‘½ç¼ºé™·ï¼šéå¹³ç¨³æ€§ (Non-Stationarity)&lt;/strong&gt;ã€‚
ä»æ™ºèƒ½ä½“ $i$ çš„è§†è§’çœ‹ï¼ŒçŠ¶æ€è½¬ç§»æ¦‚ç‡å˜æˆäº†ï¼š
$$ P(s&apos;|s, a_i) = \sum_{\mathbf{a}&lt;em&gt;{-i}} P(s&apos;|s, a_i, \mathbf{a}&lt;/em&gt;{-i}) \pi_{-i}(\mathbf{a}&lt;em&gt;{-i}|s) $$
æ³¨æ„å…¬å¼é‡Œçš„ $\pi&lt;/em&gt;{-i}$ï¼ˆé˜Ÿå‹çš„ç­–ç•¥ï¼‰ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œ&lt;strong&gt;é˜Ÿå‹ä¹Ÿåœ¨å­¦ä¹ ï¼Œ$\pi_{-i}$ ä¸€ç›´åœ¨å˜&lt;/strong&gt;ã€‚
è¿™æ„å‘³ç€ï¼š&lt;strong&gt;å¯¹äºæ™ºèƒ½ä½“ $i$ æ¥è¯´ï¼Œæ˜¨å¤©æœ‰ç”¨çš„ç­–ç•¥ï¼Œä»Šå¤©å¯èƒ½å°±æ²¡ç”¨äº†ï¼Œå› ä¸ºç¯å¢ƒï¼ˆé˜Ÿå‹ï¼‰å˜äº†ã€‚&lt;/strong&gt;
è¿™ç ´åäº†é©¬å°”å¯å¤«å‡è®¾ï¼Œç†è®ºä¸Šç®—æ³•æ— æ³•æ”¶æ•›ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;æ€»ç»“ä¸å¯¹æ¯”&lt;/h2&gt;
&lt;p&gt;| ç»´åº¦ | è”åˆåŠ¨ä½œå­¦ä¹  (JAL) | ç‹¬ç«‹å­¦ä¹  (IPPO) |
| :--- | :--- | :--- |
| &lt;strong&gt;æ§åˆ¶æ–¹å¼&lt;/strong&gt; | &lt;strong&gt;å®Œå…¨ä¸­å¿ƒåŒ–&lt;/strong&gt; (Super Agent) | &lt;strong&gt;å®Œå…¨å»ä¸­å¿ƒåŒ–&lt;/strong&gt; (Independent Agents) |
| &lt;strong&gt;åŠ¨ä½œç©ºé—´&lt;/strong&gt; | è”åˆåŠ¨ä½œ $\mathbf{a}$ | ç‹¬ç«‹åŠ¨ä½œ $a_i$ |
| &lt;strong&gt;ç©ºé—´å¤æ‚åº¦&lt;/strong&gt; | &lt;strong&gt;æŒ‡æ•°çº§çˆ†ç‚¸&lt;/strong&gt; $|A|^N$ | &lt;strong&gt;çº¿æ€§å¢é•¿&lt;/strong&gt; $N \times |A|$ |
| &lt;strong&gt;ç¯å¢ƒæ€§è´¨&lt;/strong&gt; | &lt;strong&gt;å¹³ç¨³ (Stationary)&lt;/strong&gt; | &lt;strong&gt;éå¹³ç¨³ (Non-Stationary)&lt;/strong&gt; |
| &lt;strong&gt;ç†è®ºä¿è¯&lt;/strong&gt; | æœ‰æ”¶æ•›ä¿è¯ | æ— æ”¶æ•›ä¿è¯ |
| &lt;strong&gt;å®é™…è¡¨ç°&lt;/strong&gt; | è§„æ¨¡ç¨å¤§å³æ— æ³•è¿è¡Œ | å°½ç®¡æ²¡ç†è®ºä¿è¯ï¼Œä½†åœ¨å®è·µä¸­å¾€å¾€æ˜¯ Strong Baseline |&lt;/p&gt;
&lt;h3&gt;è¿™ä¸€ç« çš„å¯ç¤º&lt;/h3&gt;
&lt;p&gt;æˆ‘ä»¬é™·å…¥äº†ä¸¤éš¾å¢ƒåœ°ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;é€‰ JALï¼Œç†è®ºç¨³ä½†ç®—ä¸åŠ¨ã€‚&lt;/li&gt;
&lt;li&gt;é€‰ IPPOï¼Œç®—å¾—å¿«ä½†ç†è®ºè™šã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;è¿™å°±å¼•å‡ºäº† MARL ç ”ç©¶çš„åœ£æ¯â€”â€”&lt;strong&gt;CTDE (é›†ä¸­å¼è®­ç»ƒï¼Œåˆ†å¸ƒå¼æ‰§è¡Œ)&lt;/strong&gt;ã€‚
æˆ‘ä»¬éœ€è¦ä¸€ç§æŠ˜ä¸­çš„æ–¹æ³•ï¼š&lt;strong&gt;åœ¨è®­ç»ƒæ—¶åˆ©ç”¨ JAL çš„ä¸Šå¸è§†è§’æ¥ç¼“è§£éå¹³ç¨³æ€§ï¼Œåœ¨æ‰§è¡Œæ—¶åˆ©ç”¨ IPPO çš„ç‹¬ç«‹ç»“æ„æ¥é¿å…ç»´åº¦ç¾éš¾ã€‚&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;è¿™æ­£æ˜¯åç»­ &lt;strong&gt;MAPPO&lt;/strong&gt; å’Œ &lt;strong&gt;QMIX&lt;/strong&gt; ç­‰ç®—æ³•çš„æ ¸å¿ƒåŠ¨æœºã€‚&lt;/p&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-4.1ziqble6oe.webp"/><enclosure url="https://pic.hana0721.top/rl-note-4.1ziqble6oe.webp"/></item><item><title>RLç¬”è®°ï¼ˆ21ï¼‰ï¼šç›®æ ‡å¯¼å‘çš„å¼ºåŒ–å­¦ä¹  (Goal-Conditioned RL)</title><link>https://claudiakim6827362.github.io/blog/rl-note-21</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/rl-note-21</guid><description>ä»è§£å†³å•ä¸€ä»»åŠ¡åˆ°è§£å†³ä¸€ç±»ä»»åŠ¡ï¼šè¯¦è§£ç›®æ ‡å¯¼å‘ RL çš„æ•°å­¦å½¢å¼åŒ–ã€‚æ¶µç›–é€šç”¨ä»·å€¼å‡½æ•°è¿‘ä¼¼ (UVFA) ç†è®ºï¼Œä»¥åŠè§£å†³ç¨€ç–å¥–åŠ±éš¾é¢˜çš„æ ¸å¿ƒæŠ€æœ¯â€”â€”äº‹åç»éªŒå›æ”¾ (HER)ã€‚</description><pubDate>Tue, 30 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;å¼•è¨€ï¼ˆIntroductionï¼‰&lt;/h2&gt;
&lt;p&gt;åœ¨æ ‡å‡†çš„å¼ºåŒ–å­¦ä¹ è®¾å®šä¸­ï¼Œæˆ‘ä»¬é€šå¸¸è®­ç»ƒä¸€ä¸ªæ™ºèƒ½ä½“å»å®Œæˆ&lt;strong&gt;ä¸€ä¸ªç‰¹å®šçš„ä»»åŠ¡&lt;/strong&gt;ï¼ˆä¾‹å¦‚ï¼šæ‰“èµ¢ä¸€å±€æ¸¸æˆï¼Œæˆ–è€…è®©æœºå™¨äººèµ°åˆ°ç‰¹å®šçš„åæ ‡ $(x,y)$ï¼‰ã€‚å¦‚æœä»»åŠ¡ç›®æ ‡å˜äº†ï¼ˆä¾‹å¦‚ï¼šèµ°åˆ°æ–°çš„åæ ‡ $(x&apos;, y&apos;)$ï¼‰ï¼Œæˆ‘ä»¬é€šå¸¸éœ€è¦é‡æ–°è®­ç»ƒç½‘ç»œã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ç›®æ ‡å¯¼å‘çš„å¼ºåŒ–å­¦ä¹  (Goal-Conditioned RL, GCRL)&lt;/strong&gt; æ—¨åœ¨æ‰“ç ´è¿™ä¸€é™åˆ¶ã€‚æˆ‘ä»¬å¸Œæœ›è®­ç»ƒä¸€ä¸ªæ™ºèƒ½ä½“ï¼Œå®ƒä¸ä»…èƒ½æ ¹æ®çŠ¶æ€ $s$ åšå‡ºå†³ç­–ï¼Œè¿˜èƒ½æ ¹æ®&lt;strong&gt;è¾“å…¥çš„ç›®æ ‡ $g$&lt;/strong&gt; åŠ¨æ€è°ƒæ•´ç­–ç•¥ã€‚&lt;/p&gt;
&lt;p&gt;å³ç­–ç•¥å‡½æ•°å˜ä¸º $\pi(a|s, g)$ï¼Œä»·å€¼å‡½æ•°å˜ä¸º $Q(s, a, g)$ã€‚è¿™ä½¿å¾—æ™ºèƒ½ä½“å…·å¤‡äº†&lt;strong&gt;å¤šä»»åŠ¡æ³›åŒ–&lt;/strong&gt;çš„èƒ½åŠ›ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;é—®é¢˜å½¢å¼åŒ– (Problem Formulation)&lt;/h2&gt;
&lt;p&gt;æˆ‘ä»¬å°†æ ‡å‡†çš„é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ (MDP) æ‰©å±•ä¸º &lt;strong&gt;ç›®æ ‡å¢å¼ºçš„ MDP (Augmented MDP)&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;h3&gt;æ‰©å±•å…ƒç»„&lt;/h3&gt;
&lt;p&gt;æ–°çš„å…ƒç»„å®šä¹‰ä¸º $\mathcal{M} = (\mathcal{S}, \mathcal{A}, \mathcal{P}, \mathcal{G}, r, \gamma)$ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\mathcal{G}$ï¼šç›®æ ‡ç©ºé—´ï¼ˆé€šå¸¸æ˜¯çŠ¶æ€ç©ºé—´ $\mathcal{S}$ çš„å­é›†ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;$r(s, a, g)$ï¼šç›®æ ‡å¯¼å‘çš„å¥–åŠ±å‡½æ•°ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;å¥–åŠ±å‡½æ•°çš„è®¾è®¡&lt;/h3&gt;
&lt;p&gt;åœ¨ GCRL ä¸­ï¼Œæœ€å¸¸è§çš„å¥–åŠ±å‡½æ•°æœ‰ä¸¤ç§å½¢å¼ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ç¨€ç–å¥–åŠ± (Sparse Reward)&lt;/strong&gt;ï¼š
åªæœ‰å½“æ™ºèƒ½ä½“çœŸæ­£è¾¾æˆç›®æ ‡æ—¶æ‰ç»™å¥–åŠ±ï¼ˆé€šå¸¸ç”¨äºæœºæ¢°è‡‚æŠ“å–ç­‰ç²¾ç¡®ä»»åŠ¡ï¼‰ã€‚
$$
r(s, a, g) = \mathbb{I}(\phi(s) = g) = \begin{cases} 0 &amp;#x26; \text{if } ||\phi(s) - g|| &amp;#x3C; \epsilon \ -1 &amp;#x26; \text{otherwise} \end{cases}
$$
&lt;em&gt;(æ³¨ï¼šè¿™é‡Œç”¨ 0/-1 å¥–åŠ±ç»“æ„æ¯” 1/0 æ›´å¸¸è§ï¼Œå› ä¸ºè¿™æ ·ä»·å€¼å‡½æ•°ä»£è¡¨äº†â€œåˆ°è¾¾ç›®æ ‡çš„æœŸæœ›æ­¥æ•°â€çš„è´Ÿå€¼)&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ç¨ å¯†å¥–åŠ± (Dense Reward)&lt;/strong&gt;ï¼š
åŸºäºå½“å‰çŠ¶æ€ä¸ç›®æ ‡çš„è·ç¦»ã€‚
$$
r(s, a, g) = -||\phi(s) - g||_2
$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;ç›®æ ‡ï¼šUVFA&lt;/h3&gt;
&lt;p&gt;æˆ‘ä»¬çš„ä¼˜åŒ–ç›®æ ‡æ˜¯æ‰¾åˆ°ä¸€ä¸ªæœ€ä¼˜ç­–ç•¥ $\pi^*$ï¼Œæœ€å¤§åŒ–æ‰€æœ‰å¯èƒ½çš„èµ·å§‹çŠ¶æ€å’Œç›®æ ‡çš„æœŸæœ›å›æŠ¥ï¼š
$$
J(\pi) = \mathbb{E}&lt;em&gt;{g \sim p(g), s_0 \sim p(s_0), \tau \sim \pi} \left[ \sum&lt;/em&gt;{t=0}^\infty \gamma^t r(s_t, a_t, g) \right]
$$&lt;/p&gt;
&lt;p&gt;è¿™ç§èƒ½å¤ŸåŒæ—¶æ³›åŒ–çŠ¶æ€ $s$ å’Œç›®æ ‡ $g$ çš„ä»·å€¼å‡½æ•°è¿‘ä¼¼å™¨ï¼Œè¢«ç§°ä¸º &lt;strong&gt;é€šç”¨ä»·å€¼å‡½æ•°è¿‘ä¼¼ (Universal Value Function Approximators, UVFA)&lt;/strong&gt;ã€‚
$$ V(s, g; \theta) \approx \mathbb{E} [R | s, g] $$
ç¥ç»ç½‘ç»œç»“æ„é€šå¸¸æ˜¯å°†çŠ¶æ€ç‰¹å¾ $\phi(s)$ å’Œç›®æ ‡ç‰¹å¾ $\psi(g)$ æ‹¼æ¥åè¾“å…¥ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;ç¨€ç–å¥–åŠ±éš¾é¢˜&lt;/h2&gt;
&lt;p&gt;å°½ç®¡ UVFA æä¾›äº†ç†è®ºæ¡†æ¶ï¼Œä½†åœ¨å®é™…è®­ç»ƒä¸­ï¼Œå¦‚æœä½¿ç”¨&lt;strong&gt;ç¨€ç–å¥–åŠ±&lt;/strong&gt;ï¼Œå­¦ä¹ ä¼šæå…¶å›°éš¾ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;é—®é¢˜&lt;/strong&gt;ï¼šåœ¨ä¸€ä¸ªé«˜ç»´ç¯å¢ƒä¸­ï¼ˆä¾‹å¦‚æœºæ¢°è‡‚æ§åˆ¶ï¼‰ï¼Œéšæœºæ¢ç´¢ç¢°åˆ°ç›®æ ‡ $g$ çš„æ¦‚ç‡å‡ ä¹ä¸º 0ã€‚
è¿™æ„å‘³ç€ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ç»éªŒå›æ”¾æ±  $\mathcal{D}$ ä¸­å‡ ä¹æ‰€æœ‰çš„æ ·æœ¬ï¼Œå…¶å¥–åŠ± $r$ éƒ½æ˜¯ -1ï¼ˆæˆ– 0ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;æ™ºèƒ½ä½“æ”¶ä¸åˆ°ä»»ä½•æ­£åé¦ˆï¼Œæ¢¯åº¦æ— æ³•æŒ‡å¼•ä¼˜åŒ–çš„æ–¹å‘ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;è¿™è¢«ç§°ä¸º &lt;strong&gt;ç¨€ç–å¥–åŠ±é—®é¢˜ (Sparse Reward Problem)&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;äº‹åç»éªŒå›æ”¾ (Hindsight Experience Replay, HER)&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;HER&lt;/strong&gt; æ˜¯ GCRL é¢†åŸŸæœ€æ ¸å¿ƒçš„ç®—æ³•åˆ›æ–°ã€‚å®ƒçš„çµæ„Ÿæ¥æºäºäººç±»çš„â€œç²¾ç¥èƒœåˆ©æ³•â€ã€‚&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;ğŸ’¡ ç›´è§‰&lt;/strong&gt;ï¼š
å‡è®¾ä½ çš„ç›®æ ‡æ˜¯å°„ä¸­é¶å¿ƒï¼Œä½†ä½ å°„åäº†ï¼Œå°„åˆ°äº†æ—è¾¹çš„æ ‘ä¸Šã€‚
è™½ç„¶ä½œä¸ºâ€œå°„é¶å¿ƒâ€çš„ä»»åŠ¡ä½ å¤±è´¥äº†ï¼Œä½†å¦‚æœæˆ‘ä»¬äº‹åå›é¡¾ï¼ˆHindsightï¼‰ï¼Œå‡è®¾åŸæœ¬çš„ç›®æ ‡å°±æ˜¯â€œå°„ä¸­é‚£æ£µæ ‘â€ï¼Œé‚£ä½ é€šè¿‡åˆšæ‰çš„åŠ¨ä½œåºåˆ—ï¼Œå®Œç¾åœ°å®Œæˆäº†ä»»åŠ¡ï¼&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;ç†è®ºæ¨å¯¼&lt;/h3&gt;
&lt;p&gt;HER çš„æ ¸å¿ƒåœ¨äº&lt;strong&gt;é‡æ ‡è®° (Relabeling)&lt;/strong&gt; ç»éªŒå›æ”¾æ± ä¸­çš„ç›®æ ‡ã€‚&lt;/p&gt;
&lt;p&gt;å‡è®¾æ™ºèƒ½ä½“åœ¨ç›®æ ‡ $g$ çš„æŒ‡å¯¼ä¸‹ï¼Œäº§ç”Ÿäº†ä¸€æ¡è½¨è¿¹ï¼š
$$ \tau = {s_0, a_0, r_0, s_1, \dots, s_T} $$
å…¶ä¸­ï¼Œæœ€åçš„çŠ¶æ€ $s_T$ å¹¶æ²¡æœ‰åˆ°è¾¾é¢„è®¾ç›®æ ‡ $g$ï¼Œæ‰€ä»¥æ‰€æœ‰çš„ $r_t = -1$ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;HER çš„æ“ä½œ&lt;/strong&gt;ï¼š
æˆ‘ä»¬æ„é€ ä¸€ä¸ªæ–°çš„è™šå‡ç›®æ ‡ $g&apos; = s_T$ï¼ˆå³æŠŠæœ€åå®é™…è¾¾åˆ°çš„çŠ¶æ€å½“ä½œç›®æ ‡ï¼‰ã€‚
å¯¹äºè½¨è¿¹ä¸­çš„æ¯ä¸€ä¸ªè½¬æ¢ $(s_t, a_t, s_{t+1})$ï¼Œæˆ‘ä»¬æ ¹æ®æ–°ç›®æ ‡ $g&apos;$ é‡æ–°è®¡ç®—å¥–åŠ±ï¼š
$$
r&apos;&lt;em&gt;t = r(s_t, a_t, g&apos;) = \begin{cases} 0 &amp;#x26; \text{if } s&lt;/em&gt;{t+1} = g&apos; \ -1 &amp;#x26; \text{otherwise} \end{cases}
$$
ç”±äº $g&apos;$ å°±æ˜¯ $s_T$ï¼Œé‚£ä¹ˆåœ¨è½¨è¿¹ç»“æŸæ—¶ï¼Œæ™ºèƒ½ä½“&lt;strong&gt;å¿…ç„¶&lt;/strong&gt;è·å¾—äº†æ­£å¥–åŠ±ã€‚&lt;/p&gt;
&lt;p&gt;æˆ‘ä»¬å°†åŸå§‹æ•°æ® $(s_t, a_t, r_t, s_{t+1}, g)$ å’Œä¿®æ”¹åçš„æ•°æ® $(s_t, a_t, r&apos;&lt;em&gt;t, s&lt;/em&gt;{t+1}, g&apos;)$ éƒ½å­˜å…¥ Replay Bufferã€‚&lt;/p&gt;
&lt;h3&gt;ä¸ºä»€ä¹ˆæ•°å­¦ä¸Šæ˜¯æˆç«‹çš„ï¼Ÿ(Off-Policy çš„é‡è¦æ€§)&lt;/h3&gt;
&lt;p&gt;HER åªèƒ½ç”¨äº &lt;strong&gt;ç¦»çº¿ç­–ç•¥ (Off-Policy)&lt;/strong&gt; ç®—æ³•ï¼ˆå¦‚ DQN, DDPG, SACï¼‰ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;åŸå› &lt;/strong&gt;ï¼š
æˆ‘ä»¬åŸæœ¬äº§ç”Ÿçš„è½¨è¿¹ $\tau$ æ˜¯ç”±ç­–ç•¥ $\pi(\cdot | s, g)$ ç”Ÿæˆçš„ã€‚
ä½†åœ¨è®­ç»ƒæ—¶ï¼Œæˆ‘ä»¬å°†å…¶å¼ºè¡Œè§£é‡Šä¸ºæ˜¯ç”±ç­–ç•¥ $\pi(\cdot | s, g&apos;)$ ç”Ÿæˆçš„ã€‚
è¿™æœ¬è´¨ä¸Šæ˜¯ä¸€ç§æç«¯çš„ Off-Policy å­¦ä¹ ï¼š&lt;strong&gt;è¡Œä¸ºç­–ç•¥çš„ç›®æ ‡ä¸æ›´æ–°æ—¶çš„ç›®æ ‡å®Œå…¨ä¸åŒã€‚&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;åªè¦ç®—æ³•æ”¯æŒ Off-Policyï¼ˆå³ä¸ä»…å¯ä»¥åˆ©ç”¨è‡ªå·±äº§ç”Ÿçš„æ—§æ•°æ®ï¼Œè¿˜å¯ä»¥åˆ©ç”¨â€œåˆ«äººâ€äº§ç”Ÿçš„æ•°æ®ï¼‰ï¼ŒHER å°±æ˜¯æ•°å­¦ä¸Šåˆæ³•çš„ã€‚å› ä¸ºå¯¹äº $(s_t, a_t, s_{t+1})$ è¿™ä¸ªç‰©ç†è½¬æ¢æ¥è¯´ï¼Œå®ƒåªéµå¾ªç¯å¢ƒåŠ¨åŠ›å­¦ $P(s&apos;|s,a)$ï¼Œä¸ç›®æ ‡ $g$ æ— å…³ã€‚ç¯å¢ƒçš„ç‰©ç†è§„å¾‹æ˜¯ä¸éšå¿ƒä¸­çš„ç›®æ ‡è€Œæ”¹å˜çš„ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;HER çš„å˜ç§ä¸ç†è®ºè§£é‡Š&lt;/h2&gt;
&lt;h3&gt;ä¸åŒçš„é‡æ ‡è®°ç­–ç•¥ (Replay Strategy)&lt;/h3&gt;
&lt;p&gt;åœ¨å°†æ•°æ®å­˜å…¥ Buffer æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©ä¸åŒçš„é‡æ ‡è®°æ–¹å¼ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Future&lt;/strong&gt;: ä»å½“å‰æ—¶é—´æ­¥ $t$ ä¹‹åçš„è½¨è¿¹ä¸­éšæœºé€‰å–ä¸€ä¸ªçŠ¶æ€ä½œä¸ºæ–°ç›®æ ‡ $g&apos;$ã€‚ï¼ˆè¿™æ˜¯æ ‡å‡†åšæ³•ï¼Œæ•ˆæœæœ€å¥½ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Final&lt;/strong&gt;: ä»…ä½¿ç”¨è½¨è¿¹çš„æœ€åä¸€ä¸ªçŠ¶æ€ $s_T$ ä½œä¸º $g&apos;$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Episode&lt;/strong&gt;: ä»æ•´ä¸ªè½¨è¿¹ä¸­éšæœºé€‰å–ä¸€ä¸ªçŠ¶æ€ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Random&lt;/strong&gt;: éšæœºç”Ÿæˆä¸€ä¸ªå…¨æ–°çš„ç›®æ ‡ï¼ˆæ•ˆæœé€šå¸¸ä¸å¥½ï¼‰ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;éšå¼è¯¾ç¨‹å­¦ä¹  (Implicit Curriculum Learning)&lt;/h3&gt;
&lt;p&gt;ä»ç†è®ºä¸Šè®²ï¼ŒHER å®ç°äº†ä¸€ç§è‡ªåŠ¨çš„è¯¾ç¨‹å­¦ä¹ ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;åˆæœŸ&lt;/strong&gt;ï¼šæ™ºèƒ½ä½“å¾ˆç¬¨ï¼Œåªèƒ½ç¢°åˆ°ç¦»èµ·å§‹ç‚¹å¾ˆè¿‘çš„çŠ¶æ€ã€‚HER æŠŠè¿™äº›è¿‘çš„çŠ¶æ€è®¾ä¸ºç›®æ ‡ï¼Œæ™ºèƒ½ä½“å­¦ä¼šäº†å¦‚ä½•â€œèµ°ä¸€å°æ­¥â€ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä¸­æœŸ&lt;/strong&gt;ï¼šå­¦ä¼šèµ°ä¸€å°æ­¥åï¼Œæ™ºèƒ½ä½“èƒ½æ¢ç´¢åˆ°ç¨è¿œä¸€ç‚¹çš„çŠ¶æ€ã€‚HER å†æ¬¡æŠŠç¨è¿œçš„çŠ¶æ€è®¾ä¸ºç›®æ ‡ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åæœŸ&lt;/strong&gt;ï¼šéšç€èƒ½åŠ›æ‰©å±•ï¼Œæ™ºèƒ½ä½“æœ€ç»ˆèƒ½å­¦ä¼šåˆ°è¾¾çœŸæ­£çš„è¿œè·ç¦»ç›®æ ‡ $g$ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;è¿™ç§å¥–åŠ±ä¿¡å·ä»å®¹æ˜“åˆ°å›°éš¾çš„è‡ªåŠ¨ä¼ æ’­ï¼Œæ˜¯ HER è§£å†³ç¨€ç–å¥–åŠ±é—®é¢˜çš„æœ¬è´¨åŸå› ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;æ€»ç»“&lt;/h2&gt;
&lt;p&gt;ç›®æ ‡å¯¼å‘ RL å°†å¼ºåŒ–å­¦ä¹ ä»â€œè§£å†³ä¸€ä¸ªé—®é¢˜â€æå‡åˆ°äº†â€œè§£å†³ä¸€ç±»é—®é¢˜â€ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;UVFA&lt;/strong&gt; æä¾›äº†ç½‘ç»œç»“æ„çš„ç†è®ºåŸºç¡€ï¼Œè®© $V(s,g)$ æˆä¸ºå¯èƒ½ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HER&lt;/strong&gt; è§£å†³äº†æœ€ä¸ºæ£˜æ‰‹çš„ç¨€ç–å¥–åŠ±é—®é¢˜ï¼Œé€šè¿‡&lt;strong&gt;äº‹åé‡æ ‡è®°&lt;/strong&gt;ï¼Œå°†æ¯ä¸€æ¬¡å¤±è´¥çš„å°è¯•éƒ½è½¬åŒ–ä¸ºå¦ä¸€æ¬¡æˆåŠŸçš„è®­ç»ƒæ•°æ®ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;è‡³æ­¤ï¼Œæˆ‘ä»¬å·²ç»æŒæ¡äº†è®©æ™ºèƒ½ä½“å­¦ä¼šâ€œæŒ‡å“ªæ‰“å“ªâ€çš„å…³é”®æŠ€æœ¯ã€‚&lt;/p&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-3.3yex1xdpri.webp"/><enclosure url="https://pic.hana0721.top/rl-note-3.3yex1xdpri.webp"/></item><item><title>Paper Reading: LLM 1</title><link>https://claudiakim6827362.github.io/blog/paper-reading-llm1</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/paper-reading-llm1</guid><description>è¯»ä¸€äº›å¤§å‹è¯­è¨€æ¨¡å‹ç›¸å…³çš„è®ºæ–‡</description><pubDate>Fri, 26 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;import { ArxivRating, RatingCriteria } from &apos;@/components/advanced&apos;&lt;/p&gt;
&lt;h2&gt;GPT 1.0&lt;/h2&gt;
&lt;h2&gt;BERT&lt;/h2&gt;
&lt;h2&gt;GPT 2.0&lt;/h2&gt;
&lt;h2&gt;Megatron-LM&lt;/h2&gt;
&lt;h2&gt;T5&lt;/h2&gt;
&lt;h2&gt;ZeRO&lt;/h2&gt;
&lt;h2&gt;Scaling Law&lt;/h2&gt;
&lt;h2&gt;GPT 3.0&lt;/h2&gt;
&lt;h2&gt;Switch Transformers&lt;/h2&gt;
&lt;h2&gt;Codex&lt;/h2&gt;
&lt;h2&gt;COT&lt;/h2&gt;
&lt;h2&gt;InstructGPT&lt;/h2&gt;
&lt;h2&gt;PaLM&lt;/h2&gt;
&lt;h2&gt;LLaMA&lt;/h2&gt;
&lt;h2&gt;GPT 4&lt;/h2&gt;
&lt;h2&gt;DPO&lt;/h2&gt;
&lt;h2&gt;ToT&lt;/h2&gt;
&lt;h2&gt;LLaMA2&lt;/h2&gt;
&lt;h2&gt;Mistral 7B&lt;/h2&gt;
&lt;h2&gt;Mamba&lt;/h2&gt;
&lt;h2&gt;Mamba2&lt;/h2&gt;
&lt;h2&gt;Qwen2.5&lt;/h2&gt;
&lt;h2&gt;DeepSeek-V3&lt;/h2&gt;
&lt;h2&gt;DeepSeek-R1&lt;/h2&gt;
&lt;h2&gt;Kimi K2&lt;/h2&gt;
&lt;h2&gt;DFT&lt;/h2&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-5.32ifmhjene.webp"/><enclosure url="https://pic.hana0721.top/rl-note-5.32ifmhjene.webp"/></item><item><title>Paper Reading: LLM 2</title><link>https://claudiakim6827362.github.io/blog/paper-reading-llm2</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/paper-reading-llm2</guid><description>è¯»ä¸€äº›å¤§å‹è¯­è¨€æ¨¡å‹ç›¸å…³çš„è®ºæ–‡</description><pubDate>Fri, 26 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;import { ArxivRating, RatingCriteria } from &apos;@/components/advanced&apos;&lt;/p&gt;
&lt;h2&gt;MMaDA&lt;/h2&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-5.32ifmhjene.webp"/><enclosure url="https://pic.hana0721.top/rl-note-5.32ifmhjene.webp"/></item><item><title>Paper Reading: MLLM 1</title><link>https://claudiakim6827362.github.io/blog/paper-reading-mllm1</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/paper-reading-mllm1</guid><description>è¯»ä¸€äº›å¤šæ¨¡æ€ç›¸å…³çš„è®ºæ–‡</description><pubDate>Fri, 26 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;import { ArxivRating, RatingCriteria } from &apos;@/components/advanced&apos;&lt;/p&gt;
&lt;h2&gt;CLIP&lt;/h2&gt;
&lt;h2&gt;SigLip&lt;/h2&gt;
&lt;h2&gt;SigLipV2&lt;/h2&gt;
&lt;h2&gt;Dino V1&lt;/h2&gt;
&lt;h2&gt;Dino V2&lt;/h2&gt;
&lt;h2&gt;Dino V3&lt;/h2&gt;
&lt;h2&gt;ViLT&lt;/h2&gt;
&lt;h2&gt;ALBEF&lt;/h2&gt;
&lt;h2&gt;VLMo&lt;/h2&gt;
&lt;h2&gt;BLIP&lt;/h2&gt;
&lt;h2&gt;CoCa&lt;/h2&gt;
&lt;h2&gt;BEiT V3&lt;/h2&gt;
&lt;h2&gt;BLIP2&lt;/h2&gt;
&lt;h2&gt;LLava&lt;/h2&gt;
&lt;h2&gt;Flamingo&lt;/h2&gt;
&lt;h2&gt;Visual Instruction Tuning&lt;/h2&gt;
&lt;h2&gt;Qwen-VL&lt;/h2&gt;
&lt;h2&gt;Gemini&lt;/h2&gt;
&lt;h2&gt;GPT-4V&lt;/h2&gt;
&lt;h2&gt;LISA&lt;/h2&gt;
&lt;h2&gt;Cambrian-1&lt;/h2&gt;
&lt;h2&gt;Qwen2-VL&lt;/h2&gt;
&lt;h2&gt;Qwen2.5-VL&lt;/h2&gt;
&lt;h2&gt;InstructBLIP&lt;/h2&gt;
&lt;h2&gt;LLaMA-Adapter&lt;/h2&gt;
&lt;h2&gt;VisionLLM&lt;/h2&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-2.8vndvqvn7c.webp"/><enclosure url="https://pic.hana0721.top/rl-note-2.8vndvqvn7c.webp"/></item><item><title>Paper Reading: MLLM 2</title><link>https://claudiakim6827362.github.io/blog/paper-reading-mllm2</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/paper-reading-mllm2</guid><description>è¯»ä¸€äº›å¤šæ¨¡æ€ç›¸å…³çš„è®ºæ–‡</description><pubDate>Fri, 26 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;import { ArxivRating, RatingCriteria } from &apos;@/components/advanced&apos;&lt;/p&gt;
&lt;h2&gt;LLaVA-OneVision&lt;/h2&gt;
&lt;h2&gt;GPT 5&lt;/h2&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-2.8vndvqvn7c.webp"/><enclosure url="https://pic.hana0721.top/rl-note-2.8vndvqvn7c.webp"/></item><item><title>Paper Reading: Unify MLLM 1</title><link>https://claudiakim6827362.github.io/blog/paper-reading-umllm1</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/paper-reading-umllm1</guid><description>è¯»ä¸€äº›ç»Ÿä¸€å¤šæ¨¡æ€å¤§æ¨¡å‹ç›¸å…³çš„è®ºæ–‡</description><pubDate>Fri, 26 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;import { ArxivRating, RatingCriteria } from &apos;@/components/advanced&apos;&lt;/p&gt;
&lt;h2&gt;å‰è¨€&lt;/h2&gt;
&lt;p&gt;é€Ÿè§ˆä¸€äº›ç»Ÿä¸€å¤šæ¨¡æ€å¤§æ¨¡å‹çš„è®ºæ–‡ã€‚&lt;/p&gt;
&lt;h2&gt;SEED&lt;/h2&gt;
&lt;h2&gt;LaVIT&lt;/h2&gt;
&lt;h2&gt;SEED-X&lt;/h2&gt;
&lt;h2&gt;Emu&lt;/h2&gt;
&lt;h2&gt;Emu2&lt;/h2&gt;
&lt;h2&gt;Chameleon&lt;/h2&gt;
&lt;h2&gt;Transfusion&lt;/h2&gt;
&lt;h2&gt;Emu3&lt;/h2&gt;
&lt;h2&gt;MMAR&lt;/h2&gt;
&lt;h2&gt;Janus&lt;/h2&gt;
&lt;h2&gt;PUMA&lt;/h2&gt;
&lt;h2&gt;Show-o&lt;/h2&gt;
&lt;h2&gt;VILA-U&lt;/h2&gt;
&lt;h2&gt;MIO&lt;/h2&gt;
&lt;h2&gt;JanusFlow&lt;/h2&gt;
&lt;h2&gt;Orthus&lt;/h2&gt;
&lt;h2&gt;TokenFlow&lt;/h2&gt;
&lt;h2&gt;Liquid&lt;/h2&gt;
&lt;h2&gt;MUSE-VL&lt;/h2&gt;
&lt;h2&gt;SILMM&lt;/h2&gt;
&lt;h2&gt;ILLUME&lt;/h2&gt;
&lt;h2&gt;Visual Lexicon&lt;/h2&gt;
&lt;h2&gt;LatentLM&lt;/h2&gt;
&lt;h2&gt;SynerGen-VL&lt;/h2&gt;
&lt;h2&gt;MetaMorph&lt;/h2&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note.3yex1wenfg.webp"/><enclosure url="https://pic.hana0721.top/rl-note.3yex1wenfg.webp"/></item><item><title>Paper Reading: Unify MLLM 1</title><link>https://claudiakim6827362.github.io/blog/paper-reading-umllm2</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/paper-reading-umllm2</guid><description>è¯»ä¸€äº›ç»Ÿä¸€å¤šæ¨¡æ€å¤§æ¨¡å‹ç›¸å…³çš„è®ºæ–‡</description><pubDate>Fri, 26 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;import { ArxivRating, RatingCriteria } from &apos;@/components/advanced&apos;&lt;/p&gt;
&lt;h2&gt;å‰è¨€&lt;/h2&gt;
&lt;p&gt;é€Ÿè§ˆä¸€äº›ç»Ÿä¸€å¤šæ¨¡æ€å¤§æ¨¡å‹çš„è®ºæ–‡ã€‚&lt;/p&gt;
&lt;h2&gt;LMFusion&lt;/h2&gt;
&lt;h2&gt;UniToken&lt;/h2&gt;
&lt;h2&gt;VARGPT&lt;/h2&gt;
&lt;h2&gt;Janus-Pro&lt;/h2&gt;
&lt;h2&gt;BLIP3-o&lt;/h2&gt;
&lt;h2&gt;Show-o2&lt;/h2&gt;
&lt;h2&gt;Qwen-Image&lt;/h2&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note.3yex1wenfg.webp"/><enclosure url="https://pic.hana0721.top/rl-note.3yex1wenfg.webp"/></item><item><title>RLç¬”è®°ï¼ˆ20ï¼‰ï¼šDecision Transformer</title><link>https://claudiakim6827362.github.io/blog/rl-note-20</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/rl-note-20</guid><description>èŒƒå¼è½¬ç§»ï¼šå½“å¼ºåŒ–å­¦ä¹ é‡ä¸Š Transformerã€‚è¯¦è§£ Decision Transformer å¦‚ä½•æŠ›å¼ƒè´å°”æ›¼æ–¹ç¨‹ï¼Œåˆ©ç”¨ Return-to-Go å°† RL é‡æ„ä¸ºæ¡ä»¶åºåˆ—å»ºæ¨¡é—®é¢˜ã€‚</description><pubDate>Mon, 29 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;å¼•è¨€ï¼ˆIntroductionï¼‰&lt;/h2&gt;
&lt;p&gt;åœ¨ä¹‹å‰çš„ç¬”è®°ä¸­ï¼Œæ— è®ºæ˜¯æœ‰æ¨¡å‹è¿˜æ˜¯æ— æ¨¡å‹ï¼Œåœ¨çº¿è¿˜æ˜¯ç¦»çº¿ï¼Œæˆ‘ä»¬è§£å†³ RL é—®é¢˜çš„æ ¸å¿ƒæ€è·¯éƒ½æ˜¯åŸºäº &lt;strong&gt;åŠ¨æ€è§„åˆ’ (Dynamic Programming)&lt;/strong&gt; çš„ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;æˆ‘ä»¬è¦ä¼°è®¡ä»·å€¼å‡½æ•° $V(s)$ æˆ– $Q(s,a)$ã€‚&lt;/li&gt;
&lt;li&gt;åˆ©ç”¨è´å°”æ›¼æ–¹ç¨‹è¿›è¡Œè¿­ä»£æ›´æ–°ï¼ˆè‡ªä¸¾ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;é€šè¿‡æœ€å¤§åŒ–ä»·å€¼æ¥è·å¾—ç­–ç•¥ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Decision Transformer (DT)&lt;/strong&gt; æå‡ºäº†ä¸€ç§å®Œå…¨ä¸åŒçš„è§†è§’ï¼š
å¦‚æœæˆ‘ä»¬æ‹¥æœ‰å¤§é‡çš„ç¦»çº¿è½¨è¿¹æ•°æ®ï¼Œä¸ºä»€ä¹ˆä¸æŠŠå®ƒçœ‹ä½œæ˜¯ä¸€ä¸ª &lt;strong&gt;åºåˆ—å»ºæ¨¡ (Sequence Modeling)&lt;/strong&gt; é—®é¢˜å‘¢ï¼Ÿ
å°±åƒ GPT é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ä¸€æ ·ï¼Œèƒ½ä¸èƒ½æ ¹æ®&lt;strong&gt;è¿‡å»çš„è½¨è¿¹&lt;/strong&gt;å’Œ&lt;strong&gt;æœŸæœ›çš„å›æŠ¥&lt;/strong&gt;ï¼Œç›´æ¥é¢„æµ‹&lt;strong&gt;ä¸‹ä¸€ä¸ªåŠ¨ä½œ&lt;/strong&gt;ï¼Ÿ&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;æ ¸å¿ƒæ€æƒ³&lt;/strong&gt;ï¼š
å¼ºåŒ–å­¦ä¹  $\approx$ åœ¨ç»™å®š&lt;strong&gt;æœŸæœ›å›æŠ¥ (Target Return)&lt;/strong&gt; æ¡ä»¶ä¸‹çš„&lt;strong&gt;è¡Œä¸ºå…‹éš† (Conditional Behavior Cloning)&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2&gt;è½¨è¿¹è¡¨ç¤ºä¸ Return-to-Go&lt;/h2&gt;
&lt;p&gt;ä¸ºäº†å°† RL é—®é¢˜è½¬åŒ–ä¸º Transformer å¯ä»¥å¤„ç†çš„åºåˆ—é—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦é‡æ–°å®šä¹‰æ¨¡å‹çš„è¾“å…¥ã€‚&lt;/p&gt;
&lt;h3&gt;è½¨è¿¹ (Trajectory)&lt;/h3&gt;
&lt;p&gt;ä¸€æ¡æ ‡å‡†çš„ RL è½¨è¿¹ç”±çŠ¶æ€ã€åŠ¨ä½œå’Œå¥–åŠ±ç»„æˆï¼š
$$ \tau = (s_1, a_1, r_1, s_2, a_2, r_2, \dots, s_T, a_T, r_T) $$&lt;/p&gt;
&lt;h3&gt;å‰©ä½™å›æŠ¥ (Return-to-Go, RTG)&lt;/h3&gt;
&lt;p&gt;ä¼ ç»Ÿçš„ RL ä½¿ç”¨å³æ—¶å¥–åŠ± $r_t$ã€‚ä½†åœ¨åšåºåˆ—é¢„æµ‹æ—¶ï¼Œæˆ‘ä»¬æ›´å…³å¿ƒâ€œ&lt;strong&gt;æœªæ¥è¿˜èƒ½æ‹¿å¤šå°‘åˆ†&lt;/strong&gt;â€ã€‚
å®šä¹‰ $t$ æ—¶åˆ»çš„ &lt;strong&gt;Return-to-Go (RTG)&lt;/strong&gt; $\hat{R}_t$ ä¸ºä»å½“å‰æ—¶åˆ»åˆ°å›åˆç»“æŸçš„ç´¯ç§¯å›æŠ¥ï¼š
$$
\hat{R}&lt;em&gt;t = \sum&lt;/em&gt;{k=t}^T r_k
$$&lt;/p&gt;
&lt;h3&gt;æ¨¡å‹çš„è¾“å…¥åºåˆ—&lt;/h3&gt;
&lt;p&gt;DT çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå°† RTG ä½œä¸ºä¸€ç§&lt;strong&gt;æ¡ä»¶ (Condition)&lt;/strong&gt; è¾“å…¥ç»™æ¨¡å‹ã€‚
è¾“å…¥åºåˆ—è¢«ç»„ç»‡ä¸ºä¸‰å…ƒç»„çš„åºåˆ—ï¼ˆK-V-Q æ¨¡å¼ï¼‰ï¼š
$$
\tau_{input} = (\hat{R}_1, s_1, a_1, \hat{R}_2, s_2, a_2, \dots, \hat{R}_T, s_T, a_T)
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç›´è§‰&lt;/strong&gt;ï¼šè¿™å°±åƒæ˜¯åœ¨å‘Šè¯‰æ¨¡å‹ï¼šâ€œæˆ‘ç°åœ¨çŠ¶æ€æ˜¯ $s_1$ï¼Œæˆ‘æƒ³åœ¨æœªæ¥æ€»å…±è·å¾— $\hat{R}_1$ åˆ†ï¼Œè¯·å‘Šè¯‰æˆ‘è¯¥åšä»€ä¹ˆåŠ¨ä½œ $a_1$ï¼Ÿâ€&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;ç½‘ç»œæ¶æ„&lt;/h2&gt;
&lt;p&gt;DT ç›´æ¥ä½¿ç”¨äº† &lt;strong&gt;GPT (Generative Pre-trained Transformer)&lt;/strong&gt; çš„æ¶æ„ï¼Œå³å› æœæ©ç  Transformer (Causal Transformer)ã€‚&lt;/p&gt;
&lt;h3&gt;åµŒå…¥å±‚ (Embeddings)&lt;/h3&gt;
&lt;p&gt;ç”±äº $R, s, a$ çš„æ¨¡æ€ä¸åŒï¼ˆæ ‡é‡ã€å›¾åƒ/å‘é‡ã€ç¦»æ•£/è¿ç»­ï¼‰ï¼Œæˆ‘ä»¬éœ€è¦å…ˆå°†å®ƒä»¬æ˜ å°„åˆ°åŒä¸€ä¸ªç»´åº¦ $d$ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;çŠ¶æ€åµŒå…¥&lt;/strong&gt;ï¼šCNN æˆ– MLP å¤„ç† $s_t$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åŠ¨ä½œåµŒå…¥&lt;/strong&gt;ï¼šEmbedding å±‚æˆ– MLP å¤„ç† $a_t$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å›æŠ¥åµŒå…¥&lt;/strong&gt;ï¼šMLP å¤„ç† $\hat{R}_t$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ—¶é—´æ­¥åµŒå…¥ (Timestep Embedding)&lt;/strong&gt;ï¼šä¸ºäº†è®©æ¨¡å‹çŸ¥é“å½“å‰å¤„äºè½¨è¿¹çš„å“ªä¸ªé˜¶æ®µï¼Œé¢å¤–åŠ å…¥ä¸€ä¸ªå¯å­¦ä¹ çš„æ—¶é—´ä½ç½®ç¼–ç ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;ä¸Šä¸‹æ–‡çª—å£ (Context Window)&lt;/h3&gt;
&lt;p&gt;ç”±äºè½¨è¿¹å¯èƒ½å¾ˆé•¿ï¼ŒTransformer æ— æ³•å¤„ç†æ•´ä¸ª Episodeã€‚DT ä½¿ç”¨ä¸€ä¸ªå›ºå®šçš„ä¸Šä¸‹æ–‡çª—å£ $K$ï¼ˆcontext lengthï¼‰ï¼ŒåªæŠŠæœ€è¿‘çš„ $K$ æ­¥è¾“å…¥æ¨¡å‹ï¼š
$$
\text{Input}&lt;em&gt;t = [\hat{R}&lt;/em&gt;{t-K}, s_{t-K}, a_{t-K}, \dots, \hat{R}_t, s_t]
$$&lt;/p&gt;
&lt;h3&gt;é¢„æµ‹ç›®æ ‡&lt;/h3&gt;
&lt;p&gt;æ¨¡å‹çš„ç›®æ ‡æ˜¯é¢„æµ‹ä¸‹ä¸€ä¸ª tokenã€‚åœ¨ DT ä¸­ï¼Œæˆ‘ä»¬ä¸»è¦å…³æ³¨é¢„æµ‹&lt;strong&gt;åŠ¨ä½œ&lt;/strong&gt; $a_t$ã€‚
$$
a_t = \text{DecisionTransformer}(\hat{R}&lt;em&gt;{t-K}, s&lt;/em&gt;{t-K}, a_{t-K}, \dots, \hat{R}_t, s_t)
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;è®­ç»ƒä¸æ¨æ–­&lt;/h2&gt;
&lt;h3&gt;è®­ç»ƒ (Training)&lt;/h3&gt;
&lt;p&gt;DT çš„è®­ç»ƒè¿‡ç¨‹å®Œå…¨æ˜¯&lt;strong&gt;ç›‘ç£å­¦ä¹  (Supervised Learning)&lt;/strong&gt;ï¼Œä¸éœ€è¦è®¡ç®—æ¢¯åº¦ï¼Œä¸éœ€è¦è´å°”æ›¼è¯¯å·®ï¼Œä¸éœ€è¦ç›®æ ‡ç½‘ç»œã€‚&lt;/p&gt;
&lt;p&gt;ä»ç¦»çº¿æ•°æ®é›† $\mathcal{D}$ ä¸­é‡‡æ ·è½¨è¿¹ç‰‡æ®µï¼Œæœ€å°åŒ–é¢„æµ‹åŠ¨ä½œä¸çœŸå®åŠ¨ä½œçš„è¯¯å·®ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç¦»æ•£åŠ¨ä½œ&lt;/strong&gt;ï¼šäº¤å‰ç†µæŸå¤± (Cross-Entropy Loss)ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è¿ç»­åŠ¨ä½œ&lt;/strong&gt;ï¼šå‡æ–¹è¯¯å·® (MSE Loss)ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
\mathcal{L}(\theta) = \mathbb{E}&lt;em&gt;{\tau \sim \mathcal{D}} \left[ \sum&lt;/em&gt;{t=1}^T (a_t - \hat{a}_t)^2 \right]
$$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;ğŸ’¡ æ³¨æ„&lt;/strong&gt;ï¼šè™½ç„¶æ•°æ®é›†ä¸­å¯èƒ½åŒ…å«ä½åˆ†çš„è½¨è¿¹ï¼ˆâ€œè‡­æ£‹â€ï¼‰ï¼Œä½†æ¨¡å‹å­¦ä¹ çš„æ˜¯æ¡ä»¶æ¦‚ç‡ $P(a_t | \hat{R}_t, s_t, \dots)$ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæ¨¡å‹å­¦ä¼šäº†â€œå¦‚æœæƒ³è¦ä½åˆ†è¯¥æ€ä¹ˆåšâ€ä»¥åŠâ€œå¦‚æœæƒ³è¦é«˜åˆ†è¯¥æ€ä¹ˆåšâ€ã€‚&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;æ¨æ–­ (Inference)&lt;/h3&gt;
&lt;p&gt;è¿™æ˜¯ DT æœ€ç¥å¥‡çš„åœ°æ–¹ã€‚è®­ç»ƒå®Œæˆåï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡&lt;strong&gt;æç¤º (Prompting)&lt;/strong&gt; æ¥æ§åˆ¶æ™ºèƒ½ä½“ã€‚&lt;/p&gt;
&lt;p&gt;æˆ‘ä»¬ç»™æ™ºèƒ½ä½“è®¾å®šä¸€ä¸ª&lt;strong&gt;ç›®æ ‡å›æŠ¥ (Target Return)&lt;/strong&gt; $\hat{R}_{target}$ï¼ˆé€šå¸¸è®¾ä¸ºæ•°æ®é›†ä¸­æœ€é«˜åˆ†çš„é‚£ä¸ªå›æŠ¥ï¼Œæˆ–è€…æ›´é«˜ï¼‰ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;è‡ªå›å½’ç”Ÿæˆè¿‡ç¨‹&lt;/strong&gt;ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;åˆå§‹æ—¶åˆ» $t=1$&lt;/strong&gt;ï¼šè¾“å…¥ $(\hat{R}_{target}, s_1)$ï¼Œæ¨¡å‹è¾“å‡ºåŠ¨ä½œ $a_1$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç¯å¢ƒäº¤äº’&lt;/strong&gt;ï¼šæ‰§è¡Œ $a_1$ï¼Œç¯å¢ƒè¿”å›å³æ—¶å¥–åŠ± $r_1$ å’Œæ–°çŠ¶æ€ $s_2$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ›´æ–°ç›®æ ‡&lt;/strong&gt;ï¼šæ—¢ç„¶å·²ç»æ‹¿åˆ°äº† $r_1$ï¼Œå‰©ä¸‹çš„ç›®æ ‡å°±è¦å‡å»å®ƒï¼š
$$ \hat{R}_2 = \hat{R}_1 - r_1 $$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä¸‹ä¸€æ—¶åˆ»&lt;/strong&gt;ï¼šè¾“å…¥ $(\dots, \hat{R}_1, s_1, a_1, \hat{R}_2, s_2)$ï¼Œé¢„æµ‹ $a_2$ã€‚&lt;/li&gt;
&lt;li&gt;é‡å¤ç›´è‡³ç»“æŸã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2&gt;ç†è®ºå¯¹æ¯”ï¼šDT vs. CQL&lt;/h2&gt;
&lt;p&gt;ä¸ºäº†ç†è§£ DT çš„ä½ç½®ï¼Œæˆ‘ä»¬å°†å®ƒä¸ä¸Šä¸€ç¯‡ç¬”è®°ä¸­çš„ CQL è¿›è¡Œå¯¹æ¯”ï¼š&lt;/p&gt;
&lt;p&gt;| ç»´åº¦ | Conservative Q-Learning (CQL) | Decision Transformer (DT) |
| :--- | :--- | :--- |
| &lt;strong&gt;æ ¸å¿ƒèŒƒå¼&lt;/strong&gt; | &lt;strong&gt;åŠ¨æ€è§„åˆ’ (DP)&lt;/strong&gt; | &lt;strong&gt;åºåˆ—å»ºæ¨¡ (SL)&lt;/strong&gt; |
| &lt;strong&gt;å­¦ä¹ ç›®æ ‡&lt;/strong&gt; | é€¼è¿‘æœ€ä¼˜ä»·å€¼å‡½æ•° $Q^*(s,a)$ | æ‹Ÿåˆæ¡ä»¶åˆ†å¸ƒ $P(a|\hat{R}, s)$ |
| &lt;strong&gt;è®­ç»ƒæ–¹å¼&lt;/strong&gt; | æœ€å°åŒ–è´å°”æ›¼è¯¯å·® (TD Error) | æœ€å¤§åŒ–åŠ¨ä½œä¼¼ç„¶ (Supervised) |
| &lt;strong&gt;OOD å¤„ç†&lt;/strong&gt; | æ˜¾å¼æƒ©ç½šæœªçŸ¥åŠ¨ä½œçš„ Q å€¼ (æ‚²è§‚ä¸»ä¹‰) | ä¾é  Transformer çš„æ³›åŒ–èƒ½åŠ› (æ— æ˜¾å¼çº¦æŸ) |
| &lt;strong&gt;é•¿æ—¶åºä¿¡ç”¨åˆ†é…&lt;/strong&gt; | ä¾é  $Q$ å€¼çš„è‡ªä¸¾ä¼ æ’­ (Bootstrapping) | ä¾é  Attention æœºåˆ¶ç›´æ¥å…³è”è¿‡å»ä¸æœªæ¥ |
| &lt;strong&gt;ä¼˜ç‚¹&lt;/strong&gt; | ç†è®ºä¸‹ç•Œä¿è¯ï¼Œæ“…é•¿æ‹¼æ¥è½¨è¿¹ (Stitching) | è®­ç»ƒæå…¶ç¨³å®šï¼Œæ˜“äºæ‰©å±•ï¼Œèƒ½å¤Ÿå¤„ç†ç¨€ç–å¥–åŠ± |&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;æ€»ç»“&lt;/h2&gt;
&lt;p&gt;Decision Transformer çš„æå‡ºè¯æ˜äº†ï¼š&lt;strong&gt;åªè¦æ¨¡å‹è¶³å¤Ÿå¼ºï¼ˆTransformerï¼‰ï¼Œå¼ºåŒ–å­¦ä¹ å¯ä»¥è¢«ç®€åŒ–ä¸ºç›‘ç£å­¦ä¹ ã€‚&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å®ƒä¸éœ€è¦å¤æ‚çš„ Actor-Critic æ¶æ„ã€‚&lt;/li&gt;
&lt;li&gt;å®ƒä¸éœ€è¦å¤„ç†â€œè¿‡é«˜ä¼°è®¡â€ç­‰æ­»æ¿çš„æ•°å€¼é—®é¢˜ã€‚&lt;/li&gt;
&lt;li&gt;å®ƒé€šè¿‡ &lt;strong&gt;Return-to-Go&lt;/strong&gt; å®ç°äº†ç±»ä¼¼äºâ€œäº‹åè¯¸è‘›äº®â€çš„æ¡ä»¶æ§åˆ¶ï¼šåˆ©ç”¨è¿™ä¸€å±€æœ€ç»ˆçš„å¾—åˆ†ä½œä¸ºæ¡ä»¶ï¼Œæ¥å­¦ä¹ è¿™ä¸€å±€ä¸­çš„åŠ¨ä½œã€‚&lt;/li&gt;
&lt;/ul&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-3.3yex1xdpri.webp"/><enclosure url="https://pic.hana0721.top/rl-note-3.3yex1xdpri.webp"/></item><item><title>RLç¬”è®°ï¼ˆ19ï¼‰ï¼šç¦»çº¿å¼ºåŒ–å­¦ä¹  (Offline RL)</title><link>https://claudiakim6827362.github.io/blog/rl-note-19</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/rl-note-19</guid><description>æ•°æ®é©±åŠ¨çš„å¼ºåŒ–å­¦ä¹ ï¼šå½“ä¸èƒ½ä¸ç¯å¢ƒäº¤äº’æ—¶ï¼Œå¦‚ä½•ä»é™æ€æ•°æ®é›†ä¸­å­¦ä¹ ï¼Ÿæ·±åº¦è§£æåˆ†å¸ƒåç§» (Distribution Shift) é—®é¢˜ï¼Œä»¥åŠ BCQ å’Œ CQL ç®—æ³•çš„ç†è®ºæ¨å¯¼ã€‚</description><pubDate>Sun, 28 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;å¼•è¨€ï¼ˆIntroductionï¼‰&lt;/h2&gt;
&lt;p&gt;åœ¨ä¹‹å‰çš„ç« èŠ‚ï¼ˆDQN, SAC, DDPGï¼‰ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºçš„éƒ½æ˜¯ &lt;strong&gt;åœ¨çº¿ (Online)&lt;/strong&gt; æˆ– &lt;strong&gt;ç¦»çº¿ç­–ç•¥ (Off-Policy)&lt;/strong&gt; ç®—æ³•ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Online&lt;/strong&gt;: è¾¹ç©è¾¹å­¦ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Off-Policy&lt;/strong&gt;: å¯ä»¥åˆ©ç”¨ä¹‹å‰çš„ç»éªŒå›æ”¾æ± ï¼ˆReplay Bufferï¼‰ï¼Œä½†ä»ç„¶éœ€è¦ä¸æ–­ä¸ç¯å¢ƒäº¤äº’æ¥è¡¥å……æ–°æ•°æ®ï¼Œçº æ­£ä»·å€¼ä¼°è®¡ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ç¦»çº¿å¼ºåŒ–å­¦ä¹  (Offline RL)&lt;/strong&gt;ï¼Œåˆç§° Batch RLï¼Œé¢ä¸´çš„æ˜¯ä¸€ä¸ªæ›´ä¸¥è‹›çš„åœºæ™¯ï¼š
&lt;strong&gt;æ™ºèƒ½ä½“å®Œå…¨ä¸èƒ½ä¸ç¯å¢ƒäº¤äº’ï¼Œåªèƒ½ä»ä¸€ä¸ªå›ºå®šçš„ã€å†å²çš„æ•°æ®é›† $\mathcal{D}$ ä¸­å­¦ä¹ ç­–ç•¥ã€‚&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;è¿™å°±åƒæ˜¯â€œä»…ä»…é€šè¿‡çœ‹åˆ«äººä¸‹æ£‹çš„æ£‹è°±ï¼ˆè€Œä¸”å¯èƒ½å«æœ‰è‡­æ£‹ï¼‰ï¼Œå°±è¦å­¦ä¼šæˆä¸ºæ£‹åœ£â€ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;æ ¸å¿ƒæŒ‘æˆ˜ï¼šåˆ†å¸ƒåç§» (Distribution Shift)&lt;/h2&gt;
&lt;p&gt;æ—¢ç„¶ Off-Policy ç®—æ³•ï¼ˆå¦‚ SACï¼‰å¯ä»¥ä½¿ç”¨ Replay Bufferï¼Œä¸ºä»€ä¹ˆä¸èƒ½ç›´æ¥æŠŠé™æ€æ•°æ®é›† $\mathcal{D}$ å½“ä½œ Buffer è·‘ SAC å‘¢ï¼Ÿ&lt;/p&gt;
&lt;p&gt;ç­”æ¡ˆæ˜¯ï¼š&lt;strong&gt;å¤–æ¨è¯¯å·® (Extrapolation Error)&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;h3&gt;è´å°”æ›¼æ›´æ–°çš„é™·é˜±&lt;/h3&gt;
&lt;p&gt;å›é¡¾ Q-Learning çš„è´å°”æ›¼æ›´æ–°ç›®æ ‡ï¼š
$$
\mathcal{T}Q(s, a) = r + \gamma \max_{a&apos;} Q(s&apos;, a&apos;)
$$
æˆ–è€… Actor-Critic ä¸­çš„ï¼š
$$
y = r + \gamma Q(s&apos;, \pi(s&apos;))
$$&lt;/p&gt;
&lt;p&gt;è¿™é‡Œå­˜åœ¨ä¸€ä¸ªè‡´å‘½çš„ &lt;strong&gt;åäº‹å®æŸ¥è¯¢ (Counterfactual Query)&lt;/strong&gt; é—®é¢˜ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;æ•°æ®é›† $\mathcal{D}$ æ˜¯ç”±è¡Œä¸ºç­–ç•¥ $\pi_\beta$ äº§ç”Ÿçš„ã€‚&lt;/li&gt;
&lt;li&gt;æˆ‘ä»¬å­¦ä¹ çš„æ–°ç­–ç•¥ $\pi$ é€šå¸¸ä¼šä¸ $\pi_\beta$ ä¸åŒï¼ˆä¸ºäº†å˜å¾—æ›´å¥½ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;åœ¨è®¡ç®—ç›®æ ‡å€¼æ—¶ï¼Œæˆ‘ä»¬éœ€è¦æŸ¥è¯¢ $Q(s&apos;, \pi(s&apos;))$ã€‚&lt;/li&gt;
&lt;li&gt;å¦‚æœ $\pi(s&apos;)$ é€‰å‡ºçš„åŠ¨ä½œ $a&apos;$ &lt;strong&gt;ä»æœªåœ¨æ•°æ®é›† $\mathcal{D}$ ä¸­å‡ºç°è¿‡&lt;/strong&gt;ï¼ˆOOD, Out-of-Distributionï¼‰ï¼ŒQ ç½‘ç»œå¯¹è¿™ä¸ªä»æœªè§è¿‡çš„ $(s&apos;, a&apos;)$ ä¼šè¾“å‡ºä»€ä¹ˆï¼Ÿ
&lt;ul&gt;
&lt;li&gt;æ ¹æ®ç¥ç»ç½‘ç»œçš„ç‰¹æ€§ï¼Œå®ƒä¼šè¾“å‡ºä¸€ä¸ªéšæœºçš„ã€æ— æ„ä¹‰çš„å€¼ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æœ€å¤§åŒ–çš„è¯…å’’&lt;/strong&gt;ï¼šç”±äº $\max$ æ“ä½œçš„å­˜åœ¨ï¼Œä¼˜åŒ–å™¨ä¼šå€¾å‘äºé€‰æ‹©é‚£äº›è¢«&lt;strong&gt;é”™è¯¯é«˜ä¼°&lt;/strong&gt;çš„ OOD åŠ¨ä½œã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è¯¯å·®ä¼ æ’­&lt;/strong&gt;ï¼šè¿™ä¸ªé«˜ä¼°çš„è¯¯å·®ä¼šé€šè¿‡è´å°”æ›¼æ–¹ç¨‹å›ä¼ ï¼Œå¯¼è‡´æ•´ä¸ª Q å‡½æ•°å´©æºƒã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;è¿™å°±æ˜¯ &lt;strong&gt;åˆ†å¸ƒåç§»&lt;/strong&gt;ï¼šè®­ç»ƒæ•°æ®çš„åˆ†å¸ƒ $(s, a) \sim \pi_\beta$ ä¸å­¦ä¹ ç­–ç•¥çš„åˆ†å¸ƒ $(s, a) \sim \pi$ ä¸ä¸€è‡´ï¼Œå¯¼è‡´ Q å€¼åœ¨æœªçŸ¥åŒºåŸŸä¸¥é‡é«˜ä¼°ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;è§£å†³æ–¹æ¡ˆä¸€ï¼šåŸºäºçº¦æŸçš„æ–¹æ³• (BCQ)&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;BCQ (Batch-Constrained deep Q-learning)&lt;/strong&gt; çš„æ€è·¯éå¸¸ç›´è§‚ï¼š
æ—¢ç„¶ OOD åŠ¨ä½œä¼šå¯¼è‡´ Q å€¼é«˜ä¼°ï¼Œé‚£æˆ‘å°±&lt;strong&gt;ç¦æ­¢æ™ºèƒ½ä½“é€‰æ‹©é‚£äº›åœ¨æ•°æ®é›†ä¸­æ²¡å‡ºç°è¿‡çš„åŠ¨ä½œ&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;h3&gt;ç†è®ºæ¨å¯¼&lt;/h3&gt;
&lt;p&gt;æˆ‘ä»¬å¸Œæœ›ä¼˜åŒ–ç­–ç•¥ $\pi$ï¼Œä½¿å…¶åœ¨æœ€å¤§åŒ– $Q$ å€¼çš„åŠ¨ä½œï¼ŒåŒæ—¶æ»¡è¶³å®ƒç”Ÿæˆçš„åŠ¨ä½œåˆ†å¸ƒæ¥è¿‘è¡Œä¸ºç­–ç•¥ $\pi_\beta$ï¼š
$$
\pi(s) = \arg\max_{a} Q(s,a) \quad \text{s.t.} \quad P(a|s, \mathcal{D}) &gt; \tau
$$&lt;/p&gt;
&lt;h3&gt;ç®—æ³•å®ç°é€»è¾‘&lt;/h3&gt;
&lt;p&gt;ç”±äº $\pi_\beta$ æœªçŸ¥ï¼ŒBCQ è®­ç»ƒä¸€ä¸ª &lt;strong&gt;ç”Ÿæˆæ¨¡å‹ (VAE)&lt;/strong&gt; æ¥æ‹Ÿåˆæ•°æ®é›†ä¸­çš„çŠ¶æ€-åŠ¨ä½œåˆ†å¸ƒã€‚&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;ç”Ÿæˆ (Generation)&lt;/strong&gt;ï¼šä½¿ç”¨ CVAE æ ¹æ®çŠ¶æ€ $s$ ç”Ÿæˆä¸€ç»„â€œåœ¨è¯¥çŠ¶æ€ä¸‹å¯èƒ½å‡ºç°è¿‡çš„â€å€™é€‰åŠ¨ä½œ ${a_1, \dots, a_n}$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ‰°åŠ¨ (Perturbation)&lt;/strong&gt;ï¼šè®­ç»ƒä¸€ä¸ªæ‰°åŠ¨ç½‘ç»œ $\xi_\phi(s,a)$ï¼Œå¯¹ç”Ÿæˆçš„åŠ¨ä½œè¿›è¡Œå¾®è°ƒï¼ˆåœ¨å°èŒƒå›´å†…å¯»æ‰¾æ›´ä¼˜è§£ï¼‰ï¼Œå¾—åˆ° ${a_1+\xi_1, \dots, a_n+\xi_n}$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;é€‰æ‹© (Selection)&lt;/strong&gt;ï¼šåœ¨è¿™äº›åŠ¨ä½œä¸­ï¼Œé€‰æ‹© Q å€¼æœ€å¤§çš„é‚£ä¸ªä½œä¸ºæœ€ç»ˆè¾“å‡ºã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;ğŸ’¡ è¯„ä»·&lt;/strong&gt;ï¼šBCQ æ˜¯ä¸€ç§ä¿å®ˆç­–ç•¥ï¼Œå®ƒæ¶ˆé™¤äº†å¤–æ¨è¯¯å·®ï¼Œä½†ä¹Ÿé™åˆ¶äº†ç­–ç•¥çš„æ³›åŒ–èƒ½åŠ›ï¼ˆåªèƒ½åœ¨è§è¿‡çš„æ•°æ®é™„è¿‘å¾®è°ƒï¼‰ã€‚&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2&gt;è§£å†³æ–¹æ¡ˆäºŒï¼šåŸºäºä»·å€¼çš„ä¿å®ˆæ–¹æ³• (CQL)&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;CQL (Conservative Q-Learning)&lt;/strong&gt; æ˜¯ç›®å‰ç†è®ºæœ€å®Œå¤‡çš„ Offline RL ç®—æ³•ä¹‹ä¸€ã€‚
å®ƒçš„æ€è·¯æ˜¯ï¼š&lt;strong&gt;ä¿®æ”¹è´å°”æ›¼æ›´æ–°çš„ç›®æ ‡å‡½æ•°ï¼Œæ˜¾å¼åœ°æƒ©ç½š OOD åŠ¨ä½œçš„ Q å€¼ã€‚&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;ç›®æ ‡å‡½æ•°è®¾è®¡&lt;/h3&gt;
&lt;p&gt;æ ‡å‡†çš„è´å°”æ›¼è¯¯å·®æ˜¯æœ€å°åŒ– $\mathbb{E}_{(s,a)\sim\mathcal{D}} [(Q - \mathcal{T}Q)^2]$ã€‚
CQL å¢åŠ äº†ä¸€ä¸ªæ­£åˆ™é¡¹ï¼Œç”¨äº&lt;strong&gt;æœ€å°åŒ–&lt;/strong&gt;ç­–ç•¥ $\mu$ï¼ˆæ–°ç­–ç•¥ï¼‰äº§ç”Ÿçš„åŠ¨ä½œçš„ Q å€¼ï¼ŒåŒæ—¶&lt;strong&gt;æœ€å¤§åŒ–&lt;/strong&gt;æ•°æ®é›† $\mathcal{D}$ ä¸­åŠ¨ä½œçš„ Q å€¼ï¼š&lt;/p&gt;
&lt;p&gt;$$
\min_Q \alpha \left( \underbrace{\mathbb{E}&lt;em&gt;{s\sim\mathcal{D}, a\sim\mu(a|s)} [Q(s,a)]}&lt;/em&gt;{\text{å‹ä½ OOD åŠ¨ä½œçš„ Q å€¼}} - \underbrace{\mathbb{E}&lt;em&gt;{s\sim\mathcal{D}, a\sim\pi&lt;/em&gt;\beta(a|s)} [Q(s,a)]}&lt;em&gt;{\text{æ‹‰é«˜æ•°æ®ä¸­åŠ¨ä½œçš„ Q å€¼}} \right) + \frac{1}{2} \mathbb{E}&lt;/em&gt;{\mathcal{D}} [(Q - \mathcal{B}^{\pi}Q)^2]
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\mu(a|s)$ï¼šå¯ä»¥æ˜¯å½“å‰å­¦ä¹ çš„ç­–ç•¥ï¼Œä¹Ÿå¯ä»¥æ˜¯éšæœºåˆ†å¸ƒã€‚&lt;/li&gt;
&lt;li&gt;é€šè¿‡è¿™ç§â€œå‹ä½æœªçŸ¥ï¼Œæ‹‰é«˜å·²çŸ¥â€ï¼ŒCQL è¿«ä½¿ Q å‡½æ•°åœ¨ OOD åŒºåŸŸäº§ç”Ÿä½ä¼°ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;ç†è®ºæ¨å¯¼ï¼šQ å€¼ä¸‹ç•Œ (Lower Bound)&lt;/h3&gt;
&lt;p&gt;CQL çš„æ ¸å¿ƒç†è®ºè´¡çŒ®åœ¨äºè¯æ˜äº†ä¸Šè¿°ç›®æ ‡å‡½æ•°å­¦ä¹ åˆ°çš„ Q å€¼ $\hat{Q}$ æ˜¯çœŸå® Q å€¼ $Q^\pi$ çš„&lt;strong&gt;ä¸‹ç•Œ&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;p&gt;ä»¤ $\mathcal{B}^\pi$ ä¸ºè´å°”æ›¼ç®—å­ã€‚CQL çš„ä¸åŠ¨ç‚¹è¿­ä»£å¯ä»¥è¿‘ä¼¼å†™ä½œï¼š
$$
\hat{Q}_{k+1} \leftarrow \mathcal{B}^\pi \hat{Q}&lt;em&gt;k - \alpha (\mu - \pi&lt;/em&gt;\beta)
$$
(è¿™é‡Œçœç•¥äº†å¤æ‚çš„é‡‡æ ·è¯¯å·®é¡¹ï¼Œä»…å…³æ³¨æœŸæœ›è¡Œä¸º)&lt;/p&gt;
&lt;p&gt;å½“ $\alpha$ è¶³å¤Ÿå¤§æ—¶ï¼Œå¯ä»¥è¯æ˜ï¼š
$$
\mathbb{E}&lt;em&gt;{\pi(a|s)} [\hat{Q}(s,a)] \le \mathbb{E}&lt;/em&gt;{\pi(a|s)} [Q^\pi(s,a)]
$$&lt;/p&gt;
&lt;p&gt;è¿™æ„å‘³ç€ CQL å­¦ä¹ åˆ°çš„ Q å€¼æ˜¯&lt;strong&gt;ä¿å®ˆçš„ (Conservative)&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å¦‚æœç­–ç•¥æƒ³å»ä¸€ä¸ªæœªçŸ¥åŒºåŸŸï¼ŒCQL ä¼šå‘Šè¯‰å®ƒï¼šâ€œé‚£ä¸ªåœ°æ–¹ Q å€¼å¾ˆä½ï¼ˆå“ªæ€•å®é™…ä¸Šå¯èƒ½å¾ˆé«˜ï¼‰â€ã€‚&lt;/li&gt;
&lt;li&gt;å› æ­¤ï¼Œç­–ç•¥ä¼šå€¾å‘äºç•™åœ¨æ•°æ®è¦†ç›–çš„â€œå®‰å…¨åŒºåŸŸâ€å†…ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;å¹¿ä¹‰ CQL (Generalization)&lt;/h3&gt;
&lt;p&gt;å¯¹äºè¿ç»­åŠ¨ä½œç©ºé—´ï¼ŒCQL å°†ç¬¬ä¸€é¡¹æ­£åˆ™åŒ–æ”¹ä¸º $\log\sum\exp$ å½¢å¼ï¼ˆSoft-maxï¼‰ï¼Œä»¥è¦†ç›–æ‰€æœ‰å¯èƒ½çš„åŠ¨ä½œï¼š&lt;/p&gt;
&lt;p&gt;$$
\min_Q \alpha \mathbb{E}&lt;em&gt;{s \sim \mathcal{D}} \left[ \log \sum_a \exp(Q(s,a)) - \mathbb{E}&lt;/em&gt;{a \sim \pi_\beta}[Q(s,a)] \right] + \text{Bellman Error}
$$&lt;/p&gt;
&lt;p&gt;è¿™ç­‰ä»·äºå‹ä½æ•´ä¸ª Q å€¼å‡½æ•°çš„é…åˆ†å‡½æ•°ï¼Œç¡®ä¿æ²¡æœ‰ä»»ä½•ä¸€ä¸ª OOD åŠ¨ä½œèƒ½ç”±äºå¤–æ¨è¯¯å·®è€Œè·å¾—å¼‚å¸¸é«˜çš„ Q å€¼ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;æ€»ç»“ï¼šä»ä¹è§‚åˆ°æ‚²è§‚&lt;/h2&gt;
&lt;p&gt;| ç»´åº¦ | åœ¨çº¿/ç¦»çº¿ç­–ç•¥ RL (DQN/SAC) | ç¦»çº¿ RL (Offline RL) |
| :--- | :--- | :--- |
| &lt;strong&gt;å¿ƒæ€&lt;/strong&gt; | &lt;strong&gt;ä¹è§‚ (Optimistic)&lt;/strong&gt; | &lt;strong&gt;æ‚²è§‚ (Pessimistic) / ä¿å®ˆ&lt;/strong&gt; |
| &lt;strong&gt;å¯¹å¾…æœªçŸ¥&lt;/strong&gt; | æœªçŸ¥åŠ¨ä½œ = æ½œåœ¨çš„é«˜å›æŠ¥ (æ¢ç´¢çº¢åˆ©) | æœªçŸ¥åŠ¨ä½œ = æ½œåœ¨çš„é£é™© (å¤–æ¨è¯¯å·®) |
| &lt;strong&gt;æ ¸å¿ƒç®—æ³•&lt;/strong&gt; | $\max Q$ | $\max Q$ s.t. $a \in \mathcal{D}$ (BCQ)  $\min Q_{OOD}$ (CQL) |
| &lt;strong&gt;é€‚ç”¨åœºæ™¯&lt;/strong&gt; | æ¨¡æ‹Ÿå™¨ã€ä½æˆæœ¬è¯•é”™ç¯å¢ƒ | åŒ»ç–—ã€å·¥ä¸šæ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶ (è¯•é”™æˆæœ¬æé«˜) |&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ç¦»çº¿å¼ºåŒ–å­¦ä¹ çš„æœ¬è´¨&lt;/strong&gt;ï¼š
åœ¨æ— æ³•éªŒè¯çœŸä¼ªçš„æƒ…å†µä¸‹ï¼Œ&lt;strong&gt;å®å¯é”™è¿‡ï¼ˆä½ä¼°ï¼‰ï¼Œä¸å¯åšé”™ï¼ˆé«˜ä¼°ï¼‰ã€‚&lt;/strong&gt; åªæœ‰å½“æ•°æ®å……åˆ†è¯æ˜æŸä¸ªç­–ç•¥å¥½æ—¶ï¼Œæˆ‘ä»¬æ‰æ•¢ä¿¡ä»»å®ƒã€‚&lt;/p&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-3.3yex1xdpri.webp"/><enclosure url="https://pic.hana0721.top/rl-note-3.3yex1xdpri.webp"/></item><item><title>RLç¬”è®°ï¼ˆ18ï¼‰ï¼šåŸºäºæ¨¡å‹çš„ç­–ç•¥ä¼˜åŒ– (MBPO)</title><link>https://claudiakim6827362.github.io/blog/rl-note-18</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/rl-note-18</guid><description>Model-Based RL çš„é›†å¤§æˆè€…ï¼šæ·±åº¦è§£æ MBPO çš„ç†è®ºè¾¹ç•Œã€‚ä»å•è°ƒæ€§ä¿è¯åˆ°åˆ†æ”¯æ¨æ¼” (Branched Rollout)ï¼Œè®ºè¯å¦‚ä½•é€šè¿‡æ§åˆ¶æ¨æ¼”æ­¥é•¿æ¥è§£å†³æ¨¡å‹åå·®å¸¦æ¥çš„äºŒæ¬¡è¯¯å·®ç´¯ç§¯é—®é¢˜ã€‚</description><pubDate>Sat, 27 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;å¼•è¨€ï¼ˆIntroductionï¼‰&lt;/h2&gt;
&lt;p&gt;åœ¨å¼ºåŒ–å­¦ä¹ çš„è°±ç³»ä¸­ï¼Œå­˜åœ¨ä¸€å¯¹çŸ›ç›¾ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Model-Free (å¦‚ SAC)&lt;/strong&gt;ï¼šæ¸è¿›æ€§èƒ½å¥½ï¼ˆèƒ½æ”¶æ•›åˆ°å¾ˆé«˜çš„åˆ†æ•°ï¼‰ï¼Œä½†æ ·æœ¬æ•ˆç‡æä½ï¼ˆéœ€è¦å‡ ç™¾ä¸‡æ¬¡äº¤äº’ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Model-Based (å¦‚ Dyna)&lt;/strong&gt;ï¼šæ ·æœ¬æ•ˆç‡é«˜ï¼ˆåˆ©ç”¨æ¨¡å‹ç”Ÿæˆæ•°æ®ï¼‰ï¼Œä½†å¾€å¾€å—é™äº&lt;strong&gt;æ¨¡å‹åå·® (Model Bias)&lt;/strong&gt;ï¼Œå¯¼è‡´æ¸è¿›æ€§èƒ½è¾ƒå·®ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;æ¨¡å‹åå·®çš„è¯…å’’&lt;/strong&gt;åœ¨äºï¼šæ¨¡å‹ä¹Ÿæ˜¯ä»æ•°æ®ä¸­æ‹Ÿåˆå‡ºæ¥çš„ï¼Œå®ƒå¿…ç„¶å­˜åœ¨è¯¯å·®ã€‚å½“æ™ºèƒ½ä½“åœ¨æ¨¡å‹ä¸­è¿›è¡Œé•¿è·ç¦»æ¨æ¼”æ—¶ï¼Œå¾®å°çš„è¯¯å·®ä¼šåƒæ»šé›ªçƒä¸€æ ·è¿…é€Ÿæ”¾å¤§ï¼ˆCompound Errorï¼‰ï¼Œå¯¼è‡´æ™ºèƒ½ä½“åœ¨â€œè™šæ„çš„å®Œç¾ä¸–ç•Œâ€é‡Œè¡¨ç°å¾ˆå¥½ï¼Œä½†åœ¨â€œæ®‹é…·çš„ç°å®ä¸–ç•Œâ€é‡Œä¸€å¡Œç³Šæ¶‚ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MBPO (Model-Based Policy Optimization)&lt;/strong&gt; çš„æ ¸å¿ƒè´¡çŒ®åœ¨äºå®ƒé€šè¿‡ä¸¥æ ¼çš„ç†è®ºæ¨å¯¼ï¼Œå®šé‡åœ°åˆ†æäº†æ¨¡å‹è¯¯å·®ä¸ç­–ç•¥æ€§èƒ½çš„å…³ç³»ï¼Œå¹¶æå‡ºäº†ä¸€ç§&lt;strong&gt;åˆ†æ”¯æ¨æ¼” (Branched Rollout)&lt;/strong&gt; æœºåˆ¶ï¼Œåœ¨ä¿è¯å•è°ƒæå‡çš„å‰æä¸‹ï¼Œæœ€å¤§åŒ–åœ°åˆ©ç”¨æ¨¡å‹ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;ç†è®ºæ¨å¯¼ï¼šå›æŠ¥å·®çš„ä¸Šç•Œ&lt;/h2&gt;
&lt;p&gt;æˆ‘ä»¬å¸Œæœ›æ‰¾åˆ°ä¸€ä¸ªç­–ç•¥ $\pi$ï¼Œæœ€å¤§åŒ–çœŸå®ç¯å¢ƒä¸­çš„æœŸæœ›å›æŠ¥ $\eta[\pi]$ã€‚
ä½†æˆ‘ä»¬åªèƒ½ä¼˜åŒ–æ¨¡å‹ç¯å¢ƒä¸­çš„æœŸæœ›å›æŠ¥ $\hat{\eta}[\pi]$ã€‚
æˆ‘ä»¬éœ€è¦æ¨å¯¼ä¸¤è€…ä¹‹é—´çš„è¯¯å·®ä¸Šç•Œï¼Œä»è€Œæ‰¾åˆ°ä¸€ä¸ªå®‰å…¨ä¼˜åŒ–çš„ &lt;strong&gt;ä¸‹ç•Œ (Lower Bound)&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;h3&gt;å®šä¹‰ä¸å‡è®¾&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;çœŸå®ç¯å¢ƒçš„çŠ¶æ€è½¬ç§»åˆ†å¸ƒï¼š$p(s&apos;|s,a)$&lt;/li&gt;
&lt;li&gt;å­¦ä¹ æ¨¡å‹çš„çŠ¶æ€è½¬ç§»åˆ†å¸ƒï¼š$\hat{p}(s&apos;|s,a)$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ¨¡å‹è¯¯å·® $\epsilon_m$&lt;/strong&gt;ï¼šå‡è®¾æ¨¡å‹åœ¨åˆ†å¸ƒä¸Šçš„æœ€å¤§è¯¯å·®æ˜¯æœ‰ç•Œçš„ï¼ˆTV æ•£åº¦ï¼‰ï¼š
$$ \max_{s,a} D_{TV}(p(\cdot|s,a) || \hat{p}(\cdot|s,a)) \le \epsilon_m $$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;çŠ¶æ€åˆ†å¸ƒçš„å·®å¼‚&lt;/h3&gt;
&lt;p&gt;ç­–ç•¥ $\pi$ åœ¨çœŸå®åŠ¨åŠ›å­¦ä¸‹çš„çŠ¶æ€è®¿é—®åˆ†å¸ƒä¸º $\rho_\pi$ï¼Œåœ¨æ¨¡å‹åŠ¨åŠ›å­¦ä¸‹çš„çŠ¶æ€è®¿é—®åˆ†å¸ƒä¸º $\hat{\rho}&lt;em&gt;\pi$ã€‚
æ ¹æ® &lt;em&gt;Simulation Lemma&lt;/em&gt;ï¼Œä¸¤è€…ä¹‹é—´çš„å·®å¼‚ä¸Šç•Œä¸ºï¼š
$$
D&lt;/em&gt;{TV}(\rho_\pi || \hat{\rho}_\pi) \le \frac{\gamma \epsilon_m}{(1-\gamma)^2}
$$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;âš ï¸ è­¦ç¤º&lt;/strong&gt;ï¼šæ³¨æ„è¿™é‡Œçš„ $(1-\gamma)^2$ã€‚è¿™æ„å‘³ç€çŠ¶æ€åˆ†å¸ƒçš„è¯¯å·®æ˜¯éšç€æ—¶é—´è§†ç•Œï¼ˆHorizonï¼‰&lt;strong&gt;äºŒæ¬¡æ–¹&lt;/strong&gt;å¢é•¿çš„ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆåœ¨ä¼ ç»Ÿ Model-Based RL ä¸­ï¼Œé•¿è·ç¦»æ¨æ¼”ä¼šå¯¼è‡´æå…¶ä¸¥é‡çš„åå·®ã€‚&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;çœŸå®å›æŠ¥ä¸æ¨¡å‹å›æŠ¥çš„å·®å¼‚&lt;/h3&gt;
&lt;p&gt;åŸºäºä¸Šè¿°çŠ¶æ€åˆ†å¸ƒå·®å¼‚ï¼Œæˆ‘ä»¬å¯ä»¥æ¨å¯¼å‡ºçœŸå®å›æŠ¥ $\eta[\pi]$ ä¸æ¨¡å‹å›æŠ¥ $\hat{\eta}[\pi]$ çš„å·®å€¼ä¸Šç•Œï¼š
$$
\left| \eta[\pi] - \hat{\eta}[\pi] \right| \le 2 r_{\max} \frac{\gamma \epsilon_m}{(1-\gamma)^2}
$$&lt;/p&gt;
&lt;p&gt;è¿™ä¸ªä¸Šç•Œå‘Šè¯‰æˆ‘ä»¬ï¼šå¦‚æœæˆ‘ä»¬åªæ˜¯ç®€å•åœ°è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œç„¶ååœ¨æ¨¡å‹é‡Œä»å¤´è·‘åˆ°å°¾ï¼ˆFull Rolloutï¼‰æ¥è®­ç»ƒç­–ç•¥ï¼Œé‚£ä¹ˆçœŸå®æ€§èƒ½å’Œæ¨¡å‹æ€§èƒ½çš„å·®è·å¯èƒ½ä¼šéå¸¸å¤§ï¼Œä¼˜åŒ– $\hat{\eta}$ å¹¶ä¸ä»£è¡¨èƒ½æå‡ $\eta$ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;æ ¸å¿ƒçªç ´ï¼šåˆ†æ”¯æ¨æ¼” (Branched Rollout)&lt;/h2&gt;
&lt;p&gt;ä¸ºäº†æ‰“ç ´ä¸Šè¿°çš„â€œäºŒæ¬¡æ–¹è¯¯å·®è¯…å’’â€ï¼ŒMBPO æå‡ºæ”¹å˜æ¨æ¼”çš„æ–¹å¼ã€‚&lt;/p&gt;
&lt;h3&gt;ä»€ä¹ˆæ˜¯åˆ†æ”¯æ¨æ¼”ï¼Ÿ&lt;/h3&gt;
&lt;p&gt;ä¼ ç»Ÿçš„ Dyna é£æ ¼æ˜¯ä»åˆå§‹çŠ¶æ€ $s_0$ å¼€å§‹ï¼Œä¸€ç›´æ¨æ¼”åˆ° $s_T$ã€‚
MBPO çš„ &lt;strong&gt;$k$-æ­¥åˆ†æ”¯æ¨æ¼”&lt;/strong&gt; æ˜¯ï¼š
ä»ç­–ç•¥åœ¨&lt;strong&gt;çœŸå®ç¯å¢ƒ&lt;/strong&gt;ä¸­è®¿é—®è¿‡çš„çŠ¶æ€åˆ†å¸ƒ $\mathcal{D}_{\text{env}}$ ä¸­é‡‡æ ·ä¸€ä¸ªçŠ¶æ€ $s$ï¼Œä½œä¸ºæ¨æ¼”çš„èµ·ç‚¹ï¼Œç„¶åä»…åœ¨æ¨¡å‹ä¸­æ¨æ¼” $k$ æ­¥ã€‚&lt;/p&gt;
&lt;h3&gt;ä¿®æ­£åçš„è¯¯å·®è¾¹ç•Œ&lt;/h3&gt;
&lt;p&gt;åœ¨ $k$-æ­¥åˆ†æ”¯æ¨æ¼”ä¸‹ï¼Œå›æŠ¥å·®çš„ä¸Šç•Œè¢«æ˜¾è‘—æ”¶ç´§äº†ï¼š
$$
\left| \eta[\pi] - \hat{\eta}&lt;em&gt;k[\pi] \right| \le 2 r&lt;/em&gt;{\max} \left[ \frac{\gamma^{k+1} \epsilon_\pi}{(1-\gamma)^2} + \frac{\gamma^k \epsilon_m}{1-\gamma} + \frac{k}{1-\gamma}\epsilon_m \right]
$$
&lt;em&gt;(æ³¨ï¼šå…¬å¼ç•¥ä½œç®€åŒ–ä»¥ç›´è§‚å±•ç¤ºæ ¸å¿ƒé¡¹)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;å…³é”®åœ¨äºæœ€åä¸€é¡¹ $\frac{k}{1-\gamma}\epsilon_m$ã€‚
è¿™è¡¨æ˜ï¼š&lt;strong&gt;åœ¨åˆ†æ”¯æ¨æ¼”ä¸‹ï¼Œæ¨¡å‹è¯¯å·® $\epsilon_m$ å¯¹æ€»å›æŠ¥è¯¯å·®çš„è´¡çŒ®æ˜¯éš $k$ çº¿æ€§å¢é•¿çš„ï¼Œè€Œä¸æ˜¯äºŒæ¬¡æ–¹å¢é•¿ã€‚&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;$k$ çš„æƒè¡¡ (Trade-off)&lt;/h3&gt;
&lt;p&gt;è¿™ä¸ªç†è®ºè¾¹ç•Œæ­ç¤ºäº†è¶…å‚æ•° $k$ çš„ç‰©ç†æ„ä¹‰ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å½“ $k$ å¾ˆå°æ—¶&lt;/strong&gt;ï¼šè¯¯å·®ç•Œå¾ˆç´§ï¼ˆçº¿æ€§ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥æ”¾å¿ƒåœ°ä¿¡ä»»æ¨¡å‹æ•°æ®ã€‚ä½†æ˜¯æ¨¡å‹èƒ½æä¾›çš„â€œè¿œè§â€æœ‰é™ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å½“ $k$ å¾ˆå¤§æ—¶&lt;/strong&gt;ï¼šè¯¯å·®ç•Œå˜æ¾ï¼ˆè¶‹å‘äºŒæ¬¡æ–¹ï¼‰ï¼Œæ¨¡å‹åå·®å¼€å§‹ä¸»å¯¼ï¼Œå¯¼è‡´ç­–ç•¥æ€§èƒ½ä¸‹é™ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;å› æ­¤ï¼ŒMBPO åŠ¨æ€è°ƒæ•´ $k$ï¼šåœ¨è®­ç»ƒåˆæœŸæ¨¡å‹ä¸å‡†æ—¶ï¼Œ$k=1$ï¼›éšç€æ¨¡å‹ç²¾åº¦æé«˜ï¼Œé€æ¸å¢åŠ  $k$ï¼ˆé€šå¸¸ä» 1 å¢åŠ åˆ° 15 å·¦å³ï¼‰ï¼Œåœ¨ä¿è¯åå·®å¯æ§çš„å‰æä¸‹æœ€å¤§åŒ–åˆ©ç”¨æ¨¡å‹ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;ç®—æ³•æ¶æ„è®¾è®¡&lt;/h2&gt;
&lt;p&gt;MBPO çš„å®ç°æ˜¯å›´ç»•ä¸Šè¿°ç†è®ºæ„å»ºçš„ï¼Œç”±ä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—ç»„æˆã€‚&lt;/p&gt;
&lt;h3&gt;æ¦‚ç‡æ¨¡å‹é›†æˆ (Ensemble of Probabilistic Models)&lt;/h3&gt;
&lt;p&gt;ä¸ºäº†å‡†ç¡®ä¼°è®¡æ¨¡å‹è¯¯å·®å¹¶é˜²æ­¢è¿‡æ‹Ÿåˆï¼ŒMBPO è®­ç»ƒä¸€ç»„ï¼ˆå¦‚ 7 ä¸ªï¼‰é«˜æ–¯æ¦‚ç‡ç½‘ç»œã€‚
$$ \hat{p}&lt;em&gt;\theta(s&apos;|s,a) = \mathcal{N}(\mu&lt;/em&gt;\theta(s,a), \Sigma_\theta(s,a)) $$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä¸ç¡®å®šæ€§æ„ŸçŸ¥&lt;/strong&gt;ï¼šé¢„æµ‹æ—¶éšæœºä»é›†æˆæ¨¡å‹ä¸­é€‰æ‹©ä¸€ä¸ªæˆå‘˜ï¼Œè¿™æ¨¡æ‹Ÿäº†è´å¶æ–¯åéªŒé‡‡æ ·ï¼Œèƒ½å¤Ÿæ•æ‰&lt;strong&gt;è®¤çŸ¥ä¸ç¡®å®šæ€§ (Epistemic Uncertainty)&lt;/strong&gt;ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;æ··åˆç­–ç•¥ä¼˜åŒ– (Model-Based Policy Optimization)&lt;/h3&gt;
&lt;p&gt;MBPO ä½¿ç”¨ &lt;strong&gt;SAC (Soft Actor-Critic)&lt;/strong&gt; ä½œä¸ºåº•å±‚çš„ç­–ç•¥ä¼˜åŒ–å™¨ã€‚
ä¸ºäº†å…‹æœæ¨¡å‹åå·®ï¼ŒSAC çš„è®­ç»ƒæ•°æ®ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;çœŸå®æ•°æ® $\mathcal{D}_{\text{env}}$&lt;/strong&gt;ï¼šå æ¯”å¾ˆå°ï¼ˆå¦‚ 5%ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ¨¡å‹æ•°æ® $\mathcal{D}_{\text{model}}$&lt;/strong&gt;ï¼šç”±åˆ†æ”¯æ¨æ¼”äº§ç”Ÿçš„æµ·é‡æ•°æ®ï¼Œå æ¯”å¾ˆå¤§ï¼ˆå¦‚ 95%ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;ç®—æ³•æµç¨‹ (ä¼ªä»£ç )&lt;/h3&gt;
&lt;p&gt;$$
\begin{aligned}
&amp;#x26; \bullet ; \text{Initialize policy } \pi_\phi, \text{ ensemble models } {p_{\theta_1}, \dots, p_{\theta_B}} \
&amp;#x26; \bullet ; \text{Initialize empty buffers } \mathcal{D}&lt;em&gt;{\text{env}}, \mathcal{D}&lt;/em&gt;{\text{model}} \
&amp;#x26; \bullet ; \textbf{For } N \text{ epochs} \textbf{ do}: \
&amp;#x26; \bullet \qquad \textbf{1. Collect Real Data (Exploration)} \
&amp;#x26; \bullet \qquad \text{Rollout policy in real environment, add transitions to } \mathcal{D}&lt;em&gt;{\text{env}} \
&amp;#x26; \bullet \qquad \textbf{2. Train Models (Supervised Learning)} \
&amp;#x26; \bullet \qquad \text{Train ensemble } {p&lt;/em&gt;\theta} \text{ on } \mathcal{D}&lt;em&gt;{\text{env}} \text{ via Max Likelihood} \
&amp;#x26; \bullet \qquad \textbf{3. Branched Rollout (Data Augmentation)} \
&amp;#x26; \bullet \qquad \text{Sample states } s \sim \mathcal{D}&lt;/em&gt;{\text{env}} \
&amp;#x26; \bullet \qquad \text{Rollout } k \text{ steps using models, add to } \mathcal{D}&lt;em&gt;{\text{model}} \
&amp;#x26; \bullet \qquad \textbf{4. Policy Optimization (SAC)} \
&amp;#x26; \bullet \qquad \textbf{For } G \text{ gradient steps} \textbf{ do}: \
&amp;#x26; \bullet \qquad \qquad \text{Sample batch } B \text{ from } \mathcal{D}&lt;/em&gt;{\text{env}} \cup \mathcal{D}&lt;em&gt;{\text{model}} \text{ (e.g., 95% model data)} \
&amp;#x26; \bullet \qquad \qquad \text{Update } \pi&lt;/em&gt;\phi, Q_\psi \text{ using SAC loss} \
&amp;#x26; \bullet \qquad \textbf{End For} \
&amp;#x26; \bullet ; \textbf{End For}
\end{aligned}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;æ€»ç»“ï¼šMBPO çš„å¯ç¤º&lt;/h2&gt;
&lt;p&gt;MBPO æ˜¯ Model-Based RL çš„ä¸€ä¸ªè½¬æŠ˜ç‚¹ï¼Œå®ƒé€šè¿‡ç†è®ºè¯æ˜å›ç­”äº†**â€œæˆ‘ä»¬è¯¥å¤šå¤§ç¨‹åº¦ä¿¡ä»»æ¨¡å‹ï¼Ÿâ€**è¿™ä¸ªé—®é¢˜ã€‚&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;å•è°ƒæ€§ä¿è¯&lt;/strong&gt;ï¼šé€šè¿‡é™åˆ¶æ¨æ¼”æ­¥é•¿ $k$ï¼ŒMBPO å°†æ¨¡å‹è¯¯å·®æ§åˆ¶åœ¨çº¿æ€§å¢é•¿èŒƒå›´å†…ï¼Œä»è€Œä¿è¯äº†ç­–ç•¥æ”¹è¿›çš„å•è°ƒæ€§ï¼ˆç±»ä¼¼ TRPO çš„ Trust Region æ€æƒ³ï¼Œä½†åº”ç”¨åœ¨ Rollout Length ä¸Šï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ•°æ®å¢å¼º&lt;/strong&gt;ï¼šMBPO æœ¬è´¨ä¸Šæ˜¯æŠŠå­¦åˆ°çš„æ¨¡å‹å½“ä½œä¸€ä¸ª&lt;strong&gt;è¶…çº§æ•°æ®å¢å¼ºå™¨&lt;/strong&gt;ã€‚å®ƒä»æœ‰é™çš„çœŸå®æ•°æ®å‡ºå‘ï¼Œé€šè¿‡çŸ­æ­¥æ¨æ¼”ï¼Œæ‰©æ•£å‡ºæµ·é‡çš„è™šæ‹Ÿæ•°æ®ä¾› SAC è®­ç»ƒã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç»“æœ&lt;/strong&gt;ï¼šMBPO åœ¨ MuJoCo ç­‰åŸºå‡†æµ‹è¯•ä¸­ï¼Œä»¥ 1/10 ç”šè‡³æ›´å°‘çš„æ ·æœ¬é‡ï¼Œè¾¾åˆ°äº†ä¸ SAC ç›¸å½“çš„æ¸è¿›æ€§èƒ½ï¼Œæ‰“ç ´äº†â€œModel-Based ä¹Ÿå°±æ˜¯å­¦å¾—å¿«ä½†åˆ†ä¸é«˜â€çš„åˆ»æ¿å°è±¡ã€‚&lt;/li&gt;
&lt;/ol&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-3.3yex1xdpri.webp"/><enclosure url="https://pic.hana0721.top/rl-note-3.3yex1xdpri.webp"/></item><item><title>Paper Reading: VLM 1</title><link>https://claudiakim6827362.github.io/blog/paper-reading-vlm1</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/paper-reading-vlm1</guid><description>ä»é›¶å¼€å§‹çš„VLMç ”ç©¶ç”Ÿæ´»ã€‚</description><pubDate>Fri, 26 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;import { ArxivRating, RatingCriteria } from &apos;@/components/advanced&apos;&lt;/p&gt;
&lt;h2&gt;å‰è¨€&lt;/h2&gt;
&lt;p&gt;æµ…æµ…å­¦ä¹ ä¸€ä¸‹VLMç›¸å…³çš„çŸ¥è¯†ã€‚&lt;/p&gt;</content:encoded><h:img src="https://pic.hana0721.top/dst-1.86u4d7doms.webp"/><enclosure url="https://pic.hana0721.top/dst-1.86u4d7doms.webp"/></item><item><title>Paper Reading: VLM 2</title><link>https://claudiakim6827362.github.io/blog/paper-reading-vlm2</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/paper-reading-vlm2</guid><description>ä»é›¶å¼€å§‹çš„VLMç ”ç©¶ç”Ÿæ´»ã€‚</description><pubDate>Fri, 26 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;import { ArxivRating, RatingCriteria } from &apos;@/components/advanced&apos;&lt;/p&gt;
&lt;h2&gt;å‰è¨€&lt;/h2&gt;
&lt;p&gt;æµ…æµ…å­¦ä¹ ä¸€ä¸‹VLMç›¸å…³çš„çŸ¥è¯†ã€‚&lt;/p&gt;</content:encoded><h:img src="https://pic.hana0721.top/dst-1.86u4d7doms.webp"/><enclosure url="https://pic.hana0721.top/dst-1.86u4d7doms.webp"/></item><item><title>Paper Reading: Basic Method 1</title><link>https://claudiakim6827362.github.io/blog/paper-reading-bm1</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/paper-reading-bm1</guid><description>ä»åŸºç¡€å¼€å§‹å§ï¼</description><pubDate>Fri, 26 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;import { ArxivRating, RatingCriteria } from &apos;@/components/advanced&apos;&lt;/p&gt;
&lt;h2&gt;å‰è¨€&lt;/h2&gt;
&lt;p&gt;è¿™é‡Œä¸»è¦æ˜¯ä¸€äº›æ¯”è¾ƒåŸºç¡€æ€§çš„æ–‡ç« ã€‚&lt;/p&gt;
&lt;h2&gt;VAE&lt;/h2&gt;
&lt;h2&gt;Transformer&lt;/h2&gt;
&lt;h2&gt;Diffusion&lt;/h2&gt;</content:encoded><h:img src="https://pic.hana0721.top/ppp1.szf66edwc.webp"/><enclosure url="https://pic.hana0721.top/ppp1.szf66edwc.webp"/></item><item><title>Paper Reading: CV 1</title><link>https://claudiakim6827362.github.io/blog/paper-reading-cv1</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/paper-reading-cv1</guid><description>æµ…åº¦ä¸€äº›è§†è§‰ç›¸å…³çš„å·¥ä½œ</description><pubDate>Fri, 26 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;import { ArxivRating, RatingCriteria } from &apos;@/components/advanced&apos;&lt;/p&gt;
&lt;h2&gt;å‰è¨€&lt;/h2&gt;
&lt;p&gt;è¿™é‡Œä¸»è¦æ˜¯ä¸€äº›æ¯”è¾ƒåŸºç¡€æ€§çš„æ–‡ç« ã€‚&lt;/p&gt;
&lt;h2&gt;AlexNet&lt;/h2&gt;
&lt;h2&gt;VGG&lt;/h2&gt;
&lt;h2&gt;ResNet&lt;/h2&gt;
&lt;h2&gt;PointNet&lt;/h2&gt;
&lt;h2&gt;PointNet++&lt;/h2&gt;
&lt;h2&gt;VGGT&lt;/h2&gt;</content:encoded><h:img src="https://pic.hana0721.top/xiaozha-yuki.13m9ao1ccd.webp"/><enclosure url="https://pic.hana0721.top/xiaozha-yuki.13m9ao1ccd.webp"/></item><item><title>Paper Reading: Embodied AI 4</title><link>https://claudiakim6827362.github.io/blog/paper-reading-eba4</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/paper-reading-eba4</guid><description>ä»é›¶å¼€å§‹çš„Embodied AIç ”ç©¶ç”Ÿæ´»ã€‚</description><pubDate>Fri, 26 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;import { ArxivRating, RatingCriteria } from &apos;@/components/advanced&apos;&lt;/p&gt;
&lt;p&gt;import { ManualTOC } from &apos;@/components/advanced&apos;&lt;/p&gt;
&lt;p&gt;&amp;#x3C;ManualTOC
title=&apos;&apos;
categories={[
{
title: &apos;Embodied AI Paper Reading&apos;,
items: [
{
title: &apos;Batch 1&apos;,
href: &apos;/blog/paper-reading-eba1&apos;,
order: &apos;1&apos;
},
{
title: &apos;Batch 2&apos;,
href: &apos;/blog/paper-reading-eba2&apos;,
order: &apos;2&apos;
},
{
title: &apos;Batch 3&apos;,
href: &apos;/blog/paper-reading-eba3&apos;,
order: &apos;3&apos;
},
{
title: &apos;Batch 4&apos;,
href: &apos;/blog/paper-reading-eba4&apos;,
order: &apos;4&apos;
}
]
}
]}
/&gt;&lt;/p&gt;
&lt;h2&gt;å‰è¨€&lt;/h2&gt;
&lt;p&gt;RLèœé¸¡å¼€å§‹è¿›å†›Embodied AIï¼Œæ…¢æ…¢ç§¯ç´¯ï¼Œæå‡è‡ªå·±ã€‚&lt;/p&gt;
&lt;h2&gt;4D-VLA&lt;/h2&gt;
&lt;h2&gt;D(R,O) Grasp&lt;/h2&gt;
&lt;h2&gt;Fast-in-Slow&lt;/h2&gt;
&lt;h2&gt;NavDP&lt;/h2&gt;
&lt;h2&gt;Nav $A^3$&lt;/h2&gt;
&lt;h2&gt;StreamVLN&lt;/h2&gt;
&lt;h2&gt;V-JEPA 2&lt;/h2&gt;
&lt;h2&gt;MolmoAct&lt;/h2&gt;
&lt;h2&gt;MimicGen&lt;/h2&gt;
&lt;h2&gt;SpatialVLA&lt;/h2&gt;
&lt;h2&gt;TraceVLA&lt;/h2&gt;
&lt;h2&gt;Hume&lt;/h2&gt;
&lt;h2&gt;RICL&lt;/h2&gt;
&lt;h2&gt;OmniVTLA&lt;/h2&gt;
&lt;h2&gt;Spatial Traces&lt;/h2&gt;
&lt;h2&gt;Embodied-R1&lt;/h2&gt;
&lt;h2&gt;RynnEC&lt;/h2&gt;
&lt;h2&gt;RoboRefer&lt;/h2&gt;
&lt;h2&gt;Discrete Diffusion VLA&lt;/h2&gt;
&lt;h2&gt;G0&lt;/h2&gt;
&lt;h2&gt;InternScenes&lt;/h2&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-3.3yex1xdpri.webp"/><enclosure url="https://pic.hana0721.top/rl-note-3.3yex1xdpri.webp"/></item><item><title>Paper Reading: Embodied AI 3</title><link>https://claudiakim6827362.github.io/blog/paper-reading-eba3</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/paper-reading-eba3</guid><description>ä»é›¶å¼€å§‹çš„Embodied AIç ”ç©¶ç”Ÿæ´»ã€‚</description><pubDate>Fri, 26 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;import { ArxivRating, RatingCriteria } from &apos;@/components/advanced&apos;&lt;/p&gt;
&lt;p&gt;import { ManualTOC } from &apos;@/components/advanced&apos;&lt;/p&gt;
&lt;p&gt;&amp;#x3C;ManualTOC
title=&apos;&apos;
categories={[
{
title: &apos;Embodied AI Paper Reading&apos;,
items: [
{
title: &apos;Batch 1&apos;,
href: &apos;/blog/paper-reading-eba1&apos;,
order: &apos;1&apos;
},
{
title: &apos;Batch 2&apos;,
href: &apos;/blog/paper-reading-eba2&apos;,
order: &apos;2&apos;
},
{
title: &apos;Batch 3&apos;,
href: &apos;/blog/paper-reading-eba3&apos;,
order: &apos;3&apos;
},
{
title: &apos;Batch 4&apos;,
href: &apos;/blog/paper-reading-eba4&apos;,
order: &apos;4&apos;
}
]
}
]}
/&gt;&lt;/p&gt;
&lt;h2&gt;å‰è¨€&lt;/h2&gt;
&lt;p&gt;RLèœé¸¡å¼€å§‹è¿›å†›Embodied AIï¼Œæ…¢æ…¢ç§¯ç´¯ï¼Œæå‡è‡ªå·±ã€‚&lt;/p&gt;
&lt;h2&gt;RoboVerse&lt;/h2&gt;
&lt;h2&gt;AgiBot World Colosseo&lt;/h2&gt;
&lt;h2&gt;UniVLA&lt;/h2&gt;
&lt;h2&gt;GraspVLA&lt;/h2&gt;
&lt;h2&gt;GRAPE&lt;/h2&gt;
&lt;h2&gt;A0&lt;/h2&gt;
&lt;h2&gt;OneTwoVLA&lt;/h2&gt;
&lt;h2&gt;RDT-1B&lt;/h2&gt;
&lt;h2&gt;Octo&lt;/h2&gt;
&lt;h2&gt;FAST&lt;/h2&gt;
&lt;h2&gt;Magma&lt;/h2&gt;
&lt;h2&gt;ChatVLA&lt;/h2&gt;
&lt;h2&gt;ChatVLA-2&lt;/h2&gt;
&lt;h2&gt;RoboBrain&lt;/h2&gt;
&lt;h2&gt;CoT-VLA&lt;/h2&gt;
&lt;h2&gt;Interleave-VLA&lt;/h2&gt;
&lt;h2&gt;Knowledge Insulating Vision-Language-Action Models&lt;/h2&gt;
&lt;h2&gt;Hi Robot&lt;/h2&gt;
&lt;h2&gt;Scenethesis&lt;/h2&gt;
&lt;h2&gt;LBM&lt;/h2&gt;
&lt;h2&gt;UniVLA&lt;/h2&gt;
&lt;h2&gt;SmolVLA&lt;/h2&gt;
&lt;h2&gt;ThinkAct&lt;/h2&gt;
&lt;h2&gt;VIDAR&lt;/h2&gt;
&lt;h2&gt;DreamVLA&lt;/h2&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-3.3yex1xdpri.webp"/><enclosure url="https://pic.hana0721.top/rl-note-3.3yex1xdpri.webp"/></item><item><title>Paper Reading: MARL 1</title><link>https://claudiakim6827362.github.io/blog/paper-reading-marl1</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/paper-reading-marl1</guid><description>å›æ¥å§MARLï¼Œæˆ‘æœ€éª„å‚²çš„ä¿¡ä»°ã€‚</description><pubDate>Fri, 26 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;import { ArxivRating, RatingCriteria } from &apos;@/components/advanced&apos;&lt;/p&gt;
&lt;h2&gt;å‰è¨€&lt;/h2&gt;
&lt;p&gt;åšä¸»åˆ¶ä½œè¿™ç¯‡åšå®¢æ—¶ï¼Œå·²å¼ƒå‘MARLï¼Œä»…ç•™ä½œçºªå¿µï¼Œæ€€å¿µæœ€åˆçš„æ„Ÿè§‰ã€‚&lt;/p&gt;
&lt;h2&gt;VDN&lt;/h2&gt;
&lt;h2&gt;QMIX&lt;/h2&gt;
&lt;h2&gt;Qatten&lt;/h2&gt;
&lt;h2&gt;QTRAN&lt;/h2&gt;
&lt;h2&gt;QPLEX&lt;/h2&gt;
&lt;h2&gt;RQN&lt;/h2&gt;
&lt;h2&gt;GraphMix&lt;/h2&gt;
&lt;h2&gt;Weighted QMIX&lt;/h2&gt;
&lt;h2&gt;MAVEN&lt;/h2&gt;
&lt;h2&gt;HAPPO&lt;/h2&gt;
&lt;h2&gt;MAT&lt;/h2&gt;
&lt;h2&gt;RODE&lt;/h2&gt;
&lt;h2&gt;EMC&lt;/h2&gt;
&lt;h2&gt;EMU&lt;/h2&gt;
&lt;h2&gt;HPN&lt;/h2&gt;</content:encoded><h:img src="https://pic.hana0721.top/basic-algorithm.lw77gyrtm.webp"/><enclosure url="https://pic.hana0721.top/basic-algorithm.lw77gyrtm.webp"/></item><item><title>RLç¬”è®°ï¼ˆ17ï¼‰ï¼šæ¨¡å‹é¢„æµ‹æ§åˆ¶ (MPC)</title><link>https://claudiakim6827362.github.io/blog/rl-note-17</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/rl-note-17</guid><description>åœ¨å·²çŸ¥ç¯å¢ƒæ¨¡å‹çš„æƒ…å†µä¸‹ï¼Œå¦‚ä½•é«˜æ•ˆè§„åˆ’ï¼Ÿè¯¦è§£æ¨¡å‹é¢„æµ‹æ§åˆ¶ (MPC) çš„åŸç†ï¼šé¢„æµ‹æœªæ¥ã€æ»šåŠ¨ä¼˜åŒ–ä¸MPC-SACã€‚</description><pubDate>Fri, 26 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;å¼•è¨€ï¼ˆIntroductionï¼‰&lt;/h2&gt;
&lt;p&gt;åœ¨ä¹‹å‰çš„ç¬”è®°ä¸­ï¼Œæˆ‘ä»¬æ¢è®¨äº†&lt;strong&gt;æ— æ¨¡å‹ (Model-Free)&lt;/strong&gt; ç®—æ³•ï¼ˆå¦‚ Q-Learning, PPO, SACï¼‰å¦‚ä½•é€šè¿‡è¯•é”™å­¦ä¹ ã€‚æˆ‘ä»¬ä¹Ÿåˆæ­¥æ¥è§¦äº†&lt;strong&gt;åŸºäºæ¨¡å‹ (Model-Based)&lt;/strong&gt; çš„ Dyna-Qï¼Œå®ƒé€šè¿‡å­¦ä¹ ç¯å¢ƒæ¨¡å‹æ¥ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®è¾…åŠ©å­¦ä¹ ã€‚&lt;/p&gt;
&lt;p&gt;ä»Šå¤©æˆ‘ä»¬æ·±å…¥ Model-Based RL çš„å¦ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼š&lt;strong&gt;æ¨¡å‹é¢„æµ‹æ§åˆ¶ (Model Predictive Control, MPC)&lt;/strong&gt;ã€‚
MPC çš„æ ¸å¿ƒä¼˜åŠ¿åœ¨äºï¼Œå®ƒ&lt;strong&gt;ç›´æ¥åˆ©ç”¨ç¯å¢ƒæ¨¡å‹è¿›è¡Œå‰å‘è§„åˆ’&lt;/strong&gt;ï¼Œåƒä¸€ä¸ªç»éªŒä¸°å¯Œçš„æ£‹æ‰‹ä¸€æ ·â€œé¢„åˆ¤â€æœªæ¥ï¼Œç„¶åæ ¹æ®é¢„æµ‹ç»“æœåšå‡ºå½“å‰æœ€ä¼˜çš„å†³ç­–ã€‚&lt;/p&gt;
&lt;p&gt;MPC ä¸ä»…ä»…æ˜¯ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ï¼ˆåƒ Dyna-Qï¼‰ï¼Œå®ƒæ˜¯åœ¨æ¯ä¸€ä¸ªçŠ¶æ€ä¸‹ï¼Œéƒ½&lt;strong&gt;é‡æ–°è§„åˆ’&lt;/strong&gt;ä¸€æ¬¡æœªæ¥çš„åŠ¨ä½œåºåˆ—ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;MPC çš„æ ¸å¿ƒæ€æƒ³&lt;/h2&gt;
&lt;p&gt;MPC æ˜¯ä¸€ç§æ§åˆ¶ç­–ç•¥ï¼Œå®ƒå‡è®¾æˆ‘ä»¬æ‹¥æœ‰ä¸€ä¸ªç²¾ç¡®çš„ç¯å¢ƒæ¨¡å‹ $M(s,a) \to (r, s&apos;)$ã€‚&lt;/p&gt;
&lt;h3&gt;é¢„æµ‹ä¸è§„åˆ’ (Prediction &amp;#x26; Planning)&lt;/h3&gt;
&lt;p&gt;åœ¨å½“å‰çŠ¶æ€ $s_t$ï¼ŒMPC å¹¶ä¸ç›´æ¥é€‰æ‹©ä¸€ä¸ªåŠ¨ä½œã€‚è€Œæ˜¯ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;é¢„æµ‹æœªæ¥&lt;/strong&gt;ï¼šå‡è®¾ä»å½“å‰çŠ¶æ€ $s_t$ å¼€å§‹ï¼Œæ‰§è¡Œä¸€ç³»åˆ—åŠ¨ä½œ $\pi = {a_t, a_{t+1}, \dots, a_{t+H}}$ï¼ˆç§°ä¸º&lt;strong&gt;é¢„æµ‹æ—¶åŸŸ (Prediction Horizon)&lt;/strong&gt; $H$ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ¨¡æ‹Ÿè½¨è¿¹&lt;/strong&gt;ï¼šåˆ©ç”¨æ¨¡å‹ $M$ï¼Œæ¨¡æ‹Ÿå‡ºè¿™ä¸€ç³»åˆ—åŠ¨ä½œå¯èƒ½äº§ç”Ÿçš„è½¨è¿¹åŠå…¶ç´¯ç§¯å¥–åŠ±ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜åŒ–è§„åˆ’&lt;/strong&gt;ï¼šæ‰¾åˆ°èƒ½æœ€å¤§åŒ–ç´¯ç§¯å¥–åŠ±çš„åŠ¨ä½œåºåˆ— $\pi^*$ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;æ»šåŠ¨ä¼˜åŒ– (Rolling Optimization)&lt;/h3&gt;
&lt;p&gt;MPC çš„å†³ç­–è¿‡ç¨‹æ˜¯&lt;strong&gt;æ»šåŠ¨&lt;/strong&gt;çš„ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;åœ¨çŠ¶æ€ $s_t$ï¼ŒMPC æ‰¾åˆ°æœ€ä¼˜åŠ¨ä½œåºåˆ— $\pi^* = {a_t^&lt;em&gt;, a_{t+1}^&lt;/em&gt;, \dots, a_{t+H}^*}$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åªæ‰§è¡Œç¬¬ä¸€ä¸ªåŠ¨ä½œ $a_t^*$&lt;/strong&gt;ã€‚&lt;/li&gt;
&lt;li&gt;æ™ºèƒ½ä½“è¿›å…¥æ–°çŠ¶æ€ $s_{t+1}$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;é‡æ–°è§„åˆ’&lt;/strong&gt;ï¼šåŸºäºæ–°çš„çŠ¶æ€ $s_{t+1}$ï¼Œé‡å¤æ­¥éª¤ 1-3ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;ğŸ’¡ ç›´è§‰&lt;/strong&gt;ï¼š
MPC å°±åƒä¸€ä¸ªæœ‰é¢„è§æ€§çš„å†³ç­–è€…ã€‚å®ƒä¸ä¼šä¸€æ¬¡æ€§æŠŠæ‰€æœ‰æ­¥éª¤éƒ½å®šæ­»ï¼Œè€Œæ˜¯æ¯èµ°ä¸€æ­¥ï¼Œéƒ½æ ¹æ®å½“å‰æƒ…å†µé‡æ–°è§„åˆ’ä¸‹ä¸€æ­¥çš„æœ€ä½³è·¯å¾„ã€‚è¿™ä½¿å¾—å®ƒèƒ½å¾ˆå¥½åœ°åº”å¯¹ç¯å¢ƒå˜åŒ–ã€‚&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2&gt;MPC ä¸å¼ºåŒ–å­¦ä¹ çš„ç»“åˆ&lt;/h2&gt;
&lt;p&gt;MPC æœ¬èº«æ˜¯ä¸€ç§æ§åˆ¶æ–¹æ³•ï¼Œå¦‚ä½•ä¸ RL ç»“åˆå‘¢ï¼Ÿ&lt;/p&gt;
&lt;h3&gt;å­¦ä¹ æ¨¡å‹&lt;/h3&gt;
&lt;p&gt;åœ¨ Model-Based RL ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦å­¦ä¹ ä¸€ä¸ªç¯å¢ƒæ¨¡å‹ $M_\theta$ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç›‘ç£å­¦ä¹ &lt;/strong&gt;ï¼šç”¨æ”¶é›†åˆ°çš„çœŸå®æ•°æ® $(s, a, r, s&apos;)$ æ¥è®­ç»ƒæ¨¡å‹ã€‚
&lt;ul&gt;
&lt;li&gt;é¢„æµ‹å¥–åŠ±ï¼š$r \approx R_\phi(s,a)$&lt;/li&gt;
&lt;li&gt;é¢„æµ‹çŠ¶æ€ï¼š$s&apos; \approx M_\theta(s,a)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ¨¡å‹ç±»å‹&lt;/strong&gt;ï¼šå¯ä»¥æ˜¯&lt;strong&gt;æ¦‚ç‡æ¨¡å‹&lt;/strong&gt;ï¼ˆå¦‚ PETS ä½¿ç”¨çš„æ¦‚ç‡ GP å›å½’ï¼‰æ¥ä¼°è®¡æ¨¡å‹çš„ä¸ç¡®å®šæ€§ï¼Œä¹Ÿå¯ä»¥æ˜¯ç¡®å®šæ€§æ¨¡å‹ï¼ˆå¦‚ç®€å•çš„ç¥ç»ç½‘ç»œï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;MPC è§„åˆ’&lt;/h3&gt;
&lt;p&gt;ä¸€æ—¦æœ‰äº†æ¨¡å‹ $M_\theta$ï¼Œå°±å¯ä»¥è¿›è¡Œè§„åˆ’ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;åœ¨å½“å‰çŠ¶æ€ $s_t$ï¼ŒMPC åœ¨æ‰€æœ‰å¯èƒ½çš„ $H$ æ­¥åŠ¨ä½œåºåˆ—ä¸­æœç´¢ï¼Œæ‰¾åˆ°èƒ½æœ€å¤§åŒ–æ¨¡æ‹Ÿç´¯ç§¯å¥–åŠ±çš„åºåˆ— $\pi^* = {a_t^&lt;em&gt;, a_{t+1}^&lt;/em&gt;, \dots, a_{t+H}^*}$ã€‚&lt;/li&gt;
&lt;li&gt;æ‰§è¡Œ $a_t^*$ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;ä¼˜åŒ–ç­–ç•¥&lt;/h3&gt;
&lt;p&gt;MPC äº§ç”Ÿçš„åŠ¨ä½œåºåˆ— $\pi^&lt;em&gt;$ æœ¬èº«å°±å¯ä»¥çœ‹ä½œæ˜¯å½“å‰çŠ¶æ€ä¸‹çš„ä¸€ä¸ªâ€œç­–ç•¥â€ã€‚æˆ‘ä»¬å¯ä»¥ç”¨æ ‡å‡†çš„ RL ç®—æ³•ï¼ˆå¦‚ PPO, SACï¼‰æ¥ä¼˜åŒ–**ç”Ÿæˆè¿™ä¸ª $\pi^&lt;/em&gt;$ çš„å‚æ•°**ã€‚&lt;/p&gt;
&lt;p&gt;ä¾‹å¦‚ï¼Œ&lt;strong&gt;MPC-SAC&lt;/strong&gt; çš„åšæ³•ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;è®­ç»ƒä¸€ä¸ªæ¨¡å‹&lt;/strong&gt; $M_\theta$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è®­ç»ƒ Actor-Critic&lt;/strong&gt;ï¼š
&lt;ul&gt;
&lt;li&gt;Critic å­¦ä¹  $Q$ å€¼ã€‚&lt;/li&gt;
&lt;li&gt;Actor å­¦ä¹ ç­–ç•¥ $\pi_\phi$ã€‚&lt;/li&gt;
&lt;li&gt;åœ¨ Actor çš„æ›´æ–°æ—¶ï¼Œ&lt;strong&gt;ä½¿ç”¨ MPC è§„åˆ’ $H$ æ­¥&lt;/strong&gt;ï¼Œè·å¾—æ›´å‡†ç¡®çš„å¥–åŠ±ä¿¡å·æ¥æ›´æ–° Actorã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2&gt;PETS ç®—æ³•ç¤ºä¾‹ (Probabilistic Embeded Trajectory Sampling)&lt;/h2&gt;
&lt;p&gt;PETS æ˜¯ä¸€ä¸ªç»å…¸çš„ Model-Based RL ç®—æ³•ï¼Œå®ƒä½¿ç”¨äº†&lt;strong&gt;æ¦‚ç‡æ¨¡å‹&lt;/strong&gt;æ¥å¤„ç†æ¨¡å‹ä¸ç¡®å®šæ€§ã€‚&lt;/p&gt;
&lt;h3&gt;æ¦‚ç‡æ¨¡å‹&lt;/h3&gt;
&lt;p&gt;PETS ä½¿ç”¨&lt;strong&gt;é«˜æ–¯è¿‡ç¨‹ (Gaussian Process, GP)&lt;/strong&gt; æˆ–å…¶ä»–æ¦‚ç‡æ¨¡å‹æ¥å­¦ä¹ å¥–åŠ±å‡½æ•° $R_\phi$ å’ŒçŠ¶æ€è½¬ç§»å‡½æ•° $M_\theta$ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜ç‚¹&lt;/strong&gt;ï¼šGP ä¸ä»…èƒ½ç»™å‡ºé¢„æµ‹å€¼ï¼Œè¿˜èƒ½ç»™å‡ºé¢„æµ‹çš„&lt;strong&gt;ä¸ç¡®å®šæ€§&lt;/strong&gt;ï¼ˆæ–¹å·®ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;é‡‡æ ·ä¸è§„åˆ’&lt;/h3&gt;
&lt;p&gt;åœ¨ MPC è§„åˆ’æ—¶ï¼ŒPETS ä¼šä»å­¦åˆ°çš„æ¦‚ç‡æ¨¡å‹ä¸­&lt;strong&gt;é‡‡æ ·&lt;/strong&gt;å¤šæ¡å¯èƒ½çš„æœªæ¥è½¨è¿¹ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å¦‚æœæ¨¡å‹é¢„æµ‹æŸä¸€æ­¥ä¸ç¡®å®šæ€§å¾ˆé«˜ï¼ˆæ–¹å·®å¤§ï¼‰ï¼Œæ„å‘³ç€æœªæ¥å¯èƒ½æœ‰å¾ˆå¤šç§æƒ…å†µï¼ŒMPC ä¼šå€¾å‘äºé€‰æ‹©é£é™©æ›´å°çš„è·¯å¾„ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;ç­–ç•¥å­¦ä¹ &lt;/h3&gt;
&lt;p&gt;PETS ä¹Ÿä¼šç”¨å­¦ä¹ åˆ°çš„æ¨¡å‹å’Œè§„åˆ’ç»“æœæ¥è®­ç»ƒä¸€ä¸ª Actor-Critic ç­–ç•¥ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;MPC çš„ä¼˜åŠ¿ä¸åŠ£åŠ¿&lt;/h2&gt;
&lt;h3&gt;ä¼˜åŠ¿&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;é«˜æ ·æœ¬æ•ˆç‡&lt;/strong&gt;ï¼šé€šè¿‡æ¨¡å‹å¯ä»¥â€œé¢„æ¼”â€å¤§é‡åœºæ™¯ï¼Œå¤§å¤§å‡å°‘ä¸çœŸå®ç¯å¢ƒçš„äº¤äº’æ¬¡æ•°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å¯è§£é‡Šæ€§&lt;/strong&gt;ï¼šæ¨¡å‹å¯ä»¥è¢«æ£€æŸ¥ï¼ŒçŸ¥é“æ™ºèƒ½ä½“ä¸ºä»€ä¹ˆè¿™ä¹ˆè§„åˆ’ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å®‰å…¨æ€§&lt;/strong&gt;ï¼šåœ¨è§„åˆ’æ—¶å¯ä»¥é¢„è§æ½œåœ¨çš„å±é™©çŠ¶æ€ï¼Œå¹¶åŠ ä»¥é¿å…ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;åŠ£åŠ¿&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;æ¨¡å‹åå·® (Model Bias)&lt;/strong&gt;ï¼šè¿™æ˜¯ Model-Based æ–¹æ³•çš„è½¯è‚‹ã€‚å¦‚æœæ¨¡å‹ä¸å‡†ç¡®ï¼Œè§„åˆ’çš„ç»“æœå¯èƒ½å®Œå…¨é”™è¯¯ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è®¡ç®—æˆæœ¬&lt;/strong&gt;ï¼šMPC è§„åˆ’æœ¬èº«éœ€è¦å¤§é‡çš„è®¡ç®—ï¼Œå°¤å…¶æ˜¯åœ¨åŠ¨ä½œç©ºé—´è¿ç»­ã€é¢„æµ‹æ—¶åŸŸé•¿çš„æƒ…å†µä¸‹ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;æ€»ç»“&lt;/h2&gt;
&lt;p&gt;MPC æä¾›äº†ä¸€ç§å¼ºå¤§çš„åœ¨&lt;strong&gt;å·²çŸ¥æ¨¡å‹&lt;/strong&gt;ä¸‹è¿›è¡Œåºåˆ—å†³ç­–çš„æ–¹æ³•ã€‚å®ƒé€šè¿‡å‘å‰çœ‹ï¼ˆé¢„æµ‹ï¼‰å’Œæ»šåŠ¨ä¼˜åŒ–ï¼Œèƒ½å¤Ÿåšå‡ºæ¯”ç›´æ¥ RL æ›´æ˜æ™ºçš„å†³ç­–ã€‚
å°† MPC ä¸ RL ç»“åˆï¼Œæ˜¯ Model-Based RL çš„é‡è¦ç ”ç©¶æ–¹å‘ï¼Œå…¶ç›®æ ‡æ˜¯å­¦å¥½æ¨¡å‹ï¼Œå¹¶ç”¨å¥½æ¨¡å‹ï¼Œä»è€Œä»¥æœ€é«˜çš„æ ·æœ¬æ•ˆç‡è§£å†³å¤æ‚ä»»åŠ¡ã€‚&lt;/p&gt;
&lt;p&gt;æˆ‘ä»¬ä¹‹å‰çš„ç¬”è®°ä¸»è¦èšç„¦äº Model-Free æ–¹æ³•ï¼ˆQ-Learning, REINFORCE, PPO, SACï¼‰ã€‚Model-Based æ–¹æ³•ï¼ˆDyna-Q, MPCï¼‰æä¾›äº†å¦ä¸€ç§æ€è·¯ï¼Œå®ƒä»¬å¾€å¾€åœ¨æ ·æœ¬æ•ˆç‡ä¸Šå…·æœ‰ä¼˜åŠ¿ï¼Œä½†åœ¨æ¨¡å‹ç²¾åº¦è¦æ±‚ä¸Šè¾ƒé«˜ã€‚&lt;/p&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-3.3yex1xdpri.webp"/><enclosure url="https://pic.hana0721.top/rl-note-3.3yex1xdpri.webp"/></item><item><title>RLç¬”è®°ï¼ˆ16ï¼‰ï¼šæ¨¡ä»¿å­¦ä¹  (Imitation Learning)</title><link>https://claudiakim6827362.github.io/blog/rl-note-16</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/rl-note-16</guid><description>æ²¡æœ‰å¥–åŠ±å‡½æ•°æ€ä¹ˆåŠï¼Ÿè¯¦è§£æ¨¡ä»¿å­¦ä¹ çš„ä¸‰å¤§æµæ´¾ï¼šè¡Œä¸ºå…‹éš† (BC) çš„ç®€å•ç²—æš´ä¸å±€é™ã€é€†å¼ºåŒ–å­¦ä¹  (IRL) çš„ç†è®ºæ¨å¯¼ï¼Œä»¥åŠç”Ÿæˆå¼å¯¹æŠ—æ¨¡ä»¿å­¦ä¹  (GAIL) çš„å¯¹æŠ—åšå¼ˆæ€æƒ³ã€‚</description><pubDate>Thu, 25 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;å¼•è¨€ï¼ˆIntroductionï¼‰&lt;/h2&gt;
&lt;p&gt;åœ¨ä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œæ™ºèƒ½ä½“é€šè¿‡æœ€å¤§åŒ–ç´¯ç§¯å¥–åŠ±æ¥å­¦ä¹ ã€‚ç„¶è€Œï¼Œåœ¨å¾ˆå¤šå¤æ‚ä»»åŠ¡ä¸­ï¼Œâ€œå®šä¹‰å¥–åŠ±â€æ¯”â€œè§£å†³ä»»åŠ¡â€æœ¬èº«è¿˜è¦éš¾ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä¾‹å­&lt;/strong&gt;ï¼šè‡ªåŠ¨é©¾é©¶ã€‚ä½ å¾ˆéš¾ç”¨æ•°å­¦å…¬å¼ç²¾ç¡®å®šä¹‰ä»€ä¹ˆå«â€œå¼€å¾—ç¨³ä¸”å®‰å…¨â€ã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥å¾ˆå®¹æ˜“åœ°æ”¶é›†åˆ°äººç±»è€å¸æœºçš„é©¾é©¶æ•°æ®ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;æ¨¡ä»¿å­¦ä¹  (Imitation Learning)&lt;/strong&gt; çš„ç›®æ ‡æ˜¯ï¼šç»™å®šä¸€ç»„ä¸“å®¶æ¼”ç¤ºæ•°æ® $\tau_E = {(s_1, a_1), (s_2, a_2), \dots }$ï¼Œè®­ç»ƒä¸€ä¸ªç­–ç•¥ $\pi_\theta$ï¼Œä½¿å…¶è¡Œä¸ºå°½å¯èƒ½æ¥è¿‘ä¸“å®¶ç­–ç•¥ $\pi_E$ã€‚&lt;/p&gt;
&lt;p&gt;æˆ‘ä»¬ä¸éœ€è¦çŸ¥é“èƒŒåçš„å¥–åŠ±å‡½æ•°æ˜¯ä»€ä¹ˆï¼Œåªéœ€è¦â€œç…§çŒ«ç”»è™â€ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;è¡Œä¸ºå…‹éš† (Behavioral Cloning, BC)&lt;/h2&gt;
&lt;p&gt;è¿™æ˜¯æœ€ç®€å•ã€æœ€ç›´è§‚çš„æ¨¡ä»¿å­¦ä¹ æ–¹æ³•ã€‚&lt;/p&gt;
&lt;h3&gt;æ ¸å¿ƒæ€æƒ³&lt;/h3&gt;
&lt;p&gt;æŠŠæ¨¡ä»¿å­¦ä¹ çœ‹ä½œä¸€ä¸ª&lt;strong&gt;ç›‘ç£å­¦ä¹  (Supervised Learning)&lt;/strong&gt; é—®é¢˜ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;è¾“å…¥&lt;/strong&gt;ï¼šçŠ¶æ€ $s$ï¼ˆç‰¹å¾ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ ‡ç­¾&lt;/strong&gt;ï¼šåŠ¨ä½œ $a$ï¼ˆä¸“å®¶åœ¨ $s$ ä¸‹åšçš„åŠ¨ä½œï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;æˆ‘ä»¬çš„ç›®æ ‡æ˜¯è®­ç»ƒä¸€ä¸ªåˆ†ç±»å™¨ï¼ˆç¦»æ•£åŠ¨ä½œï¼‰æˆ–å›å½’å™¨ï¼ˆè¿ç»­åŠ¨ä½œï¼‰$\pi_\theta(s)$ï¼Œä½¿å…¶è¾“å‡ºæ‹Ÿåˆä¸“å®¶çš„åŠ¨ä½œã€‚&lt;/p&gt;
&lt;h3&gt;ç›®æ ‡å‡½æ•°&lt;/h3&gt;
&lt;p&gt;ä½¿ç”¨æœ€å¤§ä¼¼ç„¶ä¼°è®¡ (MLE)ï¼š
$$
\max_\theta \mathbb{E}&lt;em&gt;{(s,a) \sim \pi_E} [\log \pi&lt;/em&gt;\theta(a|s)]
$$
å³æœ€å°åŒ–è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±ï¼š
$$
L(\theta) = - \sum_{i=1}^N \log \pi_\theta(a_i|s_i)
$$&lt;/p&gt;
&lt;h3&gt;å±€é™æ€§ï¼šåå˜é‡åç§» (Covariate Shift)&lt;/h3&gt;
&lt;p&gt;è™½ç„¶ BC ç®€å•æœ‰æ•ˆï¼Œä½†å®ƒæœ‰ä¸€ä¸ªè‡´å‘½å¼±ç‚¹ï¼š&lt;strong&gt;è¯¯å·®ç´¯ç§¯&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;è®­ç»ƒåˆ†å¸ƒ&lt;/strong&gt;ï¼šç­–ç•¥æ˜¯åœ¨ä¸“å®¶è®¿é—®è¿‡çš„çŠ¶æ€ $s \sim P(\pi_E)$ ä¸Šè®­ç»ƒçš„ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æµ‹è¯•åˆ†å¸ƒ&lt;/strong&gt;ï¼šåœ¨å®é™…è¿è¡Œæ—¶ï¼Œç­–ç•¥ $\pi_\theta$ å¯èƒ½ä¼šçŠ¯ä¸€ç‚¹å°é”™ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ¶æ€§å¾ªç¯&lt;/strong&gt;ï¼šè¿™ä¸€ç‚¹å°é”™ä¼šå¯¼è‡´æ™ºèƒ½ä½“è¿›å…¥ä¸€ä¸ª&lt;strong&gt;ä¸“å®¶ä»æœªå»è¿‡&lt;/strong&gt;çš„çŠ¶æ€ï¼ˆOut-of-Distributionï¼‰ã€‚åœ¨è¿™ç§é™Œç”ŸçŠ¶æ€ä¸‹ï¼ŒBC ç­–ç•¥å¯èƒ½ä¼šèƒ¡ä¹±è¡ŒåŠ¨ï¼Œå¯¼è‡´æ›´å¤§çš„é”™è¯¯ï¼Œæœ€ç»ˆè¿…é€Ÿåç¦»è½¨é“ï¼ˆæ¯”å¦‚è‡ªåŠ¨é©¾é©¶è½¦åç¦»ä¸€ç‚¹ç‚¹åï¼Œä¸çŸ¥é“æ€ä¹ˆä¿®å›å»ï¼Œç›´æ¥å†²å‡ºè·‘é“ï¼‰ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;ğŸ’¡ æ€»ç»“&lt;/strong&gt;ï¼šBC åªæ˜¯å•çº¯åœ°æ‹ŸåˆåŠ¨ä½œï¼Œè€Œä¸ç†è§£â€œä¸ºä»€ä¹ˆè¦è¿™ä¹ˆåšâ€ã€‚&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2&gt;é€†å¼ºåŒ–å­¦ä¹  (Inverse RL, IRL)&lt;/h2&gt;
&lt;p&gt;ä¸ºäº†è§£å†³ BC çš„é—®é¢˜ï¼ŒIRL æå‡ºäº†ä¸€ä¸ªæ›´æ·±å±‚çš„æ€è·¯ï¼š&lt;strong&gt;ä¸“å®¶ä¹‹æ‰€ä»¥è¿™ä¹ˆåšï¼Œæ˜¯å› ä¸ºä»–åœ¨æœ€å¤§åŒ–æŸä¸ªæœªçŸ¥çš„å¥–åŠ±å‡½æ•° $R$ã€‚&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;å¦‚æœæˆ‘ä»¬èƒ½æŠŠè¿™ä¸ª $R$ åæ¨ï¼ˆInverseï¼‰å‡ºæ¥ï¼Œå†ç”¨æ ‡å‡†çš„ RL ç®—æ³•ï¼ˆå¦‚ PPO/SACï¼‰å»æœ€å¤§åŒ–è¿™ä¸ª $R$ï¼Œä¸å°±èƒ½å­¦ä¼šä¸“å®¶çš„ç­–ç•¥äº†å—ï¼Ÿ&lt;/p&gt;
&lt;h3&gt;æ ¸å¿ƒæµç¨‹&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;å‡è®¾&lt;/strong&gt;ï¼šå­˜åœ¨ä¸€ä¸ªå‚æ•°åŒ–çš„å¥–åŠ±å‡½æ•° $R_\phi(s,a)$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç›®æ ‡&lt;/strong&gt;ï¼šæ‰¾åˆ°å‚æ•° $\phi$ï¼Œä½¿å¾—åœ¨è¯¥å¥–åŠ±å‡½æ•°ä¸‹ï¼Œä¸“å®¶çš„è½¨è¿¹è·å¾—çš„ç´¯ç§¯å›æŠ¥é«˜äºå…¶ä»–ä»»ä½•ç­–ç•¥ã€‚
$$ \mathbb{E}&lt;em&gt;{\pi_E} [R&lt;/em&gt;\phi] \ge \mathbb{E}&lt;em&gt;{\pi} [R&lt;/em&gt;\phi] $$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å†…å±‚å¾ªç¯&lt;/strong&gt;ï¼šç»™å®šå½“å‰çš„ $R_\phi$ï¼Œé€šè¿‡ RL è®­ç»ƒä¸€ä¸ªæœ€ä¼˜ç­–ç•¥ $\pi^*$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å¤–å±‚å¾ªç¯&lt;/strong&gt;ï¼šæ›´æ–° $R_\phi$ï¼Œä½¿å¾—ä¸“å®¶è½¨è¿¹å’Œ $\pi^*$ è½¨è¿¹çš„å·®è·å˜å¤§ï¼ˆè®©ä¸“å®¶å¾—åˆ†æ›´é«˜ï¼‰ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;éš¾ç‚¹&lt;/h3&gt;
&lt;p&gt;IRL æ˜¯ä¸€ä¸ª&lt;strong&gt;ä¸é€‚å®š (Ill-posed)&lt;/strong&gt; é—®é¢˜ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å¾ˆå¤šå¥–åŠ±å‡½æ•°éƒ½èƒ½è§£é‡ŠåŒä¸€ç§è¡Œä¸ºï¼ˆä¾‹å¦‚ï¼šå¦‚æœ $R=0$ï¼Œä»»ä½•ç­–ç•¥éƒ½æ˜¯æœ€ä¼˜çš„ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;å› æ­¤ï¼ŒIRL é€šå¸¸éœ€è¦å¼•å…¥&lt;strong&gt;æœ€å¤§ç†µ (Maximum Entropy)&lt;/strong&gt; å‡è®¾ï¼šåœ¨æ‰€æœ‰èƒ½è§£é‡Šä¸“å®¶è¡Œä¸ºçš„å¥–åŠ±å‡½æ•°ä¸­ï¼Œé€‰æ‹©é‚£ä¸ªå¯¹ç­–ç•¥åˆ†å¸ƒçº¦æŸæœ€å°‘ï¼ˆç†µæœ€å¤§ï¼‰çš„ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;ğŸ’¡ æ€»ç»“&lt;/strong&gt;ï¼šIRL è¯•å›¾ç†è§£ä¸“å®¶çš„â€œåŠ¨æœºâ€ã€‚ä½†å®ƒè®¡ç®—æå…¶æ˜‚è´µï¼Œå› ä¸ºæ¯æ›´æ–°ä¸€æ¬¡å¥–åŠ±å‡½æ•°ï¼Œå°±è¦é‡æ–°è·‘ä¸€éå®Œæ•´çš„ RL è®­ç»ƒã€‚&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2&gt;ç”Ÿæˆå¼å¯¹æŠ—æ¨¡ä»¿å­¦ä¹  (GAIL)&lt;/h2&gt;
&lt;p&gt;Ho &amp;#x26; Ermon (2016) è¯æ˜äº†ï¼š&lt;strong&gt;æˆ‘ä»¬å…¶å®ä¸éœ€è¦æ˜¾å¼åœ°æŠŠå¥–åŠ±å‡½æ•° $R$ æ¢å¤å‡ºæ¥ã€‚&lt;/strong&gt;
å¦‚æœæˆ‘ä»¬ç›´æ¥è®­ç»ƒä¸€ä¸ªç­–ç•¥ï¼Œè®©å®ƒçš„çŠ¶æ€-åŠ¨ä½œåˆ†å¸ƒ $\rho_\pi(s,a)$ å’Œä¸“å®¶çš„åˆ†å¸ƒ $\rho_E(s,a)$ éš¾ä»¥åŒºåˆ†ï¼Œä¸å°±è¾¾åˆ°ç›®çš„äº†å—ï¼Ÿ&lt;/p&gt;
&lt;p&gt;è¿™æ­£æ˜¯ &lt;strong&gt;GAN (ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ)&lt;/strong&gt; çš„æ€æƒ³ã€‚&lt;/p&gt;
&lt;h3&gt;æ ¸å¿ƒæ¶æ„&lt;/h3&gt;
&lt;p&gt;GAIL åŒ…å«ä¸¤ä¸ªç½‘ç»œè¿›è¡Œåšå¼ˆï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;åˆ¤åˆ«å™¨ (Discriminator) $D_w(s,a)$&lt;/strong&gt;ï¼š
&lt;ul&gt;
&lt;li&gt;ä»»åŠ¡æ˜¯&lt;strong&gt;æ‰¾èŒ¬&lt;/strong&gt;ã€‚å®ƒæ¥æ”¶ä¸€ä¸ª $(s,a)$ å¯¹ï¼Œåˆ¤æ–­è¿™æ˜¯&lt;strong&gt;ä¸“å®¶&lt;/strong&gt;äº§ç”Ÿçš„ï¼ˆè¾“å‡º 1ï¼‰ï¼Œè¿˜æ˜¯&lt;strong&gt;æ™ºèƒ½ä½“&lt;/strong&gt;äº§ç”Ÿçš„ï¼ˆè¾“å‡º 0ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç”Ÿæˆå™¨ (Generator) $\pi_\theta(a|s)$&lt;/strong&gt;ï¼š
&lt;ul&gt;
&lt;li&gt;å³æˆ‘ä»¬çš„ç­–ç•¥ç½‘ç»œã€‚ä»»åŠ¡æ˜¯&lt;strong&gt;æ¬ºéª—&lt;/strong&gt;åˆ¤åˆ«å™¨ï¼Œè®©è‡ªå·±çš„è¡Œä¸ºçœ‹èµ·æ¥åƒä¸“å®¶ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;ç›®æ ‡å‡½æ•°&lt;/h3&gt;
&lt;p&gt;GAIL çš„ä¼˜åŒ–ç›®æ ‡ä¸ GAN å‡ ä¹ä¸€è‡´ï¼š
$$
\min_\pi \max_D V(\pi, D) = \mathbb{E}&lt;em&gt;{\pi_E}[\log D(s,a)] + \mathbb{E}&lt;/em&gt;{\pi}[\log(1 - D(s,a))]
$$&lt;/p&gt;
&lt;h3&gt;è®­ç»ƒæµç¨‹&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;è®­ç»ƒåˆ¤åˆ«å™¨ $D$&lt;/strong&gt;ï¼š
&lt;ul&gt;
&lt;li&gt;é‡‡æ ·ä¸“å®¶æ•°æ® $(s_E, a_E)$ å’Œ æ™ºèƒ½ä½“æ•°æ® $(s_\pi, a_\pi)$ã€‚&lt;/li&gt;
&lt;li&gt;è®© $D(s_E, a_E) \to 1$ï¼Œè®© $D(s_\pi, a_\pi) \to 0$ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è®­ç»ƒç­–ç•¥ $\pi$&lt;/strong&gt;ï¼š
&lt;ul&gt;
&lt;li&gt;æˆ‘ä»¬ä½¿ç”¨ $D$ çš„è¾“å‡ºä½œä¸ºä¸€ç§&lt;strong&gt;æ›¿ä»£å¥–åŠ± (Surrogate Reward)&lt;/strong&gt;ã€‚&lt;/li&gt;
&lt;li&gt;å®šä¹‰å¥–åŠ±å‡½æ•°ï¼š$r(s,a) = - \log(1 - D(s,a))$ ï¼ˆæˆ–è€…å…¶ä»–å˜ä½“ï¼Œå¦‚ $\log D(s,a)$ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;å¦‚æœ $D$ è®¤ä¸ºå½“å‰åŠ¨ä½œåƒä¸“å®¶ï¼ˆ$D \approx 1$ï¼‰ï¼Œå¥–åŠ±å°±é«˜ï¼›ä¸åƒä¸“å®¶ï¼Œå¥–åŠ±å°±ä½ã€‚&lt;/li&gt;
&lt;li&gt;ä½¿ç”¨ PPO æˆ– TRPO æ¥æœ€å¤§åŒ–è¿™ä¸ªå¥–åŠ±ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;ä¼˜åŠ¿&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;è§£å†³äº† Covariate Shift&lt;/strong&gt;ï¼šå› ä¸º $\pi$ æ˜¯åœ¨ç¯å¢ƒä¸­äº¤äº’è®­ç»ƒçš„ï¼ˆRLï¼‰ï¼Œé‡åˆ°åç¦»çš„çŠ¶æ€æ—¶ï¼Œåˆ¤åˆ«å™¨ä¼šç»™ä½åˆ†ï¼ŒRL ç®—æ³•ä¼šå­¦ä¼šå¦‚ä½•ä¿®æ­£å›åˆ°æ­£è½¨ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ•ˆç‡é«˜&lt;/strong&gt;ï¼šä¸éœ€è¦åƒ IRL é‚£æ ·åå¤æ±‚è§£æœ€ä¼˜ç­–ç•¥ï¼Œç­–ç•¥å’Œåˆ¤åˆ«å™¨æ˜¯åŒæ­¥æ›´æ–°çš„ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;æ€»ç»“ä¸å¯¹æ¯”&lt;/h2&gt;
&lt;p&gt;| ç»´åº¦ | è¡Œä¸ºå…‹éš† (BC) | é€†å¼ºåŒ–å­¦ä¹  (IRL) | ç”Ÿæˆå¯¹æŠ—æ¨¡ä»¿ (GAIL) |
| :--- | :--- | :--- | :--- |
| &lt;strong&gt;æ ¸å¿ƒæ€æƒ³&lt;/strong&gt; | &lt;strong&gt;ç›‘ç£å­¦ä¹ &lt;/strong&gt;ï¼šæ‹Ÿåˆ $s \to a$ æ˜ å°„ | &lt;strong&gt;é€†å‘æ¨ç†&lt;/strong&gt;ï¼šåæ¨ $R(s,a)$ | &lt;strong&gt;å¯¹æŠ—åšå¼ˆ&lt;/strong&gt;ï¼šè®©åˆ†å¸ƒ $\rho_\pi \approx \rho_E$ |
| &lt;strong&gt;äº¤äº’éœ€æ±‚&lt;/strong&gt; | ä¸éœ€è¦ä¸ç¯å¢ƒäº¤äº’ (Offline) | éœ€è¦ (Online) | éœ€è¦ (Online) |
| &lt;strong&gt;å¥–åŠ±å‡½æ•°&lt;/strong&gt; | æ—  | æ˜¾å¼å­¦å‡º $R$ | éšå¼å¥–åŠ± ($D$ çš„è¾“å‡º) |
| &lt;strong&gt;ä¼˜ç‚¹&lt;/strong&gt; | ç®€å•ã€è®­ç»ƒå¿« | å¯è§£é‡Šæ€§å¼ºã€é²æ£’ | æ•ˆæœå¥½ã€æ— éœ€è§£å†…å±‚ RL å¾ªç¯ |
| &lt;strong&gt;ç¼ºç‚¹&lt;/strong&gt; | è¯¯å·®ç´¯ç§¯ (Covariate Shift) | è®¡ç®—æå…¶æ˜‚è´µ | è®­ç»ƒä¸ç¨³å®š (GAN é€šç—…) |&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;ğŸ’¡ æ€è€ƒ&lt;/strong&gt;ï¼š
å¦‚æœä¸“å®¶çš„æ•°æ®ä¹Ÿä¸æ˜¯å®Œç¾çš„ï¼ˆæ¯”å¦‚å¶å°”æ‰‹æ»‘ï¼‰ï¼ŒBC ä¼šå‚»å‚»åœ°æŠŠé”™è¯¯ä¹Ÿå­¦è¿›å»ï¼Œè€Œ IRL/GAIL ç”±äºæœ‰å¥–åŠ±å‡½æ•°çš„å¹³æ»‘ä½œç”¨ï¼Œé€šå¸¸èƒ½å­¦å‡ºæ¯”ä¸“å®¶æ›´å¥½çš„ç­–ç•¥ã€‚&lt;/p&gt;
&lt;/blockquote&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-3.3yex1xdpri.webp"/><enclosure url="https://pic.hana0721.top/rl-note-3.3yex1xdpri.webp"/></item><item><title>RLç¬”è®°ï¼ˆ15ï¼‰ï¼šSAC</title><link>https://claudiakim6827362.github.io/blog/rl-note-15</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/rl-note-15</guid><description>æ·±å…¥è§£æ Soft Actor-Critic (SAC)ï¼šä»æœ€å¤§ç†µåŸç†å‡ºå‘ï¼Œè¯¦ç»†æ¨å¯¼ Soft ç­–ç•¥è¿­ä»£ä¸æ”¶æ•›æ€§è¯æ˜ï¼Œå¹¶è§£æé‡å‚æ•°åŒ–æŠ€å·§ä¸è‡ªåŠ¨ç†µè°ƒèŠ‚ç­‰å…³é”®å®ç°ç»†èŠ‚ã€‚</description><pubDate>Wed, 24 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;å¼•è¨€ï¼ˆIntroductionï¼‰&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Soft Actor-Critic (SAC)&lt;/strong&gt; æ˜¯ä¸€ç§åŸºäºæœ€å¤§ç†µå¼ºåŒ–å­¦ä¹ çš„ &lt;strong&gt;Off-Policyï¼ˆç¦»çº¿ç­–ç•¥ï¼‰&lt;/strong&gt; ç®—æ³•ï¼Œäº 2018 å¹´æå‡ºã€‚
SAC çš„å‰èº«æ˜¯ Soft Q-learning (SQL)ã€‚ç›¸æ¯”äº SQL éœ€è¦å¤æ‚çš„é‡‡æ ·è¿‡ç¨‹ï¼ŒSAC å¼•å…¥äº† Actor-Critic æ¶æ„ï¼Œä½¿å…¶è®­ç»ƒæ›´åŠ ç¨³å®šä¸”é«˜æ•ˆã€‚SAC åœ¨å„ç±» Benchmark åŠçœŸå®æœºå™¨äººä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä»¥å…¶&lt;strong&gt;æå¼ºçš„æŠ—å¹²æ‰°èƒ½åŠ›&lt;/strong&gt;å’Œ&lt;strong&gt;å¯¹è¶…å‚æ•°çš„é²æ£’æ€§&lt;/strong&gt;è‘—ç§°ï¼Œæ˜¯ç°ä»£æ·±åº¦å¼ºåŒ–å­¦ä¹ çš„åŸºçŸ³ç®—æ³•ä¹‹ä¸€ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;æœ€å¤§ç†µå¼ºåŒ–å­¦ä¹  (Maximum Entropy RL)&lt;/h2&gt;
&lt;h3&gt;ç†µçš„å®šä¹‰&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;ç†µ (Entropy)&lt;/strong&gt; è¡¨ç¤ºå¯¹ä¸€ä¸ªéšæœºå˜é‡çš„éšæœºç¨‹åº¦çš„åº¦é‡ã€‚å¦‚æœ $X$ æ˜¯ä¸€ä¸ªéšæœºå˜é‡ï¼Œå®ƒçš„æ¦‚ç‡å¯†åº¦è®°ä¸º $p$ï¼Œé‚£ä¹ˆå®ƒçš„ç†µ $H$ å®šä¹‰ä¸ºï¼š
$$
\begin{align}
H(X)&amp;#x26;=\mathbb{E}&lt;em&gt;{x\sim p}[-\log p(x)]\notag \
&amp;#x26;=-\int&lt;/em&gt;{x}p(x)\log p(x) \mathrm{d}x \notag
\end{align}
$$
åœ¨å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œå¯ä»¥ä½¿ç”¨ $H(\pi(\cdot|s))$ æ¥è¡¨ç¤ºç­–ç•¥ $\pi$ åœ¨çŠ¶æ€ $s$ ä¸‹çš„éšæœºç¨‹åº¦ã€‚&lt;/p&gt;
&lt;h3&gt;ç›®æ ‡å‡½æ•°&lt;/h3&gt;
&lt;p&gt;æœ€å¤§ç†µå¼ºåŒ–å­¦ä¹ ï¼ˆmaximum entropy RLï¼‰çš„æ€æƒ³æ˜¯é™¤äº†æœ€å¤§åŒ–ç´¯è®¡å¥–åŠ±ï¼Œè¿˜è¦ä½¿å¾—ç­–ç•¥æ›´åŠ éšæœºã€‚å¦‚æ­¤ï¼Œå¼ºåŒ–å­¦ä¹ çš„ç›®æ ‡ä¸­åŠ å…¥äº†ä¸€é¡¹ç†µçš„æ­£åˆ™é¡¹ï¼Œå®šä¹‰ä¸ºï¼š
$$
\begin{align}
\pi_{\textbf{MaxEnt}}^*=\arg\max_{\pi}\mathbb{E}&lt;em&gt;{\pi}\left[\sum&lt;/em&gt;{t=0}^\infty r(s_t,a_t)+\alpha H(\pi(\cdot|s_t))\right]\notag
\end{align}
$$
å…¶ä¸­ï¼Œ$\alpha$ æ˜¯ä¸€é¡¹æ­£åˆ™é¡¹ç³»æ•°ï¼Œç”¨æ¥æƒè¡¡ç†µçš„é‡è¦ç¨‹åº¦ã€‚
SAC ç®—æ³•åŠ å…¥ç†µæ­£åˆ™é¡¹ï¼Œæœ‰åˆ©äºå¢åŠ å¼ºåŒ–å­¦ä¹ ç®—æ³•çš„æ¢ç´¢ï¼Œ$\alpha$ è¶Šå¤§ï¼Œæ¢ç´¢æ€§è¶Šå¼ºï¼Œæœ‰åŠ©äºåŠ é€Ÿç­–ç•¥çš„å­¦ä¹ ï¼Œé™ä½ç­–ç•¥é™·å…¥å±€éƒ¨æœ€ä¼˜çš„å¯èƒ½æ€§ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;åŸºäºèƒ½é‡çš„æ¨¡å‹ (Energy-Based Model, EBM)&lt;/h2&gt;
&lt;p&gt;åŸºäºèƒ½é‡çš„æ¨¡å‹ï¼ˆEnergy-Based Modelï¼ŒEBMï¼‰æ˜¯ä¸€ç±»åŸºäºç»Ÿè®¡ç‰©ç†å­¦åŸç†çš„æ¦‚ç‡æ¨¡å‹ï¼Œé€šè¿‡èƒ½é‡å‡½æ•°ä¸ºæ¯ä¸ªå¯èƒ½çš„çŠ¶æ€åˆ†é…ä¸€ä¸ªæ ‡é‡èƒ½é‡å€¼ï¼Œä½èƒ½é‡åŒºåŸŸå¯¹åº”é«˜æ¦‚ç‡åŒºåŸŸã€‚åœ¨å¼ºåŒ–å­¦ä¹ ä¸­ï¼ŒEBM å°†çŠ¶æ€-åŠ¨ä½œå¯¹ $(s,a)$ æ˜ å°„åˆ°èƒ½é‡å€¼ $\mathcal{E}$ï¼Œä»è€Œè¡¨ç¤ºç­–ç•¥åˆ†å¸ƒï¼Œå®šä¹‰ä¸ºï¼š
$$
\begin{align}
\pi(a|s)=\frac{\exp(-\mathcal{E}(s,a))}{Z(s)}\notag
\end{align}
$$
å…¶ä¸­ï¼Œ$Z(s)=\int_{A}\exp(-\mathcal{E}(s,a))\mathrm{d}a$ æ˜¯é…åˆ†å‡½æ•°ï¼Œè´Ÿè´£å½’ä¸€åŒ–èƒ½é‡å€¼ä»¥å½¢æˆæœ‰æ•ˆçš„æ¦‚ç‡åˆ†å¸ƒã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;Soft ç­–ç•¥è¿­ä»£ (Soft Policy Iteration)&lt;/h2&gt;
&lt;h3&gt;Soft è´å°”æ›¼æ–¹ç¨‹&lt;/h3&gt;
&lt;p&gt;$$
\begin{align}
V_{\textbf{soft}}^\pi(s)&amp;#x26;=\mathbb{E}&lt;em&gt;{a\sim\pi(\cdot|s)}[Q^{\pi}&lt;/em&gt;{\textbf{soft}}(s,a)-\alpha\log\pi(a|s)]\notag \
&amp;#x26;=\mathbb{E}&lt;em&gt;{a\sim \pi(a|s)}[Q^{\pi}&lt;/em&gt;{\textbf{soft}}(s,a)]+\alpha H(\pi(\cdot|s)) \notag
\end{align}
$$
$$
\begin{align}
Q^{\pi}&lt;em&gt;{\textbf{soft}}(s,a)=r(s,a)+\gamma \mathbb{E}&lt;/em&gt;{s^\prime\sim p(\cdot|s,a)}[V_{\textbf{soft}}^\pi(s^\prime)]\notag \
\end{align}
$$&lt;/p&gt;
&lt;h3&gt;Soft ç­–ç•¥è¯„ä¼° (Soft Policy Evaluation)&lt;/h3&gt;
&lt;p&gt;åœ¨ SAC ç®—æ³•ä¸­ï¼ŒSoft ä»·å€¼å‡½æ•°å®šä¹‰ä¸ºï¼š
$$
\begin{align}
V_{\textbf{soft}}^\pi(s)\triangleq\mathbb{E}&lt;em&gt;{a\sim\pi(\cdot|s)}[Q^{\pi}&lt;/em&gt;{\textbf{soft}}(s,a)-\alpha\log\pi(a|s)]\notag
\end{align}
$$
Soft åŠ¨ä½œä»·å€¼å‡½æ•°å®šä¹‰ä¸ºï¼š
$$
\begin{align}
Q^{\pi}&lt;em&gt;{\textbf{soft}}(s,a)\triangleq r(s,a)+\gamma \mathbb{E}&lt;/em&gt;{s^\prime\sim p(\cdot|s,a)}[V_{\textbf{soft}}^\pi(s^\prime)]\notag \
\end{align}
$$
åŠ¨ä½œä»·å€¼å‡½æ•°çš„ Soft è´å°”æ›¼è¿­ä»£ç®—å­å®šä¹‰ä¸ºï¼š
$$
\begin{align}
\mathcal{T}^\pi Q^{k}&lt;em&gt;{\textbf{soft}}(s,a)&amp;#x26;\triangleq r(s,a)+\gamma \mathbb{E}&lt;/em&gt;{s^\prime\sim p(\cdot|s,a)}[V_{\textbf{soft}}^{k}(s^\prime)]\notag \
&amp;#x26;\triangleq  r(s,a)+\gamma \mathbb{E}&lt;em&gt;{s^\prime\sim p(\cdot|s,a)}[\mathbb{E}&lt;/em&gt;{a^\prime\sim\pi(\cdot|s^\prime)}[Q^{k}_{\textbf{soft}}(s^\prime,a^\prime)-\alpha\log\pi(a^\prime|s^\prime)]]\notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Soft ç­–ç•¥è¯„ä¼°å®šç†&lt;/strong&gt;ï¼šåŸºäºä¸Šè¿°çš„ç®—å­ $\mathcal{T}^\pi$ ä»¥åŠåˆå§‹åŒ–çš„æ˜ å°„ $Q^0_{\textbf{soft}}:S\times A\rightarrow \mathbb{R}$ï¼Œä¸” $|A|&amp;#x3C;\infty$ï¼Œ$Q^{k+1}&lt;em&gt;{\textbf{soft}}=\mathcal{T}^\pi Q^k&lt;/em&gt;{\textbf{soft}}$ã€‚é‚£ä¹ˆå½“ $k\rightarrow\infty$ æ—¶ï¼Œåºåˆ— ${Q^k_{\textbf{soft}}}$ ä¼šæ”¶æ•›è‡³ $Q_{\textbf{soft}}^\pi$ã€‚&lt;/p&gt;
&lt;p&gt;æ¥ä¸‹æ¥è¯æ˜è¿™æ˜¯ä¸€ä¸ªå‹ç¼©æ˜ å°„ã€‚æ–‡ç« é‡æ–°å®šä¹‰äº†å¥–åŠ± $r_\pi(s,a)$ï¼š
$$
\begin{align}
r_{\pi}(s,a)\triangleq r(s,a)+\mathbb{E}&lt;em&gt;{s^\prime\sim p(\cdot|s,a)}[H(\pi(\cdot|s^\prime))]\notag \
\end{align}
$$
è¿­ä»£å¼å¯ä»¥é‡å†™ä¸ºï¼š
$$
\begin{align}
\mathcal{T}^\pi Q^{k}&lt;/em&gt;{\textbf{soft}}(s,a)\triangleq r_\pi(s,a)+\gamma \mathbb{E}&lt;em&gt;{s^\prime\sim p(\cdot|s,a), a^\prime \sim \pi(\cdot|s^\prime)}[Q^{k}&lt;/em&gt;{\textbf{soft}}(s^\prime,a^\prime)]\notag \
\end{align}
$$
åœ¨ç®—æ³•ä¸­ï¼Œæˆ‘ä»¬å‡è®¾ $|A|&amp;#x3C;\infty$ï¼Œé‚£ä¹ˆ $r_\pi(s,a)$ å°±æ˜¯æœ‰ç•Œçš„ï¼Œé‚£ä¹ˆåªéœ€è¦è¯æ˜æ­¤ä¸ç­‰å¼ï¼š
$$
\begin{align}
\big|\big|\mathcal{T}^\pi Q^N_{\textbf{soft}}(s,a)-\mathcal{T}^\pi Q^M_{\textbf{soft}}(s,a)\big|\big|&lt;em&gt;\infty \le k\big|\big| Q^N&lt;/em&gt;{\textbf{soft}}(s,a)-Q^M_{\textbf{soft}}(s,a)\big|\big|&lt;em&gt;\infty ,\quad\exists k\in(0,1)\notag
\end{align}
$$
å·¦å¼åŒ–ç®€ä¸ºï¼š
$$
\begin{align}
\big|\mathcal{T}^\pi Q^N&lt;/em&gt;{\textbf{soft}}(s,a)-\mathcal{T}^\pi Q^M_{\textbf{soft}}(s,a)\big|
&amp;#x26;=\gamma\big|\mathbb{E}&lt;em&gt;{s^\prime\sim p(\cdot|s,a), a^\prime\sim\pi(\cdot|s^\prime)}\left[Q^N&lt;/em&gt;{\textbf{soft}}(s^\prime,a^\prime)-Q^M_{\textbf{soft}}(s^\prime,a^\prime)\right]\big|\notag \
&amp;#x26;\le \gamma\mathbb{E}&lt;em&gt;{s^\prime\sim p(\cdot|s,a), a^\prime\sim\pi(\cdot|s^\prime)}\left[\big|Q^N&lt;/em&gt;{\textbf{soft}}(s^\prime,a^\prime)-Q^M_{\textbf{soft}}(s^\prime,a^\prime)\big|\right] \notag \
&amp;#x26;\le \gamma\mathbb{E}&lt;em&gt;{s^\prime\sim p(\cdot|s,a)}\left[\max&lt;/em&gt;{a^\prime\in A}\big|Q^N_{\textbf{soft}}(s^\prime,a^\prime)-Q^M_{\textbf{soft}}(s^\prime,a^\prime)\big|\right] \notag \
&amp;#x26;\le \gamma \max_{s^\prime\in S,a^\prime\in A} \big|Q^N_{\textbf{soft}}(s^\prime,a^\prime)-Q^M_{\textbf{soft}}(s^\prime,a^\prime)\big| \notag
\end{align}
$$
æœ€ç»ˆå¯ä»¥å¾—å‡ºï¼š
$$
\begin{align}
\max_{s\in S,a\in A}\big|\mathcal{T}^\pi Q^N_{\textbf{soft}}(s,a)-\mathcal{T}^\pi Q^M_{\textbf{soft}}(s,a)\big| \le \gamma \max_{s^\prime\in S,a^\prime\in A} \big|Q^N_{\textbf{soft}}(s^\prime,a^\prime)-Q^M_{\textbf{soft}}(s^\prime,a^\prime)\big| \notag \
\end{align}
$$
å…¶ä¸­ï¼ŒæŠ˜æ‰£å› å­ $\gamma\in(0,1)$ï¼Œå¯ä»¥è¯æ˜ $\mathcal{T}^\pi$ æ˜¯å‹ç¼©æ˜ å°„ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;Soft ç­–ç•¥æå‡ (Soft Policy Improvement)&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Soft ç­–ç•¥æå‡å®šç†&lt;/strong&gt;ï¼šå¯¹äºä»»æ„ $\pi_{\text{old}} \in \Pi$ï¼Œå¹¶ä»¥ä¸‹å¼ä¼˜åŒ– $\pi_{\text{new}}$ã€‚å‡è®¾ $|A|&amp;#x3C;\infty$ï¼Œé‚£ä¹ˆå¯¹äº $\forall (s,a) \in S \times A$ï¼Œæœ‰ $Q_{\textbf{soft}}^{\pi_{\text{new}}}(s,a)\ge Q_{\textbf{soft}}^{\pi_{\text{old}}}(s,a)$ã€‚
$$
\begin{align}
\pi_{\text{new}}(\cdot|s)=\arg \min_{\pi^\prime\in\Pi}D_{\textbf{KL}}\left(\pi^\prime(\cdot|s)\Big|\Big|\frac{\exp(\frac{1}{\alpha}Q^{\pi_{\text{old}}}&lt;em&gt;{\textbf{soft}}(s,\cdot))}{Z^{\pi&lt;/em&gt;{\text{old}}}(s)}\right)\notag \
\end{align}
$$
å…¶ä¸­ $Z^{\pi_{\text{old}}}(s)$ æ˜¯é…åˆ†å‡½æ•°ï¼Œè´Ÿè´£å½’ä¸€åŒ–åˆ†å¸ƒã€‚&lt;/p&gt;
&lt;p&gt;å®šä¹‰ $J(\pi(\cdot|s);\pi_{\text{old}})$ ä¸ºï¼š
$$
\begin{align}
J(\pi(\cdot|s);\pi_{\text{old}})&amp;#x26;= D_{\textbf{KL}}\left(\pi(\cdot|s)\Big|\Big|\frac{\exp(\frac{1}{\alpha}Q_{\textbf{soft}}^{\pi_\text{old}}(s,\cdot))}{Z^{\pi_\text{old}}(s)}\right)\notag \
&amp;#x26;=\int_a \pi(a|s)\log\frac{\pi(a|s)}{\exp(\frac{1}{\alpha}Q_{\textbf{soft}}^{\pi_\text{old}}(s,a)-\log Z^{\pi_{\text{old}}}(s))}\text{d}a \notag \
&amp;#x26;=\mathbb{E}&lt;em&gt;{a\sim\pi(\cdot|s)}\left[\log\pi(a|s)-\frac{1}{\alpha}Q&lt;/em&gt;{\textbf{soft}}^{\pi_\text{old}}(s,a)+\log Z^{\pi_\text{old}}(s)\right] \notag
\end{align}
$$
é‚£ä¹ˆå¯¹äº $\pi_\text{old}$ å’Œ $\pi_\text{new}$ï¼Œæ»¡è¶³ $J(\pi_\text{new}(\cdot|s);\pi_\text{old})\le J(\pi_\text{old}(\cdot|s);\pi_\text{old})$ï¼Œå³ï¼š
$$
\begin{align}
\mathbb{E}&lt;em&gt;{a\sim\pi&lt;/em&gt;\text{new}(\cdot|s)}\left[\log\pi_\text{new}(a|s)-\frac{1}{\alpha}Q_{\textbf{soft}}^{\pi_\text{old}}(s,a)+\log Z^{\pi_\text{old}}(s)\right] \le \mathbb{E}&lt;em&gt;{a\sim\pi&lt;/em&gt;\text{old}(\cdot|s)}\left[\log\pi_\text{old}(a|s)-\frac{1}{\alpha}Q_{\textbf{soft}}^{\pi_\text{old}}(s,a)+\log Z^{\pi_\text{old}}(s)\right]  \notag \
\end{align}
$$
$Z^{\pi_\text{old}}(s)$ ä¸ $a$ æ— å…³ï¼Œç›¸çº¦åå¾—ï¼š
$$
\begin{align}
\mathbb{E}&lt;em&gt;{a\sim\pi&lt;/em&gt;\text{new}(\cdot|s)}\left[\log\pi_\text{new}(a|s)-\frac{1}{\alpha}Q_{\textbf{soft}}^{\pi_\text{old}}(s,a)\right] \le \mathbb{E}&lt;em&gt;{a\sim\pi&lt;/em&gt;\text{old}(\cdot|s)}\left[\log\pi_\text{old}(a|s)-\frac{1}{\alpha}Q_{\textbf{soft}}^{\pi_\text{old}}(s,a)\right]  \notag \
\end{align}
$$
åŒ–ç®€ä¸ºï¼š
$$
\begin{align}
\mathbb{E}&lt;em&gt;{a\sim\pi&lt;/em&gt;\text{new}(\cdot|s)}\left[Q_{\textbf{soft}}^{\pi_\text{old}}(s,a)-\alpha\log\pi_\text{new}(a|s)\right] \ge \mathbb{E}&lt;em&gt;{a\sim\pi&lt;/em&gt;\text{old}(\cdot|s)}\left[Q_{\textbf{soft}}^{\pi_\text{old}}(s,a)-\alpha\log\pi_\text{old}(a|s)\right] = V_{\textbf{soft}}^{\pi_\text{old}}(s) \notag \
\end{align}
$$
æ¥ä¸‹æ¥è¯æ˜ $Q_{\textbf{soft}}^{\pi_{\text{new}}}(s,a)\ge Q_{\textbf{soft}}^{\pi_{\text{old}}}(s,a)$ï¼Œæˆ‘ä»¬åˆ©ç”¨ä¸Šå¼è¿›è¡Œè¿­ä»£å±•å¼€ï¼š
$$
\begin{align}
Q_{\textbf{soft}}^{\pi_{\text{old}}}(s,a) &amp;#x26;= r_0 + \gamma \mathbb{E}&lt;em&gt;{s_1\sim p(\cdot|s,a)}\left[ V&lt;/em&gt;{\textbf{soft}}^{\pi_\text{old}}(s_1)\right]\notag \
&amp;#x26;\le r_0 + \gamma \mathbb{E}&lt;em&gt;{s_1\sim p(\cdot|s,a)}\left[\mathbb{E}&lt;/em&gt;{a_1\sim \pi_\text{new}(\cdot|s_1)}\left[Q_{\textbf{soft}}^{\pi_\text{old}}(s_1,a_1) - \alpha \log \pi_\text{new}(a_1|s_1)\right]\right] \notag \
&amp;#x26;= r_0 + \gamma \mathbb{E}&lt;em&gt;{s_1\sim p(\cdot|s,a)}\left[\mathbb{E}&lt;/em&gt;{a_1\sim \pi_\text{new}(\cdot|s_1)}\left[r(s_1, a_1) + \gamma \mathbb{E}&lt;em&gt;{s_2}[V&lt;/em&gt;{\textbf{soft}}^{\pi_\text{old}}(s_2)] + \alpha H(\pi_\text{new}(\cdot|s_1))\right]\right] \notag \
&amp;#x26;\cdots \notag \
&amp;#x26;\le \sum_{t=0}^\infty \gamma^t \mathbb{E}&lt;em&gt;{(s_t,a_t)\sim \rho^{\pi&lt;/em&gt;\text{new}}}\left[r(s_t,a_t)+\alpha H(\pi_\text{new}(\cdot|s_t))\right]\notag \
&amp;#x26;=Q_{\textbf{soft}}^{\pi_\text{new}}(s,a) \notag
\end{align}
$$
è¯æ˜å®Œæ¯•ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;Soft ç­–ç•¥è¿­ä»£å®šç†&lt;/h3&gt;
&lt;p&gt;å‡è®¾ $|A|&amp;#x3C;\infty$ï¼Œå¯¹äºä»»æ„ $\pi \in \Pi$ï¼Œé‡å¤åº”ç”¨ Soft ç­–ç•¥è¯„ä¼°å’Œ Soft ç­–ç•¥æå‡ï¼Œä¼šæ”¶æ•›åˆ° $\pi^&lt;em&gt;$ï¼Œä½¿å¾—å¯¹äºä»»æ„ $\pi \in \Pi$ ä»¥åŠ $(s,a)\in S\times A$ï¼Œéƒ½æœ‰ $Q^{\pi^&lt;/em&gt;}&lt;em&gt;\textbf{soft}(s,a)\ge Q^{\pi}&lt;/em&gt;\textbf{soft}(s,a)$ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;è¯æ˜è¿‡ç¨‹&lt;/strong&gt;ï¼š
ä»¤ $\pi_i$ ä¸ºç¬¬ $i$ è½®è¿­ä»£çš„ç­–ç•¥ï¼Œæ ¹æ® Soft ç­–ç•¥è¿­ä»£å®šç†ï¼Œåºåˆ— ${Q^{\pi_i}&lt;em&gt;\textbf{soft}}$ æ˜¯å•è°ƒé€’å¢çš„ã€‚å¯¹äºä»»æ„ $\pi \in \Pi$ï¼Œ $Q^\pi&lt;/em&gt;\textbf{soft}$ æ˜¯æœ‰ä¸Šç•Œçš„ï¼ˆå¥–åŠ±ä¸ç†µå‡æ˜¯æœ‰ç•Œçš„ï¼‰ï¼Œå› æ­¤åºåˆ—ä¼šæ”¶æ•›åˆ°æŸä¸ª $\pi^&lt;em&gt;$ï¼Œæ¥ä¸‹æ¥éœ€è¦è¯æ˜ $\pi^&lt;/em&gt;$ æ˜¯æœ€ä¼˜çš„ã€‚
åœ¨æ”¶æ•›æ—¶ï¼Œå¿…ç„¶æ»¡è¶³ï¼šå¯¹äºä»»æ„ $\pi\in\Pi$ ä¸” $\pi\neq \pi^&lt;em&gt;$ï¼Œéƒ½æœ‰ $J(\pi^&lt;/em&gt;(\cdot|s);\pi^&lt;em&gt;) &amp;#x3C; J(\pi(\cdot|s);\pi^&lt;/em&gt;)$ï¼Œå³ï¼š
$$
\begin{align}
\mathbb{E}&lt;em&gt;{a\sim\pi^&lt;em&gt;(\cdot|s)}\left[\log\pi^&lt;/em&gt;(a|s)-\frac{1}{\alpha}Q&lt;/em&gt;{\textbf{soft}}^{\pi^&lt;em&gt;}(s,a)\right] &amp;#x3C; \mathbb{E}&lt;em&gt;{a\sim\pi(\cdot|s)}\left[\log\pi(a|s)-\frac{1}{\alpha}Q&lt;/em&gt;{\textbf{soft}}^{\pi^&lt;/em&gt;}(s,a)\right]  \notag \
\end{align}
$$
åŒ–ç®€ä¸ºï¼š
$$
\begin{align}
V_\textbf{soft}^{\pi^&lt;em&gt;}(s) &gt; \mathbb{E}&lt;em&gt;{a\sim \pi(\cdot|s)}\left[Q&lt;/em&gt;\textbf{soft}^{\pi^&lt;/em&gt;}(s,a)-\alpha \log \pi(a|s)\right]\notag \
\end{align}
$$
æ¥ä¸‹æ¥è¯æ˜ $\pi^&lt;em&gt;$ æ˜¯æœ€ä¼˜çš„ï¼Œå³è¯æ˜ $Q_\textbf{soft}^{\pi^&lt;/em&gt; }(s,a) &gt; Q^\pi_\textbf{soft}(s,a)$ï¼š
$$
\begin{align}
Q_\textbf{soft}^{\pi^* }(s,a)&amp;#x26;=r_0+\gamma\mathbb{E}&lt;em&gt;{s_1\sim p(\cdot|s,a)}\left[V&lt;/em&gt;\textbf{soft}^{\pi^&lt;em&gt;}(s_1)\right]\notag \
&amp;#x26;&gt;r_0+\gamma\mathbb{E}&lt;em&gt;{s_1\sim p(\cdot|s,a)}\left[\mathbb{E}&lt;/em&gt;{a_1\sim \pi(\cdot|s_1)}\left[Q_\textbf{soft}^{\pi^&lt;/em&gt;}(s_1,a_1)-\alpha \log \pi(a_1|s_1)\right]\right] \notag \
&amp;#x26;= r_0+\gamma\mathbb{E}&lt;em&gt;{s_1\sim p(\cdot|s,a)}\left[\mathbb{E}&lt;/em&gt;{a_1\sim \pi(\cdot|s_1)}\left[r(s_1, a_1) + \gamma \mathbb{E}&lt;em&gt;{s_2}[V&lt;/em&gt;\textbf{soft}^{\pi^*}(s_2)] + \alpha H(\pi(\cdot|s_1))\right]\right] \notag \
&amp;#x26;&gt; \sum_{t=0}^\infty \gamma^t \mathbb{E}&lt;em&gt;{(s_t,a_t)\sim\rho^\pi}\left[r(s_t,a_t)+\alpha H(\pi(\cdot|s_t))\right] \notag \
&amp;#x26;=Q^\pi&lt;/em&gt;\textbf{soft}(s,a)\notag
\end{align}
$$
è¯æ˜å®Œæ¯•ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;ç®—æ³•å®ç°&lt;/h2&gt;
&lt;p&gt;åœ¨ SAC ç®—æ³•ä¸­ï¼Œæˆ‘ä»¬ä¸ºä¸¤ä¸ªåŠ¨ä½œä»·å€¼å‡½æ•° $Q_\textbf{soft}$ï¼ˆå‚æ•°åˆ†åˆ« $\omega_1$ ä¸ºå’Œ $\omega_2$ï¼‰å’Œä¸€ä¸ªç­–ç•¥å‡½æ•° $\pi$ï¼ˆå‚æ•°ä¸º $\theta$ï¼‰å»ºæ¨¡ã€‚åŸºäº Double DQN çš„æ€æƒ³ï¼ŒSAC ä½¿ç”¨ $Q_\textbf{soft}$ ä¸¤ä¸ªç½‘ç»œï¼Œä½†æ¯æ¬¡ç”¨ $Q_\textbf{soft}$ ç½‘ç»œæ—¶ä¼šæŒ‘é€‰ä¸€ä¸ª $Q_\textbf{soft}$ å€¼å°çš„ç½‘ç»œï¼Œä»è€Œç¼“è§£ $Q_\textbf{soft}$ å€¼è¿‡é«˜ä¼°è®¡çš„é—®é¢˜ã€‚&lt;/p&gt;
&lt;h3&gt;åŠ¨ä½œä»·å€¼å‡½æ•° (Critic)&lt;/h3&gt;
&lt;p&gt;ä»»æ„ä¸€ä¸ªå‡½æ•° $Q_\textbf{soft}$ çš„æŸå¤±å‡½æ•°ä¸ºï¼š
$$
\begin{align}
L_{Q_\textbf{soft}}(\omega)&amp;#x26;=\mathbb{E}&lt;em&gt;{(s_t,a_t,r_t,s&lt;/em&gt;{t+1})\sim R}\left[\frac{1}{2}\left(Q_\textbf{soft}^\omega(s_t,a_t)-\left(r_t+\gamma V_{\textbf{soft}}^{\omega^-}(s_{t+1})\right)\right)^2\right]\notag \
&amp;#x26;= \mathbb{E}&lt;em&gt;{(s_t,a_t,r_t,s&lt;/em&gt;{t+1})\sim R}\left[\frac{1}{2}\left(Q_\textbf{soft}^\omega(s_t,a_t)-\left(r_t+\gamma\mathbb{E}&lt;em&gt;{a&lt;/em&gt;{t+1}\sim \pi_\theta(\cdot|s_{t+1})}\left[\min_{j=1,2} Q_\textbf{soft}^{\omega_j^-}(s_{t+1},a_{t+1})-\alpha \log \pi_{\theta}(a_{t+1}|s_{t+1})\right]\right)\right)^2\right]\notag
\end{align}
$$
å…¶ä¸­ï¼Œ$R$ æ˜¯ç­–ç•¥è¿‡å»æ”¶é›†çš„æ•°æ®ï¼Œå› ä¸º SAC æ˜¯ä¸€ç§ç¦»çº¿ç­–ç•¥ç®—æ³•ã€‚ä¸ºäº†è®©è®­ç»ƒæ›´åŠ ç¨³å®šï¼Œè¿™é‡Œä½¿ç”¨äº†ä¸¤ä¸ªç›®æ ‡ç½‘ç»œ $Q_\textbf{soft}^{\omega_j^-}$ã€‚ç›®æ ‡ç½‘ç»œçš„æ›´æ–°æ–¹å¼æ˜¯ Soft æ›´æ–°ï¼š
$$
\begin{align}
\omega_j^-\leftarrow \tau \omega_j + (1-\tau) \omega_j^-, \quad j=1,2\notag
\end{align}
$$&lt;/p&gt;
&lt;h3&gt;ç­–ç•¥å‡½æ•° (Actor)&lt;/h3&gt;
&lt;p&gt;æ¥ä¸‹æ¥æ ¹æ® Soft ç­–ç•¥æå‡å®šç†ä¸­çš„ KL æ•£åº¦æ¥æ¨å¯¼ç­–ç•¥ $\pi_\theta$ çš„æŸå¤±å‡½æ•° $L_{\pi}(\theta)$ï¼š
$$
\begin{align}
\theta&amp;#x26;=\arg \min_{\theta} L_\pi(\theta) \notag \
&amp;#x26;=\arg \min_{\theta} \mathbb{E}&lt;em&gt;{s_t\sim R}\left[D&lt;/em&gt;\textbf{KL}\left(\pi_\theta(\cdot|s_t)\Big|\Big|\frac{\exp(\frac{1}{\alpha }Q_\textbf{soft}^\omega(s_t,\cdot))}{Z(s_t)}\right)\right]\notag \
&amp;#x26;= \arg\min_\theta \mathbb{E}&lt;em&gt;{s_t\sim R}\left[\mathbb{E}&lt;/em&gt;{a_t\sim \pi_\theta(\cdot|s_t)}\left[\log\left(\frac{\pi_\theta(a_t|s_t)Z(s_t)}{\exp(\frac{1}{\alpha}Q_\textbf{soft}^\omega(s_t,a_t))}\right)\right]\right] \notag \
&amp;#x26;=\arg\min_\theta \mathbb{E}&lt;em&gt;{s_t\sim R, a_t\sim \pi&lt;/em&gt;\theta(\cdot|s_t)}\left[\log \pi_\theta(a_t|s_t)-\frac{1}{\alpha}Q_\textbf{soft}^\omega(s_t,a_t)+\log Z(s_t)\right] \notag \
&amp;#x26;=\arg\min_\theta \mathbb{E}&lt;em&gt;{s_t\sim R, a_t\sim \pi&lt;/em&gt;\theta(\cdot|s_t)}\left[\log \pi_\theta(a_t|s_t)-\frac{1}{\alpha}Q_\textbf{soft}^\omega(s_t,a_t)\right] \notag \
&amp;#x26;=\arg\min_\theta \mathbb{E}&lt;em&gt;{s_t\sim R, a_t\sim \pi&lt;/em&gt;\theta(\cdot|s_t)}\left[\alpha\log \pi_\theta(a_t|s_t)-Q_\textbf{soft}^\omega(s_t,a_t)\right] \notag \
&amp;#x26;=\arg\max_\theta \mathbb{E}&lt;em&gt;{s_t\sim R}\left[V&lt;/em&gt;\textbf{soft}^\omega (s_t)\right]\notag
\end{align}
$$
è€ƒè™‘åˆ°ä¸¤ä¸ª $Q_\textbf{soft}^\omega$ ç½‘ç»œï¼ŒæŸå¤±å‡½æ•°å†™ä¸ºï¼š
$$
\begin{align}
L_\pi(\theta)=\arg\min_\theta \mathbb{E}&lt;em&gt;{s_t\sim R, a_t\sim \pi&lt;/em&gt;\theta(\cdot|s_t)}\left[\alpha\log \pi_\theta(a_t|s_t)-\min_{j=1,2}Q_\textbf{soft}^{\omega_j}(s_t,a_t)\right] \notag \
\end{align}
$$&lt;/p&gt;
&lt;h3&gt;é‡å‚æ•°åŒ–æŠ€å·§ (Reparameterization Trick)&lt;/h3&gt;
&lt;p&gt;å¯¹äºè¿ç»­åŠ¨ä½œç©ºé—´çš„ç¯å¢ƒï¼Œç­–ç•¥è¾“å‡º Gauss åˆ†å¸ƒçš„å‡å€¼å’Œæ ‡å‡†å·®ï¼Œä½†æ˜¯ Gauss åˆ†å¸ƒé‡‡æ ·åŠ¨ä½œçš„è¿‡ç¨‹æ˜¯ä¸å¯å¯¼çš„ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†é‡å‚æ•°åŒ–æŠ€å·§ã€‚
é‡å‚æ•°åŒ–çš„åšæ³•æ˜¯å…ˆä»æ ‡å‡†çš„ Gauss åˆ†å¸ƒ $\mathcal{N}$ è¿›è¡Œé‡‡æ ·ï¼Œç„¶åå†å°†é‡‡æ ·å€¼ä¹˜ä»¥æ ‡å‡†å·®ååŠ ä¸Šå‡å€¼ï¼Œå¦‚ä¸‹ï¼š
$$
\begin{align}
a_t&amp;#x26;=f_\theta(\epsilon_t;s_t) \notag \
&amp;#x26;= \mu_\theta(s_t)+\epsilon_t\sigma_\theta(s_t), \quad \epsilon\sim\mathcal{N}(0,I)\notag
\end{align}
$$
è¿™æ ·å°±å¯ä»¥è®¤ä¸ºæ˜¯ä»ç­–ç•¥é«˜æ–¯åˆ†å¸ƒé‡‡æ ·ï¼Œå¹¶ä¸”è¿™æ ·å¯¹äºç­–ç•¥å‡½æ•°æ˜¯å¯å¯¼çš„ï¼ŒæŸå¤±å‡½æ•°å†™ä¸ºï¼š
$$
\begin{align}
L_\pi(\theta)=\arg\min_\theta \mathbb{E}&lt;em&gt;{s_t\sim R, \epsilon_t \sim \mathcal{N}}\left[\alpha\log \pi&lt;/em&gt;\theta(f_\theta(\epsilon_t;s_t)|s_t)-\min_{j=1,2}Q_\textbf{soft}^{\omega_j}(s_t,f_\theta(\epsilon_t;s_t))\right] \notag \
\end{align}
$$&lt;/p&gt;
&lt;h3&gt;è‡ªåŠ¨è°ƒæ•´ç†µç³»æ•° (Automating Entropy Adjustment)&lt;/h3&gt;
&lt;p&gt;åœ¨ SAC ç®—æ³•ä¸­ï¼Œå¦‚ä½•é€‰æ‹©ç†µæ­£åˆ™é¡¹çš„ç³»æ•°éå¸¸é‡è¦ã€‚åœ¨ä¸åŒçš„çŠ¶æ€ä¸‹éœ€è¦ä¸åŒå¤§å°çš„ç†µï¼šåœ¨æœ€ä¼˜åŠ¨ä½œä¸ç¡®å®šçš„æŸä¸ªçŠ¶æ€ä¸‹ï¼Œç†µçš„å–å€¼åº”è¯¥å¤§ä¸€ç‚¹ï¼›è€Œåœ¨æŸä¸ªæœ€ä¼˜åŠ¨ä½œæ¯”è¾ƒç¡®å®šçš„çŠ¶æ€ä¸‹ï¼Œç†µçš„å–å€¼å¯ä»¥å°ä¸€ç‚¹ã€‚
ä¸ºäº†è‡ªåŠ¨è°ƒæ•´ç†µæ­£åˆ™é¡¹ï¼ŒSAC å°†å¼ºåŒ–å­¦ä¹ çš„ç›®æ ‡æ”¹å†™ä¸ºä¸€ä¸ªå¸¦çº¦æŸçš„ä¼˜åŒ–é—®é¢˜ï¼š
$$
\begin{align}
\arg\max_\theta\mathbb{E}&lt;em&gt;{(s_t,a_t)\sim \rho^{\pi&lt;/em&gt;\theta}}\left[\sum_{t=0}^\infty r(s_t,a_t)\right] \quad \text{s.t.} \quad \mathbb{E}&lt;em&gt;{(s_t,a_t)\sim\rho^{\pi&lt;/em&gt;\theta}}\left[-\log\pi_\theta(a_t|s_t)\right]\ge H_0\notag \
\end{align}
$$
å°†ä¸Šè¿°é—®é¢˜è½¬åŒ–ä¸º KKTï¼ˆKarush-Kuhn-Tuckerï¼‰æ¡ä»¶ä¸‹çš„çº¦æŸé—®é¢˜ï¼š
$$
\begin{align}
\arg\min_\theta\mathbb{E}&lt;em&gt;{(s_t,a_t)\sim \rho^{\pi&lt;/em&gt;\theta}}\left[-\sum_{t=0}^\infty r(s_t,a_t)\right] \quad \text{s.t.} \quad H_0-\mathbb{E}&lt;em&gt;{(s_t,a_t)\sim\rho^{\pi&lt;/em&gt;\theta}}\left[-\log\pi_\theta(a_t|s_t)\right]\le 0\notag \
\end{align}
$$
é€šè¿‡æ‹‰æ ¼æœ—æ—¥ä¹˜æ•°æ³•ï¼Œè½¬åŒ–ä¸ºæ— çº¦æŸé—®é¢˜ï¼Œæ‹‰æ ¼æœ—æ—¥å‡½æ•°ä¸ºï¼š
$$
\begin{align}
L(\theta,\alpha)=\mathbb{E}&lt;em&gt;{(s_t,a_t)\sim \rho^{\pi&lt;/em&gt;\theta}}\left[-\sum_{t=0}^\infty r(s_t,a_t)\right] + \alpha\left[H_0-\mathbb{E}&lt;em&gt;{(s_t,a_t)\sim\rho^{\pi&lt;/em&gt;\theta}}\left[-\log\pi_\theta(a_t|s_t)\right]\right] \notag
\end{align}
$$
å…¶ä¸­ $\alpha\ge0$ æ˜¯æ‹‰æ ¼æœ—æ—¥ä¹˜æ•°ï¼Œå°†æ‹‰æ ¼æœ—æ—¥å‡½æ•°ä¸­ä¸ $\alpha$ ç›¸å…³çš„æå–å‡ºæ¥ï¼š
$$
\begin{align}
L(\alpha)=\mathbb{E}&lt;em&gt;{s_t\sim R,a_t\sim\pi&lt;/em&gt;\theta(\cdot|s_t)}\left[-\alpha\log\pi_\theta(a_t|s_t)-\alpha H_0\right] \notag
\end{align}
$$
å³å½“ç­–ç•¥çš„ç†µä½äºç›®æ ‡å€¼ $H_0$ æ—¶ï¼Œè®­ç»ƒç›®æ ‡ $L(\alpha)$ ä¼šä½¿ $\alpha$ çš„å€¼å¢å¤§ï¼Œè¿›è€Œåœ¨ä¸Šè¿°æœ€å°åŒ–æŸå¤±å‡½æ•° $L_\pi(\theta)$ çš„è¿‡ç¨‹ä¸­å¢åŠ äº†ç­–ç•¥ç†µå¯¹åº”é¡¹çš„é‡è¦æ€§ï¼›è€Œå½“ç­–ç•¥çš„ç†µé«˜äºç›®æ ‡å€¼ $H_0$ æ—¶ï¼Œè®­ç»ƒç›®æ ‡ $L(\alpha)$ ä¼šä½¿ $\alpha$ çš„å€¼å‡å°ï¼Œè¿›è€Œä½¿å¾—ç­–ç•¥è®­ç»ƒæ—¶æ›´ä¸“æ³¨äºä»·å€¼æå‡ã€‚&lt;/p&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-2.8vndvqvn7c.webp"/><enclosure url="https://pic.hana0721.top/rl-note-2.8vndvqvn7c.webp"/></item><item><title>RLç¬”è®°ï¼ˆ14ï¼‰ï¼šSQL</title><link>https://claudiakim6827362.github.io/blog/rl-note-14</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/rl-note-14</guid><description>æ·±å…¥è§£æ Soft Q-Learning (SQL)ï¼šä»æœ€å¤§ç†µå¼ºåŒ–å­¦ä¹ åŸç†å‡ºå‘ï¼Œè¯¦ç»†æ¨å¯¼ Soft Bellman æ–¹ç¨‹ã€ç­–ç•¥æå‡å®šç†åŠæ”¶æ•›æ€§è¯æ˜ï¼Œå¹¶æ¢è®¨åŸºäºèƒ½é‡æ¨¡å‹çš„ç­–ç•¥é‡‡æ ·ä¸å®ç°ç»†èŠ‚ã€‚</description><pubDate>Tue, 23 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;å¼•è¨€ï¼ˆIntroductionï¼‰&lt;/h2&gt;
&lt;p&gt;Soft Q-Learning (SQL) æ˜¯å¼ºåŒ–å­¦ä¹ ä¸­ç»“åˆ &lt;strong&gt;æœ€å¤§ç†µå¼ºåŒ–å­¦ä¹ ï¼ˆMaximum Entropy Reinforcement Learningï¼‰&lt;/strong&gt; æ€æƒ³çš„ Q-Learning æ‰©å±•ç®—æ³•ã€‚
å®ƒçš„æ ¸å¿ƒç›®æ ‡ä¸ä»…ä»…æ˜¯æ‰¾åˆ°&lt;strong&gt;é‚£ä¸€æ¡&lt;/strong&gt;è·å¾—æœ€é«˜åˆ†çš„è·¯ï¼Œè€Œæ˜¯è¦æ‰¾åˆ°&lt;strong&gt;æ‰€æœ‰&lt;/strong&gt;èƒ½è·å¾—é«˜åˆ†çš„è·¯ã€‚å®ƒåœ¨æœ€å¤§åŒ–ç´¯ç§¯å¥–åŠ±çš„åŒæ—¶ï¼Œå¼ºåˆ¶ç­–ç•¥ä¿æŒéšæœºæ€§ï¼ˆå³æœ€å¤§åŒ–ç­–ç•¥çš„ç†µï¼‰ï¼Œä»è€Œæå‡ç­–ç•¥çš„æ¢ç´¢èƒ½åŠ›ã€é²æ£’æ€§å’Œæ³›åŒ–æ€§ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;æœ€å¤§ç†µå¼ºåŒ–å­¦ä¹ ï¼ˆMaximum Entropy RLï¼‰&lt;/h2&gt;
&lt;h3&gt;åŸºæœ¬å®šä¹‰&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;ç†µï¼ˆEntropyï¼‰&lt;/strong&gt; æ˜¯è¡¨ç¤ºéšæœºå˜é‡ä¸ç¡®å®šæ€§çš„åº¦é‡ã€‚å¯¹äºéšæœºå˜é‡ $X$ï¼Œå¦‚æœå…¶æ¦‚ç‡å¯†åº¦ä¸º $p$ï¼Œç†µ $H$ å®šä¹‰ä¸ºï¼š&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
H(X)&amp;#x26;=\mathbb{E}&lt;em&gt;{x\sim p}[-\log p(x)]\notag \
&amp;#x26;=-\int&lt;/em&gt;{X}p(x)\log p(x) \mathrm{d}x \notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;åœ¨å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬å…³æ³¨çš„æ˜¯ç­–ç•¥ $\pi$ åœ¨çŠ¶æ€ $s$ ä¸‹çš„éšæœºç¨‹åº¦ï¼Œè®°ä¸º $H(\pi(\cdot|s))$ã€‚&lt;/p&gt;
&lt;h3&gt;ç›®æ ‡å‡½æ•°&lt;/h3&gt;
&lt;p&gt;æœ€å¤§ç†µå¼ºåŒ–å­¦ä¹ çš„æ€æƒ³æ˜¯ï¼šé™¤äº†æœ€å¤§åŒ–ç´¯è®¡å¥–åŠ±ï¼Œè¿˜è¦ä½¿å¾—ç­–ç•¥æ›´åŠ éšæœºã€‚å› æ­¤ï¼Œç›®æ ‡å‡½æ•°ä¸­åŠ å…¥äº†ä¸€é¡¹&lt;strong&gt;ç†µæ­£åˆ™é¡¹&lt;/strong&gt;ï¼š&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\pi_{\textbf{MaxEnt}}^*=\arg\max_{\pi}\sum_{t=0}^\infty \mathbb{E}_{\pi}[ r(s_t,a_t)+\alpha H(\pi(\cdot|s_t))]\notag
\end{align}
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\alpha$ (Temperature)ï¼šæ­£åˆ™é¡¹ç³»æ•°ï¼Œç”¨æ¥æƒè¡¡ç†µçš„é‡è¦ç¨‹åº¦ã€‚
&lt;ul&gt;
&lt;li&gt;$\alpha \to 0$ï¼šé€€åŒ–ä¸ºæ ‡å‡† RLï¼ˆè´ªå©ªï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;$\alpha$ è¶Šå¤§ï¼šè¶Šé¼“åŠ±æ¢ç´¢ï¼Œç­–ç•¥åˆ†å¸ƒè¶Šå¹³å¦ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;ğŸ’¡ ç›´è§‰ç†è§£&lt;/strong&gt;ï¼š
è¿™ä¸€é¡¹ $\alpha H$ çš„åŠ å…¥ï¼Œæ„å‘³ç€æ™ºèƒ½ä½“å¦‚æœä¸å»æ¢ç´¢æ–°çš„åŠ¨ä½œï¼Œæˆ–è€…å¤ªæ—©ç¡®å®šä¸€ä¸ªåŠ¨ä½œï¼ˆç†µå˜ä½ï¼‰ï¼Œå°±ä¼šå—åˆ°â€œæƒ©ç½šâ€ã€‚è¿™èƒ½æœ‰æ•ˆé˜²æ­¢æ™ºèƒ½ä½“é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2&gt;åŸºäºèƒ½é‡çš„æ¨¡å‹ (Energy-Based Model, EBM)&lt;/h2&gt;
&lt;p&gt;SQL ä½¿ç”¨åŸºäºèƒ½é‡çš„æ¨¡å‹æ¥å»ºæ¨¡ç­–ç•¥ã€‚è¿™æºäºç»Ÿè®¡ç‰©ç†å­¦ï¼šèƒ½é‡è¶Šä½çš„çŠ¶æ€ï¼Œå‡ºç°çš„æ¦‚ç‡è¶Šé«˜ã€‚&lt;/p&gt;
&lt;p&gt;åœ¨å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬å°†çŠ¶æ€-åŠ¨ä½œå¯¹ $(s,a)$ æ˜ å°„åˆ°èƒ½é‡å€¼ $\mathcal{E}$ã€‚ç­–ç•¥åˆ†å¸ƒå®šä¹‰ä¸ºï¼š&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\pi(a|s)=\frac{\exp(-\mathcal{E}(s,a))}{Z(s)}\notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;å…¶ä¸­ï¼Œ$Z(s)$ æ˜¯&lt;strong&gt;é…åˆ†å‡½æ•°ï¼ˆPartition Functionï¼‰&lt;/strong&gt;ï¼Œç”¨äºå½’ä¸€åŒ–ï¼Œç¡®ä¿æ¦‚ç‡ä¹‹å’Œä¸º 1ï¼š
$$
Z(s)=\int_{\mathcal{A}}\exp(-\mathcal{E}(s,a))\mathrm{d}a
$$&lt;/p&gt;
&lt;p&gt;åœ¨ Soft Q-Learning ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ç”¨ Soft Q å€¼æ¥ä»£æ›¿è´Ÿèƒ½é‡ $-\mathcal{E}(s,a)$ï¼Œå³ $Q_{soft}(s,a)$ è¶Šå¤§ï¼Œé€‰æ‹©è¯¥åŠ¨ä½œçš„æ¦‚ç‡è¶Šå¤§ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;Soft è´å°”æ›¼æ–¹ç¨‹ (Soft Bellman Equation)&lt;/h2&gt;
&lt;p&gt;ä¸ºäº†æ¨å¯¼ SQLï¼Œæˆ‘ä»¬éœ€è¦é‡æ–°å®šä¹‰ä»·å€¼å‡½æ•° $V$ å’Œ $Q$ï¼Œå°†ç†µåŒ…å«è¿›å»ã€‚&lt;/p&gt;
&lt;h3&gt;å›é¡¾ï¼šæ™®é€šè´å°”æ›¼æ–¹ç¨‹&lt;/h3&gt;
&lt;p&gt;æ™®é€š $Q$ å€¼ï¼š
$$
\begin{align}
Q^\pi(s,a) &amp;#x26;= r(s,a)+\gamma\mathbb{E}&lt;em&gt;{s^\prime \sim p(\cdot|s,a)}[V^\pi(s^\prime)] \notag
\end{align}
$$
æ™®é€š $V$ å€¼ï¼š
$$
\begin{align}
V^\pi(s) &amp;#x26;=\mathbb{E}&lt;/em&gt;{a\sim \pi(\cdot|s)}[Q^\pi(s,a)] \notag
\end{align}
$$&lt;/p&gt;
&lt;h3&gt;å®šä¹‰ï¼šSoft è´å°”æ›¼æ–¹ç¨‹&lt;/h3&gt;
&lt;p&gt;åœ¨æœ€å¤§ç†µæ¡†æ¶ä¸‹ï¼Œä»·å€¼å‡½æ•°çš„å®šä¹‰å‘ç”Ÿäº†å˜åŒ–ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Soft çŠ¶æ€ä»·å€¼å‡½æ•° $V_\text{soft}$ æ¨å¯¼ï¼š&lt;/strong&gt;
$V_\text{soft}$ ä¸ä»…åŒ…å«æœªæ¥çš„å¥–åŠ±ï¼Œè¿˜åŒ…å«æœªæ¥çš„ç†µã€‚&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
V_{\textbf{soft}}^\pi(s)
&amp;#x26;=\mathbb{E}&lt;em&gt;{\pi}[\sum&lt;/em&gt;{l=0}^\infty \gamma^l(R_{t+l}+\alpha H(\pi(\cdot|S_{t+l})))|S_t=s] \notag \
&amp;#x26;=\mathbb{E}&lt;em&gt;{\pi}[R_t+\alpha H(\pi(\cdot|S_t))|S_t=s]+\gamma \mathbb{E}&lt;/em&gt;{\pi}[\sum_{l=0}^\infty \gamma^l(R_{t+1+l}+\alpha H(\pi(\cdot|S_{t+1+l})))] \notag \
&amp;#x26;=\mathbb{E}&lt;em&gt;{a\sim\pi(\cdot|s)}[r(s,a)]+\alpha H(\pi(\cdot|s))+\gamma \mathbb{E}&lt;/em&gt;{a\sim\pi(\cdot|s),s^\prime\sim p(\cdot|s,a)}[V^{\pi}_{\textbf{soft}}(s^\prime)] \notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;å°† $H(\pi)$ å±•å¼€ä¸ºæœŸæœ›å½¢å¼ $\mathbb{E}[-\log \pi]$ï¼Œå¯ä»¥åˆå¹¶é¡¹ï¼š&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
V_{\textbf{soft}}^\pi(s)
&amp;#x26;=\mathbb{E}&lt;em&gt;{a\sim\pi(\cdot|s)}[r(s,a)-\alpha\log\pi(a|s)+\gamma\mathbb{E}&lt;/em&gt;{s^\prime\sim p(\cdot|s,a)}[V^{\pi}&lt;em&gt;{\textbf{soft}}(s^\prime)]] \notag \
&amp;#x26;=\mathbb{E}&lt;/em&gt;{a\sim\pi(\cdot|s)}[r(s,a)+\gamma \mathbb{E}&lt;em&gt;{s^\prime\sim p(\cdot|s,a)}[V^{\pi}&lt;/em&gt;{\textbf{soft}}(s^\prime)]]+\alpha H(\pi(\cdot|s)) \notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Soft åŠ¨ä½œä»·å€¼å‡½æ•° $Q_\text{soft}$ æ¨å¯¼ï¼š&lt;/strong&gt;
ä¸ $V$ ç±»ä¼¼ï¼Œå±•å¼€é€’å½’å½¢å¼ï¼š&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
Q_{\textbf{soft}}^\pi(s,a)
&amp;#x26;=r(s,a)+\gamma \mathbb{E}&lt;em&gt;{s^\prime\sim p(\cdot|s,a),a^\prime\sim\pi(\cdot|s^\prime)}[Q^{\pi}&lt;/em&gt;{\textbf{soft}}(s^\prime,a^\prime)-\alpha\log\pi(a^\prime|s^\prime)] \notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ä¸¤è€…å…³ç³»æ€»ç»“ï¼š&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;V ä¸ Q çš„å…³ç³»&lt;/strong&gt;ï¼š
$$
\begin{align}
V_{\textbf{soft}}^\pi(s)&amp;#x26;=\mathbb{E}&lt;em&gt;{a\sim\pi(\cdot|s)}[Q^{\pi}&lt;/em&gt;{\textbf{soft}}(s,a)-\alpha\log\pi(a|s)]\notag \
&amp;#x26;=\mathbb{E}&lt;em&gt;{a\sim \pi(a|s)}[Q^{\pi}&lt;/em&gt;{\textbf{soft}}(s,a)]+\alpha H(\pi(\cdot|s)) \notag
\end{align}
$$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;ğŸ’¡ ç¬”è®°&lt;/strong&gt;ï¼šè¿™è¯´æ˜ $V$ å€¼ç­‰äº $Q$ å€¼çš„æœŸæœ›åŠ ä¸Šå½“å‰çš„ç†µçº¢åˆ©ã€‚&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Q ä¸ V çš„å…³ç³»&lt;/strong&gt;ï¼ˆSoft Bellmanï¼‰ï¼š
$$
\begin{align}
Q^{\pi}&lt;em&gt;{\textbf{soft}}(s,a)=r(s,a)+\gamma \mathbb{E}&lt;/em&gt;{s^\prime\sim p(\cdot|s,a)}[V_{\textbf{soft}}^\pi(s^\prime)]\notag \
\end{align}
$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2&gt;Soft ç­–ç•¥æå‡å®šç† (Soft Policy Improvement)&lt;/h2&gt;
&lt;p&gt;æˆ‘ä»¬å¦‚ä½•ä¿è¯æ›´æ–°ç­–ç•¥åï¼Œæ•ˆæœä¸€å®šä¼šå˜å¥½ï¼Ÿè¿™é‡Œç»™å‡ºäº†è¯¦ç»†è¯æ˜ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;å®šç†&lt;/strong&gt;ï¼šå¯¹äºä»»æ„çŠ¶æ€ $s$ï¼Œå¦‚æœæˆ‘ä»¬æŒ‰ç…§ä»¥ä¸‹è§„åˆ™æ›´æ–°ç­–ç•¥ï¼š
$$
\begin{align}
\tilde{\pi}(\cdot|s) \propto \exp(\frac{1}{\alpha}Q^{\pi}_{\textbf{soft}}(s,\cdot)), \quad \forall s \in \mathcal{S} \notag \
\end{align}
$$
é‚£ä¹ˆæ–°ç­–ç•¥ $\tilde{\pi}$ çš„ Soft Q å€¼ä¸€å®šä¼˜äºæ—§ç­–ç•¥ $\pi$ã€‚&lt;/p&gt;
&lt;h3&gt;è¯æ˜è¿‡ç¨‹&lt;/h3&gt;
&lt;p&gt;é¦–å…ˆï¼Œæˆ‘ä»¬è®¡ç®—æ—§ç­–ç•¥ $\pi$ ä¸‹çš„ $V$ å€¼ï¼Œå¹¶å°è¯•å¼•å…¥æ–°ç­–ç•¥ $\tilde{\pi}$ çš„å½¢å¼ã€‚&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
V_{\textbf{soft}}^\pi(s)&amp;#x26;=\mathbb{E}&lt;em&gt;{a\sim \pi(\cdot|s)}[Q&lt;/em&gt;{\textbf{soft}}^\pi(s,a)]+\alpha H(\pi(\cdot|s)) \notag \
&amp;#x26;=\int_a\pi(a|s)Q_{\textbf{soft}}^\pi(s,a)\text{d}a-\alpha\int_a\pi(a|s)\log\pi(a|s)\text{d}a\notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;è¿™é‡Œåˆ©ç”¨ä¸€ä¸ªæ’ç­‰å˜æ¢ã€‚å› ä¸ºæ›´æ–°è§„åˆ™ $\tilde{\pi}(a|s) = \frac{\exp(\frac{1}{\alpha}Q(s,a))}{Z(s)}$ï¼Œæ‰€ä»¥ $Q(s,a) = \alpha \log \tilde{\pi}(a|s) + \alpha \log Z(s)$ã€‚
ä»£å…¥ç§¯åˆ†ä¸­ï¼š&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
V_{\textbf{soft}}^\pi(s) &amp;#x26;= \alpha\int_a \pi(a|s) \left[ \log \tilde{\pi}(a|s) + \log \int_{a^\prime}\exp(\frac{1}{\alpha}Q_{\textbf{soft}}^\pi(s,a^\prime))\text{d}a^\prime \right] \text{d}a - \alpha\int_a\pi(a|s)\log\pi(a|s)\text{d}a \notag \
&amp;#x26;= \alpha \log \left[ \int_{a^\prime}\exp(\frac{1}{\alpha}Q_{\textbf{soft}}^\pi(s,a^\prime))\text{d}a^\prime \right] + \alpha \int_a \pi(a|s) \log \frac{\tilde{\pi}(a|s)}{\pi(a|s)} \text{d}a \notag \
&amp;#x26;= \alpha \log \int_a\exp(\frac{1}{\alpha}Q_{\textbf{soft}}^\pi(s,a))\text{d}a - \alpha D_{\textbf{KL}}(\pi(\cdot|s)||\tilde{\pi}(\cdot|s)) \notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;å½“ $\pi = \tilde{\pi}$ æ—¶ï¼ŒKL æ•£åº¦ä¸º 0ï¼Œæˆ‘ä»¬å¾—åˆ°&lt;strong&gt;Soft Value Function çš„è§£æè§£ï¼ˆLogSumExp å½¢å¼ï¼‰&lt;/strong&gt;ï¼š
$$
V_{\textbf{soft}}^{\tilde{\pi}}(s) = \alpha \log \int_a \exp(\frac{1}{\alpha}Q_{\textbf{soft}}^\pi(s,a))\text{d}a
$$&lt;/p&gt;
&lt;p&gt;å› ä¸º KL æ•£åº¦éè´Ÿï¼ˆ$D_{KL} \ge 0$ï¼‰ï¼Œä¸” $\alpha &gt; 0$ï¼Œæ‰€ä»¥å»æ‰ KL é¡¹åï¼Œä¸ç­‰å¼æˆç«‹ï¼š
$$
\begin{align}
\alpha \log \int_a \exp(\frac{1}{\alpha}Q)\text{d}a \ge V_{\textbf{soft}}^\pi(s) + \alpha D_{\textbf{KL}} \ge V_{\textbf{soft}}^\pi(s) \notag
\end{align}
$$
è¿™å¯¼å‡ºäº†å…³é”®ä¸ç­‰å¼ï¼š
$$
\begin{align}
\mathbb{E}&lt;em&gt;{a\sim\tilde{\pi}(\cdot|s)}[Q&lt;/em&gt;{\textbf{soft}}^\pi(s,a)]+ \alpha H(\tilde{\pi}(\cdot|s))\ge
\mathbb{E}&lt;em&gt;{a\sim\pi(\cdot|s)}[Q&lt;/em&gt;{\textbf{soft}}^\pi(s,a)]+ \alpha H(\pi(\cdot|s)) \notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;æ¥ä¸‹æ¥çš„è¿­ä»£æ¨å¯¼è¯æ˜äº† $Q$ å€¼çš„å•è°ƒé€’å¢æ€§ï¼ˆé€šè¿‡ä¸æ–­å±•å¼€è´å°”æ›¼ç®—å­ï¼‰ï¼š&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
Q_{\textbf{soft}}^\pi(s,a) &amp;#x26;= r_0 + \gamma V_{soft}^\pi(s_1) \notag \
&amp;#x26;\le r_0 + \gamma (\mathbb{E}&lt;em&gt;{a_1 \sim \tilde{\pi}}[Q^\pi(s_1, a_1)] + \alpha H(\tilde{\pi})) \quad \text{(æ ¹æ®ä¸Šè¿°ä¸ç­‰å¼)} \notag \
&amp;#x26;\le \dots \notag \
&amp;#x26;\le Q&lt;/em&gt;{\textbf{soft}}^{\tilde{\pi}}(s,a) \notag
\end{align}
$$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;ğŸ’¡ ç»“è®º&lt;/strong&gt;ï¼š
åªè¦æˆ‘ä»¬å°†ç­–ç•¥æ›´æ–°ä¸ºæ­£æ¯”äº $\exp(Q/\alpha)$ï¼Œæ–°çš„ç­–ç•¥åœ¨ Soft Q å€¼çš„è¯„ä¼°ä¸‹ä¸€å®šæ¯”æ—§ç­–ç•¥æ›´å¥½ï¼ˆæˆ–æŒå¹³ï¼‰ã€‚&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2&gt;Soft ç­–ç•¥è¯„ä¼°å®šç†ä¸æ”¶æ•›æ€§è¯æ˜&lt;/h2&gt;
&lt;p&gt;æˆ‘ä»¬å®šä¹‰&lt;strong&gt;Soft è´å°”æ›¼ç®—å­ $\mathcal{T}$&lt;/strong&gt;ï¼Œå¹¶è¯æ˜åå¤åº”ç”¨å®ƒä¼šæ”¶æ•›åˆ°æœ€ä¼˜å€¼ã€‚&lt;/p&gt;
&lt;p&gt;å®šä¹‰ç®—å­æ“ä½œï¼š
$$
\begin{align}
\mathcal{T} Q_{\textbf{soft}}^\pi(s,a) \triangleq r(s,a)+\gamma \mathbb{E}&lt;em&gt;{s^\prime\sim p(\cdot|s,a)}\left[\alpha\log\int&lt;/em&gt;{a^\prime}\exp (\frac{1}{\alpha}Q_{\textbf{soft}}^\pi(s^\prime,a^\prime))\text{d}a^\prime\right]\notag
\end{align}
$$&lt;/p&gt;
&lt;h3&gt;å‹ç¼©æ˜ å°„è¯æ˜ (Contraction Mapping)&lt;/h3&gt;
&lt;p&gt;æˆ‘ä»¬è¦è¯æ˜ $||\mathcal{T}Q_1 - \mathcal{T}Q_2|| \le k ||Q_1 - Q_2||$ï¼Œå…¶ä¸­ $k &amp;#x3C; 1$ã€‚&lt;/p&gt;
&lt;p&gt;å®šä¹‰åº¦é‡è·ç¦» $\epsilon = \max_{s,a}|Q_1(s,a) - Q_2(s,a)|$ã€‚
è¿™æ„å‘³å¯¹äºä»»æ„ $(s,a)$ï¼š
$$
Q_1(s,a) \le Q_2(s,a) + \epsilon
$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;å…³é”®æ¨å¯¼æ­¥éª¤&lt;/strong&gt;ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;åˆ©ç”¨æŒ‡æ•°å•è°ƒæ€§ï¼š
$$
\exp(\frac{1}{\alpha}Q_1) \le \exp(\frac{1}{\alpha}(Q_2 + \epsilon)) = \exp(\frac{Q_2}{\alpha}) \cdot \exp(\frac{\epsilon}{\alpha})
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ç§¯åˆ†ä¿åºæ€§ï¼š
$$
\int \exp(\frac{Q_1}{\alpha}) \text{d}a&apos; \le \exp(\frac{\epsilon}{\alpha}) \int \exp(\frac{Q_2}{\alpha}) \text{d}a&apos;
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;å– $\alpha \log$ï¼ˆ&lt;strong&gt;æ³¨æ„è¿™é‡Œçš„å¸¸æ•°æå–&lt;/strong&gt;ï¼‰ï¼š
$$
\begin{align}
\alpha \log \int \exp(\frac{Q_1}{\alpha}) \text{d}a&apos;
&amp;#x26;\le \alpha \log \left[ \exp(\frac{\epsilon}{\alpha}) \int \exp(\frac{Q_2}{\alpha}) \text{d}a&apos; \right] \notag \
&amp;#x26;= \alpha \left[ \log(\exp(\frac{\epsilon}{\alpha})) + \log \int \exp(\frac{Q_2}{\alpha}) \text{d}a&apos; \right] \notag \
&amp;#x26;= \alpha \left[ \frac{\epsilon}{\alpha} + \log \int \exp(\frac{Q_2}{\alpha}) \text{d}a&apos; \right] \notag \
&amp;#x26;= \epsilon + \alpha \log \int \exp(\frac{Q_2}{\alpha}) \text{d}a&apos; \notag
\end{align}
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;è®¡ç®—ç®—å­å·®å€¼ï¼š
$$
\begin{align}
|\mathcal{T}Q_1 - \mathcal{T}Q_2| &amp;#x26;= \gamma \left| \mathbb{E}&lt;em&gt;{s&apos;} \left[ \alpha \log \int&lt;/em&gt;{a^\prime} \exp(\frac{Q_1(s^\prime,a^\prime)}{\alpha}) \text{d}a^\prime - \alpha \log \int_{a^\prime} \exp(\frac{Q_2(s^\prime,a^\prime)}{\alpha}) \text{d}a^\prime \right] \right| \notag \
&amp;#x26;\le \gamma \mathbb{E}&lt;em&gt;{s&apos;} [\epsilon] \notag \
&amp;#x26;= \gamma \max&lt;/em&gt;{s,a} |Q_1(s,a)-Q_2(s,a)| \notag
\end{align}
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ç»“è®ºï¼š
$$
||\mathcal{T}Q_1 - \mathcal{T}Q_2||&lt;em&gt;\infty \le \gamma ||Q_1 - Q_2||&lt;/em&gt;\infty
$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ç”±äºæŠ˜æ‰£å› å­ $\gamma \in (0,1)$ï¼Œç®—å­ $\mathcal{T}$ æ˜¯ä¸€ä¸ª&lt;strong&gt;å‹ç¼©æ˜ å°„&lt;/strong&gt;ï¼Œå¿…ç„¶æ”¶æ•›åˆ°å”¯ä¸€çš„ä¸åŠ¨ç‚¹ $Q^*_\text{soft}$ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;å®ç°å›°éš¾ä¸è§£å†³æ–¹æ¡ˆ&lt;/h2&gt;
&lt;p&gt;ç†è®ºå¾ˆå®Œç¾ï¼Œä½†å®é™…ç”¨ç¥ç»ç½‘ç»œå®ç°æ—¶ï¼ˆDeep RLï¼‰ï¼Œæœ‰ä¸¤ä¸ªä¸»è¦å›°éš¾ã€‚&lt;/p&gt;
&lt;h3&gt;å›°éš¾ 1ï¼šå¤„ç†ç§¯åˆ† (The Integral Problem)&lt;/h3&gt;
&lt;p&gt;åœ¨è®¡ç®— $V_\text{soft}(s)$ æ—¶ï¼Œéœ€è¦è®¡ç®— $\log \int \exp(Q) \text{d}a$ã€‚
å¦‚æœåŠ¨ä½œç©ºé—´æ˜¯è¿ç»­çš„ï¼Œè¿™ä¸ªç§¯åˆ†é€šå¸¸æ— æ³•è§£æè®¡ç®—ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;è§£å†³æ–¹æ¡ˆï¼šé‡è¦æ€§é‡‡æ · (Importance Sampling)&lt;/strong&gt;
æˆ‘ä»¬æŠŠç§¯åˆ†è½¬åŒ–ä¸ºæœŸæœ›ï¼Œé€šè¿‡é‡‡æ ·æ¥è¿‘ä¼¼ã€‚
å¼•å…¥ä¸€ä¸ªé‡‡æ ·åˆ†å¸ƒ $q_a(a)$ï¼ˆé€šå¸¸å¯ä»¥æ˜¯å½“å‰çš„ç­–ç•¥ç½‘ç»œï¼‰ï¼š&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
V_{\textbf{soft}}^{\theta}(s)&amp;#x26;= \alpha \log \int_a \exp(\frac{1}{\alpha}Q_{\textbf{soft}}^{\theta}(s,a))\text{d}a\notag \
&amp;#x26;=\alpha\log\int_a q_a(a)\frac{\exp(\frac{1}{\alpha}Q_{\textbf{soft}}^{\theta}(s,a))}{q_a(a)} \text{d}a \notag \
&amp;#x26;\approx \alpha \log \mathbb{E}&lt;em&gt;{a\sim q_a(\cdot)}\left[\frac{\exp(\frac{1}{\alpha}Q&lt;/em&gt;{\textbf{soft}}^{\theta}(s,a))}{q_a(a)}\right] \notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;äºæ˜¯ï¼ŒSoft Q-Learning çš„ç›®æ ‡å‡½æ•°ï¼ˆBellman Errorï¼‰å˜ä¸ºï¼š&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
J_Q(\theta)&amp;#x26;=\mathbb{E}&lt;em&gt;{\mathcal{D}}\left[\frac{1}{2}\left(\hat{Q}&lt;/em&gt;{\textbf{soft}}(s_t,a_t)-Q_{\textbf{soft}}^\theta(s_t,a_t)\right)^2\right]\notag
\end{align}
$$
å…¶ä¸­ç›®æ ‡å€¼ $\hat{Q}$ ä½¿ç”¨ä¸Šè¿°çš„é‡è¦æ€§é‡‡æ ·ä¼°è®¡æ¥è®¡ç®— $V$ã€‚&lt;/p&gt;
&lt;h3&gt;å›°éš¾ 2ï¼šç­–ç•¥é‡‡æ · (Sampling from Energy-Based Policy)&lt;/h3&gt;
&lt;p&gt;ç†è®ºä¸Šçš„æœ€ä¼˜ç­–ç•¥æ˜¯åŸºäºèƒ½é‡çš„ï¼š$\pi(a|s) \propto \exp(\frac{1}{\alpha}Q(s,a))$ã€‚
è¿™æ˜¯ä¸€ç§å¤æ‚çš„åˆ†å¸ƒï¼Œæˆ‘ä»¬æ— æ³•ç›´æ¥ä» Q ç½‘ç»œä¸­é«˜æ•ˆé‡‡æ ·åŠ¨ä½œã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;è§£å†³æ–¹æ¡ˆï¼šAmortized Inference (è¿‘ä¼¼æ¨æ–­)&lt;/strong&gt;
æˆ‘ä»¬è®­ç»ƒä¸€ä¸ªæ˜¾å¼çš„ç­–ç•¥ç½‘ç»œï¼ˆActorï¼‰$\pi_\phi(a|s)$ï¼ˆé€šå¸¸æ˜¯é«˜æ–¯åˆ†å¸ƒæˆ–ç”±ç¥ç»ç½‘ç»œç”Ÿæˆçš„åˆ†å¸ƒï¼‰ï¼Œè®©å®ƒå»é€¼è¿‘é‚£ä¸ªèƒ½é‡åˆ†å¸ƒã€‚&lt;/p&gt;
&lt;p&gt;ç›®æ ‡æ˜¯æœ€å°åŒ–ä¸¤è€…ä¹‹é—´çš„ KL æ•£åº¦ï¼š
$$
\begin{align}
J_\pi(\phi;s_t)=D_{\textbf{KL}}\left(\pi_\phi(\cdot|s_t)\Big|\Big|\exp\left(\frac{1}{\alpha}(Q_{\textbf{soft}}^\theta(s_t,\cdot)-V_{\textbf{soft}}^\theta(s_t))\right)\right)\notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;å°† KL æ•£åº¦å±•å¼€å¹¶å¿½ç•¥å¸¸æ•°é¡¹ï¼Œç­‰ä»·äºæœ€å¤§åŒ–ï¼š
$$
\mathbb{E}&lt;em&gt;{a \sim \pi&lt;/em&gt;\phi}[Q^\theta(s,a) - \alpha \log \pi_\phi(a|s)]
$$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;ğŸ’¡ å®ç°ç»†èŠ‚&lt;/strong&gt;ï¼š
åœ¨ SQL åŸæ–‡ä¸­ï¼Œä½œè€…ä½¿ç”¨äº† &lt;strong&gt;SVGD (Stein Variational Gradient Descent)&lt;/strong&gt; æ–¹æ³•æ¥æ›´æ–°è¿™ä¸ªç­–ç•¥ç½‘ç»œï¼Œè¿™å…è®¸ç­–ç•¥ç”Ÿæˆéå¸¸å¤æ‚çš„å¤šæ¨¡æ€åˆ†å¸ƒã€‚åç»­çš„ SAC ç®—æ³•åˆ™ä½¿ç”¨äº†é‡å‚æ•°åŒ–æŠ€å·§ï¼ˆReparameterization Trickï¼‰æ¥ç®€åŒ–è¿™ä¸€æ­¥ã€‚&lt;/p&gt;
&lt;/blockquote&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-2.8vndvqvn7c.webp"/><enclosure url="https://pic.hana0721.top/rl-note-2.8vndvqvn7c.webp"/></item><item><title>RLç¬”è®°ï¼ˆ13ï¼‰ï¼šDDPG</title><link>https://claudiakim6827362.github.io/blog/rl-note-13</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/rl-note-13</guid><description>æ·±åº¦ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦ï¼šå°† DQN æ‰©å±•åˆ°è¿ç»­åŠ¨ä½œç©ºé—´ã€‚è¯¦è§£ DDPG çš„è½¯æ›´æ–°ä¸å™ªå£°æ¢ç´¢ï¼Œä»¥åŠ TD3 å¦‚ä½•é€šè¿‡åŒ Q ç½‘ç»œå’Œå»¶è¿Ÿæ›´æ–°è§£å†³è¿‡ä¼°è®¡é—®é¢˜ã€‚</description><pubDate>Mon, 22 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;å¼•è¨€ï¼ˆIntroductionï¼‰&lt;/h2&gt;
&lt;p&gt;æˆ‘ä»¬ä¹‹å‰å­¦è¿‡ &lt;strong&gt;DQN&lt;/strong&gt;ï¼ˆå¤„ç†ç¦»æ•£åŠ¨ä½œçš„ä»·å€¼æ–¹æ³•ï¼‰å’Œ &lt;strong&gt;REINFORCE/PPO&lt;/strong&gt;ï¼ˆå¤„ç†è¿ç»­/ç¦»æ•£åŠ¨ä½œçš„éšæœºç­–ç•¥æ–¹æ³•ï¼‰ã€‚
å¦‚æœæˆ‘ä»¬å°† DQN çš„æ€æƒ³ï¼ˆOff-policy, Replay Bufferï¼‰åº”ç”¨åˆ°è¿ç»­æ§åˆ¶ä»»åŠ¡ä¸­ï¼Œä¼šé‡åˆ°ä»€ä¹ˆé—®é¢˜ï¼Ÿ&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DQN éœ€è¦å¯¹åŠ¨ä½œå–æœ€å¤§å€¼ $\max_a Q(s,a)$ã€‚åœ¨è¿ç»­ç©ºé—´ä¸­ï¼Œè¿™ä¸ªæœ€å¤§åŒ–æ“ä½œæœ¬èº«å°±æ˜¯ä¸€ä¸ªå¤æ‚çš„ä¼˜åŒ–é—®é¢˜ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;DDPG (Deep Deterministic Policy Gradient)&lt;/strong&gt; çš„å‡ºç°è§£å†³äº†è¿™ä¸ªé—®é¢˜ã€‚ä½ å¯ä»¥ç®€å•åœ°æŠŠå®ƒç†è§£ä¸º &lt;strong&gt;â€œDQN + Actor-Criticâ€&lt;/strong&gt;ã€‚å®ƒä½¿ç”¨ä¸€ä¸ª Actor ç½‘ç»œæ¥ç›´æ¥è¾“å‡ºé‚£ä¸ªâ€œè®© Q å€¼æœ€å¤§çš„åŠ¨ä½œâ€ï¼Œä»è€Œé¿å…äº†å¤æ‚çš„ç§¯åˆ†æˆ–æœ€å¤§åŒ–è®¡ç®—ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;ç­–ç•¥ç±»å‹çš„æœ¬è´¨åŒºåˆ«&lt;/h2&gt;
&lt;p&gt;åœ¨æ·±å…¥ DDPG ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦æ˜ç¡®ä¸¤ç§ç­–ç•¥çš„æ•°å­¦å½¢å¼å·®å¼‚ã€‚&lt;/p&gt;
&lt;h3&gt;éšæœºç­–ç•¥ (Stochastic Policy)&lt;/h3&gt;
&lt;p&gt;è¾“å‡ºåŠ¨ä½œçš„&lt;strong&gt;æ¦‚ç‡åˆ†å¸ƒ&lt;/strong&gt;ï¼ˆå¦‚é«˜æ–¯åˆ†å¸ƒçš„å‡å€¼å’Œæ–¹å·®ï¼‰ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç¦»æ•£åŠ¨ä½œ&lt;/strong&gt;ï¼š$\pi(a|s;\theta)=\frac{\exp(Q_\theta(s,a))}{\sum_{a^\prime}\exp(Q_\theta(s,a^\prime))}$ (Softmax)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è¿ç»­åŠ¨ä½œ&lt;/strong&gt;ï¼š$\pi(a|s;\theta) \sim \mathcal{N}(\mu_\theta(s), \sigma_\theta(s))$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;ç¡®å®šæ€§ç­–ç•¥ (Deterministic Policy)&lt;/h3&gt;
&lt;p&gt;å¯¹äºåŒä¸€ä¸ªçŠ¶æ€ï¼Œæ°¸è¿œè¾“å‡º&lt;strong&gt;åŒä¸€ä¸ªåŠ¨ä½œ&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç¦»æ•£åŠ¨ä½œ&lt;/strong&gt;ï¼š$\pi(s;\theta)=\operatorname{argmax}&lt;em&gt;{a} Q&lt;/em&gt;\theta(s,a)$ (ä¸å¯å¾®ï¼Œæ— æ³•ç”¨æ¢¯åº¦ä¸‹é™ç›´æ¥ä¼˜åŒ–)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è¿ç»­åŠ¨ä½œ&lt;/strong&gt;ï¼š$a=\mu_\theta(s)$ (å¯å¾®ï¼Œè¿™æ­£æ˜¯ DDPG çš„åŸºç¡€)&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;ğŸ’¡ æ ¸å¿ƒåŒºåˆ«&lt;/strong&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;éšæœºç­–ç•¥&lt;/strong&gt;é€šè¿‡&lt;strong&gt;å¯¹æ•°ä¼¼ç„¶ (Log-Likelihood)&lt;/strong&gt; æ¥æ›´æ–°å‚æ•°ï¼š$\nabla \log \pi \cdot Q$ã€‚å®ƒè¯•æ¢æ€§åœ°å¢åŠ é«˜åˆ†åŠ¨ä½œçš„æ¦‚ç‡ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç¡®å®šæ€§ç­–ç•¥&lt;/strong&gt;é€šè¿‡&lt;strong&gt;é“¾å¼æ³•åˆ™ (Chain Rule)&lt;/strong&gt; æ¥æ›´æ–°å‚æ•°ï¼š$\nabla_a Q \cdot \nabla_\theta \mu$ã€‚å®ƒç›´æ¥å‘Šè¯‰åŠ¨ä½œâ€œå¾€å“ªä¸ªæ–¹å‘æŒªä¸€ç‚¹ï¼ŒQ å€¼ä¼šå˜å¤§â€ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2&gt;ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦å®šç† (DPG)&lt;/h2&gt;
&lt;p&gt;è¿™æ˜¯ DDPG çš„ç†è®ºåŸºçŸ³ã€‚æˆ‘ä»¬å¸Œæœ›æ‰¾åˆ°ç­–ç•¥å‚æ•° $\theta$ï¼Œæœ€å¤§åŒ–ç›®æ ‡å‡½æ•° $J(\theta) = \mathbb{E}[Q(s, \mu_\theta(s))]$ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;å®šç†æ¨å¯¼&lt;/strong&gt;ï¼š
å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ª Critic ç½‘ç»œ $Q^w(s,a)$ ä¼°å¾—è¶³å¤Ÿå‡†ã€‚æˆ‘ä»¬æƒ³è°ƒæ•´ Actor $\mu_\theta(s)$ï¼Œä½¿å¾—è¾“å‡ºçš„åŠ¨ä½œ $a$ èƒ½è·å¾—æ›´å¤§çš„ $Q$ å€¼ã€‚
æ ¹æ®é“¾å¼æ³•åˆ™ï¼š
$$
\begin{align}
\nabla_\theta J(\mu_\theta) &amp;#x26;= \mathbb{E}&lt;em&gt;{s \sim \rho^\pi} [\nabla&lt;/em&gt;\theta Q^w(s, \mu_\theta(s))] \notag \
&amp;#x26;= \mathbb{E}&lt;em&gt;{s \sim \rho^\pi} [\underbrace{\nabla_a Q^w(s,a)|&lt;/em&gt;{a=\mu_\theta(s)}}&lt;em&gt;{\text{Critic æŒ‡å‡ºçš„æ–¹å‘}} \cdot \underbrace{\nabla&lt;/em&gt;\theta \mu_\theta(s)}_{\text{Actor çš„æ¢¯åº¦}}] \notag
\end{align}
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç›´è§‰&lt;/strong&gt;ï¼šCritic å‘Šè¯‰ Actorï¼šâ€œåŠ¨ä½œ $a$ å¾€å¤§å˜ä¸€ç‚¹ï¼ŒQ å€¼èƒ½å¢åŠ â€ã€‚Actor å°±è®¡ç®—å¦‚ä½•è°ƒæ•´ $\theta$ æ‰èƒ½è®© $a$ å˜å¤§ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;æ·±åº¦ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦ (DDPG)&lt;/h2&gt;
&lt;p&gt;DDPG æ˜¯ Deep Q-Network (DQN) åœ¨è¿ç»­åŠ¨ä½œç©ºé—´çš„è‡ªç„¶å»¶ä¼¸ã€‚&lt;/p&gt;
&lt;h3&gt;æ ¸å¿ƒç»„ä»¶&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Actor-Critic æ¶æ„&lt;/strong&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Actor $\mu(s; \theta)$ï¼šè¾“å‡ºç¡®å®šæ€§åŠ¨ä½œã€‚&lt;/li&gt;
&lt;li&gt;Critic $Q(s, a; w)$ï¼šè¯„ä¼° (çŠ¶æ€, åŠ¨ä½œ) çš„ä»·å€¼ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ç»éªŒå›æ”¾ (Replay Buffer)&lt;/strong&gt;ï¼šä¸ DQN ä¸€æ ·ï¼Œå­˜å‚¨ $(s, a, r, s&apos;)$ï¼Œæ‰“ç ´æ•°æ®ç›¸å…³æ€§ï¼Œå®ç° Off-Policy è®­ç»ƒã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ç›®æ ‡ç½‘ç»œ (Target Networks)&lt;/strong&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ä¸ºäº†ç¨³å®šè®­ç»ƒï¼Œå»ºç«‹äº† Target Actor $\mu&apos;$ å’Œ Target Critic $Q&apos;$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å…³é”®æ”¹è¿›ï¼šè½¯æ›´æ–° (Soft Update)&lt;/strong&gt;ã€‚
DQN æ˜¯æ¯éš” $C$ æ­¥ç¡¬æ‹·è´å‚æ•°ã€‚DDPG ä½¿ç”¨æ»‘åŠ¨å¹³å‡ï¼š
$$ \theta&apos; \leftarrow \tau \theta + (1-\tau)\theta&apos; $$
å…¶ä¸­ $\tau \ll 1$ (å¦‚ 0.001)ã€‚è¿™ä½¿å¾—ç›®æ ‡å€¼å˜åŒ–éå¸¸å¹³æ»‘ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;æ¢ç´¢ç­–ç•¥ (Exploration)&lt;/strong&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ç¡®å®šæ€§ç­–ç•¥æœ¬èº«ä¸ä¼šæ¢ç´¢ã€‚DDPG å¿…é¡»åœ¨åŠ¨ä½œä¸Š&lt;strong&gt;åŠ å™ªå£°&lt;/strong&gt;æ¥è¿›è¡Œæ¢ç´¢ï¼š
$$ a_t = \mu_\theta(s_t) + \mathcal{N}_t $$&lt;/li&gt;
&lt;li&gt;åŸè®ºæ–‡ä½¿ç”¨äº† &lt;strong&gt;Ornstein-Uhlenbeck (OU)&lt;/strong&gt; å™ªå£°ï¼ˆå…·æœ‰æ—¶é—´ç›¸å…³æ€§ï¼Œé€‚åˆæƒ¯æ€§ç³»ç»Ÿï¼‰ã€‚ç°åœ¨çš„å®è·µé€šå¸¸ç›´æ¥ä½¿ç”¨ç®€å•çš„&lt;strong&gt;é«˜æ–¯å™ªå£°&lt;/strong&gt; $\mathcal{N}(0, \sigma)$ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;DDPG ç®—æ³•æµç¨‹&lt;/h3&gt;
&lt;p&gt;$$
\begin{aligned}
&amp;#x26; \bullet ; \text{Initialize Actor } \mu_\theta, \text{Critic } Q_w, \text{Target nets } \mu&apos;, Q&apos; \
&amp;#x26; \bullet ; \textbf{For } \text{episode } = 1 \to E \textbf{ do}: \
&amp;#x26; \bullet \qquad \text{Receive initial state } s \
&amp;#x26; \bullet \qquad \textbf{For } t = 1 \to T \textbf{ do}: \
&amp;#x26; \bullet \qquad \qquad \text{Select action } a = \mu_\theta(s) + \text{Noise} \
&amp;#x26; \bullet \qquad \qquad \text{Execute } a, \text{ observe } r, s&apos; \
&amp;#x26; \bullet \qquad \qquad \text{Store } (s, a, r, s&apos;) \text{ in Buffer } \mathcal{R} \
&amp;#x26; \bullet \qquad \qquad \text{Sample batch } N \text{ from } \mathcal{R} \
&amp;#x26; \bullet \qquad \qquad \textbf{// Update Critic (minimize MSBE)} \
&amp;#x26; \bullet \qquad \qquad y = r + \gamma Q&apos;(s&apos;, \mu&apos;(s&apos;)) \
&amp;#x26; \bullet \qquad \qquad L_w = \frac{1}{N}\sum (y - Q_w(s,a))^2 \
&amp;#x26; \bullet \qquad \qquad \textbf{// Update Actor (maximize Q)} \
&amp;#x26; \bullet \qquad \qquad \nabla_\theta J = \frac{1}{N} \sum \nabla_a Q_w(s,a) \nabla_\theta \mu_\theta(s) \
&amp;#x26; \bullet \qquad \qquad \textbf{// Soft Update Targets} \
&amp;#x26; \bullet \qquad \qquad \theta&apos; \leftarrow \tau \theta + (1-\tau)\theta&apos; \
&amp;#x26; \bullet \qquad \qquad w&apos; \leftarrow \tau w + (1-\tau)w&apos; \
&amp;#x26; \bullet \qquad \textbf{End For} \
&amp;#x26; \bullet ; \textbf{End For}
\end{aligned}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;åŒä»·å€¼å‡½æ•°ç­–ç•¥å»¶æ—¶æ›´æ–° (TD3)&lt;/h2&gt;
&lt;p&gt;DDPG å¾ˆå¼ºï¼Œä½†éå¸¸&lt;strong&gt;è„†å¼±&lt;/strong&gt;ï¼Œå¯¹è¶…å‚æ•°æ•æ„Ÿã€‚å®ƒç»§æ‰¿äº† DQN çš„&lt;strong&gt;è¿‡é«˜ä¼°è®¡ (Overestimation)&lt;/strong&gt; é—®é¢˜ï¼Œç”šè‡³æ›´ä¸¥é‡ã€‚TD3 æå‡ºäº†ä¸‰ä¸ªæŠ€å·§æ¥ä¿®æ­£å®ƒã€‚&lt;/p&gt;
&lt;h3&gt;æŠ€å·§ 1ï¼šæˆªæ–­åŒ Q å­¦ä¹  (Clipped Double Q-Learning)&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;é—®é¢˜&lt;/strong&gt;ï¼šDQN ä¸­ $y = r + \gamma \max Q$ ä¼šå¯¼è‡´ä»·å€¼é«˜ä¼°ã€‚DDPG ä¸­è™½ç„¶æ²¡æœ‰ maxï¼Œä½† Actor ä¹Ÿæ˜¯æœç€ Q å€¼æœ€å¤§çš„æ–¹å‘æ›´æ–°çš„ï¼Œæ•ˆæœä¸€æ ·ã€‚
&lt;strong&gt;è§£å†³&lt;/strong&gt;ï¼šå­¦ä¹ ä¸¤ä¸ª Critic ($Q_1, Q_2$)ï¼Œè®¡ç®—ç›®æ ‡å€¼æ—¶&lt;strong&gt;å–æœ€å°å€¼&lt;/strong&gt;ã€‚
$$ y = r + \gamma \min_{i=1,2} Q_{\phi_i&apos;}(s&apos;, \tilde{a}) $$
è¿™ä½“ç°äº†â€œæ‚²è§‚ä¸»ä¹‰â€åŸåˆ™ï¼Œå®å¯ä½ä¼°ä¹Ÿä¸è¦é«˜ä¼°ã€‚&lt;/p&gt;
&lt;h3&gt;æŠ€å·§ 2ï¼šç­–ç•¥å‚æ•°å»¶è¿Ÿæ›´æ–° (Delayed Policy Updates)&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;é—®é¢˜&lt;/strong&gt;ï¼šCritic è¿˜åœ¨å­¦ä¹ ä¸­ï¼Œæ³¢åŠ¨å¾ˆå¤§ã€‚å¦‚æœ Actor é¢‘ç¹æ ¹æ®é”™è¯¯çš„ Critic è°ƒæ•´æ–¹å‘ï¼Œä¼šå¯¼è‡´ç­–ç•¥éœ‡è¡å‘æ•£ã€‚
&lt;strong&gt;è§£å†³&lt;/strong&gt;ï¼šè®© Critic å¤šç»ƒå‡ æ¬¡ï¼ŒActor å†åŠ¨ã€‚
é€šå¸¸ Critic æ›´æ–° 2 æ¬¡ï¼ˆæˆ–æ›´å¤šï¼‰ï¼ŒActor å’Œ ç›®æ ‡ç½‘ç»œæ‰æ›´æ–° 1 æ¬¡ã€‚&lt;/p&gt;
&lt;h3&gt;ç›®æ ‡ç­–ç•¥å¹³æ»‘ (Target Policy Smoothing)&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;é—®é¢˜&lt;/strong&gt;ï¼šCritic å¯èƒ½ä¼šå¯¹æŸäº›å°–å³°å€¼ï¼ˆé”™è¯¯çš„ Q å€¼å³°å€¼ï¼‰è¿‡æ‹Ÿåˆã€‚
&lt;strong&gt;è§£å†³&lt;/strong&gt;ï¼šåœ¨è®¡ç®—ç›®æ ‡å€¼æ—¶ï¼Œç»™åŠ¨ä½œåŠ ä¸€ç‚¹&lt;strong&gt;è¢«æˆªæ–­çš„å™ªå£°&lt;/strong&gt;ï¼Œè®© Q å‡½æ•°åœ¨åŠ¨ä½œå‘¨å›´æ›´å¹³æ»‘ã€‚
$$
\tilde{a} = \mu_{\theta&apos;}(s&apos;) + \epsilon, \quad \epsilon \sim \text{clip}(\mathcal{N}(0, \sigma), -c, c)
$$
$$ y = r + \gamma \min Q&apos;(s&apos;, \tilde{a}) $$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;ğŸ’¡ ç›´è§‰&lt;/strong&gt;ï¼šç›¸ä¼¼çš„åŠ¨ä½œåº”è¯¥æœ‰ç›¸ä¼¼çš„ä»·å€¼ã€‚å¦‚æœåŠ¨ä½œç¨å¾®å˜ä¸€ç‚¹ç‚¹ï¼Œä»·å€¼å°±å‰§çƒˆå˜åŒ–ï¼Œè¯´æ˜è¿™ä¸ª Critic æ˜¯æœ‰é—®é¢˜çš„ï¼ˆè¿‡æ‹Ÿåˆï¼‰ã€‚&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2&gt;æ·±åº¦è§£æï¼šDDPG/TD3 çš„å®šä½&lt;/h2&gt;
&lt;p&gt;æˆ‘ä»¬å¯ä»¥å°† DDPG/TD3 æ”¾åœ¨æ•´ä¸ª RL å®¶æ—è°±ç³»ä¸­è¿›è¡Œå¯¹æ¯”ï¼š&lt;/p&gt;
&lt;p&gt;| ç»´åº¦ | DDPG / TD3 | PPO / A2C | DQN |
| :--- | :--- | :--- | :--- |
| &lt;strong&gt;åŠ¨ä½œç©ºé—´&lt;/strong&gt; | &lt;strong&gt;è¿ç»­&lt;/strong&gt; (Continuous) | ç¦»æ•£ æˆ– è¿ç»­ | ç¦»æ•£ (Discrete) |
| &lt;strong&gt;ç­–ç•¥ç±»å‹&lt;/strong&gt; | &lt;strong&gt;ç¡®å®šæ€§ç­–ç•¥&lt;/strong&gt; ($\mu(s)$) | éšæœºç­–ç•¥ ($\pi(a|s)$) | ç¡®å®šæ€§ (argmax Q) |
| &lt;strong&gt;æ ·æœ¬æ•ˆç‡&lt;/strong&gt; | &lt;strong&gt;é«˜ (Off-Policy)&lt;/strong&gt; | ä½ (On-Policy) | é«˜ (Off-Policy) |
| &lt;strong&gt;æ›´æ–°æ–¹å¼&lt;/strong&gt; | &lt;strong&gt;é“¾å¼æ³•åˆ™&lt;/strong&gt; ($\nabla_a Q \nabla_\theta \mu$) | å¯¹æ•°ä¼¼ç„¶ ($\nabla \log \pi \cdot A$) | æœ€å°åŒ– TD Error |
| &lt;strong&gt;ç¨³å®šæ€§&lt;/strong&gt; | è¾ƒä½ (éœ€ç²¾ç»†è°ƒå‚) | &lt;strong&gt;é«˜&lt;/strong&gt; (é²æ£’æ€§å¼º) | ä¸­ |
| &lt;strong&gt;æ ¸å¿ƒç—›ç‚¹&lt;/strong&gt; | Q å€¼é«˜ä¼°ã€è¶…å‚æ•°æ•æ„Ÿ | é‡‡æ ·æ…¢ã€æ— æ³•åˆ©ç”¨æ—§æ•°æ® | æ— æ³•å¤„ç†è¿ç»­åŠ¨ä½œ |&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;æ€»ç»“&lt;/strong&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;DDPG&lt;/strong&gt; æ˜¯ DQN åœ¨è¿ç»­æ§åˆ¶é¢†åŸŸçš„ç»§æ‰¿è€…ï¼Œå¼•å…¥äº† Actor-Critic æ¶æ„ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;TD3&lt;/strong&gt; æ˜¯ DDPG çš„â€œè¡¥ä¸ç‰ˆâ€ï¼Œé€šè¿‡åŒ Q ç½‘ç»œå’Œå»¶è¿Ÿæ›´æ–°ï¼Œå¤§å¤§æå‡äº†ç®—æ³•çš„ç¨³å®šæ€§ã€‚&lt;/li&gt;
&lt;li&gt;å®ƒä»¬éƒ½æ˜¯ &lt;strong&gt;Off-Policy&lt;/strong&gt; ç®—æ³•ï¼Œé€‚åˆéœ€è¦æé«˜æ ·æœ¬æ•ˆç‡çš„åœºæ™¯ï¼ˆå¦‚æœºå™¨äººæ§åˆ¶ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-2.8vndvqvn7c.webp"/><enclosure url="https://pic.hana0721.top/rl-note-2.8vndvqvn7c.webp"/></item><item><title>RLç¬”è®°ï¼ˆ12ï¼‰ï¼šPPO</title><link>https://claudiakim6827362.github.io/blog/rl-note-12</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/rl-note-12</guid><description>OpenAI çš„é»˜è®¤ç®—æ³•ï¼šè¯¦è§£ PPO å¦‚ä½•é€šè¿‡ Clip æŠ€å·§ç®€åŒ– TRPOã€‚æ¶µç›– PPO-Clip ä¸ PPO-Penalty ä¸¤ç§å˜ä½“ã€GAE ä¼˜åŠ¿ä¼°è®¡åŠå®Œæ•´çš„æŸå¤±å‡½æ•°è®¾è®¡ã€‚åœ£PPOä¼Ÿå¤§æ— éœ€å¤šè¨€ï¼</description><pubDate>Sun, 21 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;å¼•è¨€ï¼ˆIntroductionï¼‰&lt;/h2&gt;
&lt;p&gt;ä¸Šä¸€ç« æåˆ°çš„ &lt;strong&gt;TRPO&lt;/strong&gt; è™½ç„¶ç†è®ºä¼˜ç¾ï¼ˆä¿è¯å•è°ƒä¸å‡ï¼‰ï¼Œä½†è®¡ç®—å¤ªå¤æ‚äº†ï¼ˆéœ€è¦å…±è½­æ¢¯åº¦æ³•æ±‚è§£ Hessian-Vector Productï¼‰ã€‚
OpenAI æå‡ºçš„ &lt;strong&gt;PPO (Proximal Policy Optimization)&lt;/strong&gt; æ˜¯ TRPO çš„ä¸€é˜¶è¿‘ä¼¼ç‰ˆæœ¬ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;æ ¸å¿ƒæ€æƒ³&lt;/strong&gt;ï¼šTRPO ä½¿ç”¨ KL æ•£åº¦ä½œä¸º&lt;strong&gt;ç¡¬çº¦æŸ (Constraint)&lt;/strong&gt;ï¼Œè€Œ PPO å°†çº¦æŸè½¬åŒ–ä¸º&lt;strong&gt;æƒ©ç½šé¡¹ (Penalty)&lt;/strong&gt; æˆ–è€…ç›´æ¥é€šè¿‡&lt;strong&gt;æˆªæ–­ (Clipping)&lt;/strong&gt; æ¥é™åˆ¶ç­–ç•¥æ›´æ–°å¹…åº¦ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åœ°ä½&lt;/strong&gt;ï¼šPPO æ˜¯ç›®å‰ Deep RL çš„åŸºå‡†ç®—æ³•ï¼Œå¹³è¡¡äº†å®ç°å¤æ‚åº¦ã€æ ·æœ¬æ•ˆç‡å’Œæ€§èƒ½ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;å˜ä½“ 1ï¼šPPO-Clip (ä¸»æµ)&lt;/h2&gt;
&lt;p&gt;è¿™æ˜¯ç›®å‰æœ€å¸¸ç”¨çš„ PPO ç‰ˆæœ¬ï¼Œå®ƒä¸éœ€è¦è®¡ç®— KL æ•£åº¦ï¼Œç›´æ¥åœ¨ç›®æ ‡å‡½æ•°é‡ŒåŠ¨æ‰‹è„šã€‚&lt;/p&gt;
&lt;h3&gt;é‡è¦æ€§é‡‡æ ·æ¯”ç‡&lt;/h3&gt;
&lt;p&gt;å®šä¹‰æ–°æ—§ç­–ç•¥çš„æ¯”ç‡ä¸º $r_t(\theta)$ï¼š
$$
r_t(\theta) = \frac{\pi_\theta(a_t|s_t)}{\pi_{\theta_{\text{old}}}(a_t|s_t)}
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å½“ $\theta = \theta_{\text{old}}$ æ—¶ï¼Œ$r_t = 1$ã€‚&lt;/li&gt;
&lt;li&gt;æˆ‘ä»¬å¸Œæœ› $r_t$ ä¸è¦åç¦» 1 å¤ªå¤šï¼Œè¿™æ„å‘³ç€æ–°ç­–ç•¥æ²¡æœ‰å‘ç”Ÿå‰§çƒˆå˜åŒ–ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;æˆªæ–­ç›®æ ‡å‡½æ•°&lt;/h3&gt;
&lt;p&gt;PPO-Clip çš„æ ¸å¿ƒç›®æ ‡å‡½æ•°å¦‚ä¸‹ï¼š
$$
L^{CLIP}(\theta)=\hat{\mathbb{E}}_t \left[ \min \left( r_t(\theta)\hat{A}_t, \text{clip}(r_t(\theta), 1-\epsilon, 1+\epsilon)\hat{A}_t \right) \right]
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\epsilon$ æ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼ˆé€šå¸¸ä¸º 0.2ï¼‰ï¼Œè¡¨ç¤ºå…è®¸ç­–ç•¥å˜åŒ–çš„å¹…åº¦ï¼ˆTrust Regionï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;$\text{clip}(r, 1-\epsilon, 1+\epsilon)$ï¼šæŠŠæ¯”ç‡ $r$ å¼ºåˆ¶é™åˆ¶åœ¨ $[0.8, 1.2]$ ä¹‹é—´ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;ç›´è§‚ç†è§£ï¼šä¸ºä»€ä¹ˆè¦ Minï¼Ÿ&lt;/h3&gt;
&lt;p&gt;æˆ‘ä»¬éœ€è¦åˆ†ä¸¤ç§æƒ…å†µæ¥çœ‹ä¼˜åŠ¿å‡½æ•° $\hat{A}_t$ çš„æ­£è´Ÿï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;æƒ…å†µ Aï¼šåŠ¨ä½œæ˜¯å¥½çš„ ($\hat{A}_t &gt; 0$)&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;æˆ‘ä»¬å¸Œæœ›å¢åŠ è¿™ä¸ªåŠ¨ä½œçš„æ¦‚ç‡ï¼Œå³ $r_t(\theta)$ å¢å¤§ã€‚&lt;/li&gt;
&lt;li&gt;ä½†ä¸èƒ½æ— é™å¢å¤§ã€‚å¦‚æœ $r_t &gt; 1+\epsilon$ï¼Œ&lt;code&gt;clip&lt;/code&gt; å‡½æ•°ä¼šå°†å…¶é”æ­»åœ¨ $1+\epsilon$ã€‚&lt;/li&gt;
&lt;li&gt;æ­¤æ—¶ $\min$ æ“ä½œç”Ÿæ•ˆï¼Œç›®æ ‡å‡½æ•°ä¸å†éš $r_t$ å¢åŠ è€Œå¢åŠ ã€‚è¿™é˜²æ­¢äº†ç­–ç•¥æ›´æ–°æ­¥å­å¤ªå¤§ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æƒ…å†µ Bï¼šåŠ¨ä½œæ˜¯åçš„ ($\hat{A}_t &amp;#x3C; 0$)&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;æˆ‘ä»¬å¸Œæœ›å‡å°è¿™ä¸ªåŠ¨ä½œçš„æ¦‚ç‡ï¼Œå³ $r_t(\theta)$ å‡å°ã€‚&lt;/li&gt;
&lt;li&gt;ä½†ä¸èƒ½æ— é™å‡å°ã€‚å¦‚æœ $r_t &amp;#x3C; 1-\epsilon$ï¼Œ&lt;code&gt;clip&lt;/code&gt; å‡½æ•°ä¼šå°†å…¶é”æ­»åœ¨ $1-\epsilon$ã€‚&lt;/li&gt;
&lt;li&gt;æ­¤æ—¶ $\min$ æ“ä½œç”Ÿæ•ˆï¼Œé˜²æ­¢ç­–ç•¥è¿‡åº¦ä¿®æ­£ï¼ˆä»¥æ­¤é¿å…ç­–ç•¥åå¡Œï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;ğŸ’¡ æ€»ç»“&lt;/strong&gt;ï¼š
åªæœ‰å½“ç­–ç•¥å˜åŒ–åœ¨â€œå®‰å…¨åŒºåŸŸâ€å†…æ—¶ï¼Œæˆ‘ä»¬æ‰è¿›è¡Œå¥–åŠ±ä¼˜åŒ–ï¼›ä¸€æ—¦è¶…å‡ºå®‰å…¨åŒºåŸŸï¼Œå°±ä¸å†ç»™äºˆé¢å¤–çš„æ¢¯åº¦å¥–åŠ±ã€‚&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2&gt;å˜ä½“ 2ï¼šPPO-Penalty (è‡ªé€‚åº” KL)&lt;/h2&gt;
&lt;p&gt;è¿™æ˜¯å¦ä¸€ç§æ¥è¿‘ TRPO åŸä¹‰çš„æ–¹æ³•ï¼Œå°† KL æ•£åº¦ä½œä¸ºæ­£åˆ™é¡¹åŠ å…¥ Lossï¼Œå¹¶åŠ¨æ€è°ƒæ•´ç³»æ•° $\beta$ã€‚&lt;/p&gt;
&lt;h3&gt;ç›®æ ‡å‡½æ•°&lt;/h3&gt;
&lt;p&gt;$$
L^{KLPEN}(\theta)=\hat{\mathbb{E}}&lt;em&gt;t \left[ r_t(\theta)\hat{A}&lt;em&gt;t - \beta D&lt;/em&gt;{KL}(\pi&lt;/em&gt;{\theta_{\text{old}}}(\cdot|s_t) || \pi_\theta(\cdot|s_t)) \right]
$$&lt;/p&gt;
&lt;h3&gt;è‡ªé€‚åº” $\beta$ æ›´æ–°è§„åˆ™&lt;/h3&gt;
&lt;p&gt;æˆ‘ä»¬åœ¨æ¯æ¬¡æ›´æ–°åè®¡ç®—å¹³å‡ KL æ•£åº¦ $d = \hat{\mathbb{E}}&lt;em&gt;t [D&lt;/em&gt;{KL}]$ï¼Œå¹¶ä¸ç›®æ ‡å€¼ $d_{\text{targ}}$ æ¯”è¾ƒï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å¦‚æœ $d &amp;#x3C; d_{\text{targ}} / 1.5$&lt;/strong&gt;ï¼šè¯´æ˜ç­–ç•¥å˜åŠ¨å¤ªå°ï¼Œæ­¥å­å¤ªä¿å®ˆã€‚&lt;strong&gt;å‡å°æƒ©ç½š&lt;/strong&gt; $\beta \leftarrow \beta / 2$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å¦‚æœ $d &gt; d_{\text{targ}} \times 1.5$&lt;/strong&gt;ï¼šè¯´æ˜ç­–ç•¥å˜åŠ¨å¤ªå¤§ï¼Œæ­¥å­å¤ªå±é™©ã€‚&lt;strong&gt;å¢å¤§æƒ©ç½š&lt;/strong&gt; $\beta \leftarrow \beta \times 2$ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;å¹¿ä¹‰ä¼˜åŠ¿ä¼°è®¡ (GAE)&lt;/h2&gt;
&lt;p&gt;åœ¨è®¡ç®—ä¼˜åŠ¿å‡½æ•° $\hat{A}_t$ æ—¶ï¼Œç®€å•çš„å¤šæ­¥ TD æˆ–è’™ç‰¹å¡æ´›éƒ½æœ‰å±€é™ã€‚PPO é€šå¸¸ä½¿ç”¨ &lt;strong&gt;GAE (Generalized Advantage Estimation)&lt;/strong&gt; æ¥å¹³è¡¡åå·®å’Œæ–¹å·®ã€‚&lt;/p&gt;
&lt;p&gt;æˆ‘ä»¬å®šä¹‰ TD Error $\delta_t = r_t + \gamma V(s_{t+1}) - V(s_t)$ã€‚
GAE æ˜¯ $\delta$ çš„åŠ æƒå‡ ä½•å¹³å‡ï¼š&lt;/p&gt;
&lt;p&gt;$$
\hat{A}&lt;em&gt;t^{GAE} = \sum&lt;/em&gt;{k=0}^{\infty} (\gamma \lambda)^k \delta_{t+k}
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\lambda = 0$ï¼šå³å•æ­¥ TDï¼ˆåå·®å¤§ï¼Œæ–¹å·®å°ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;$\lambda = 1$ï¼šå³è’™ç‰¹å¡æ´›ï¼ˆæ— åå·®ï¼Œæ–¹å·®å¤§ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;$\lambda \in (0, 1)$ï¼šé€šå¸¸å– 0.95ï¼Œåœ¨ä¸¤è€…ä¹‹é—´å–å¾—æœ€ä½³å¹³è¡¡ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;å®Œæ•´çš„ PPO æŸå¤±å‡½æ•°&lt;/h2&gt;
&lt;p&gt;åœ¨å®é™…ä»£ç å®ç°ï¼ˆå¦‚ Actor-Critic æ¶æ„ï¼‰ä¸­ï¼ŒPPO çš„æ€» Loss åŒ…å«ä¸‰éƒ¨åˆ†ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;ç­–ç•¥æŸå¤± (Policy Loss)&lt;/strong&gt;ï¼šå³ $L^{CLIP}$ï¼Œè®©ç­–ç•¥å˜å¥½ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä»·å€¼æŸå¤± (Value Loss)&lt;/strong&gt;ï¼š$L^{VF} = (V_\theta(s_t) - V_{target})^2$ï¼Œè®© Critic ä¼°å€¼æ›´å‡†ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç†µå¥–åŠ± (Entropy Bonus)&lt;/strong&gt;ï¼š$S[\pi_\theta]$ï¼Œé¼“åŠ±ç­–ç•¥ä¿æŒéšæœºæ€§ï¼Œé˜²æ­¢è¿‡æ—©æ”¶æ•›åˆ°å±€éƒ¨æœ€ä¼˜ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$$
L^{Total}_t(\theta) = - L^{CLIP}_t(\theta) + c_1 L^{VF}_t(\theta) - c_2 S&lt;a href=&quot;s_t&quot;&gt;\pi_\theta&lt;/a&gt;
$$
&lt;em&gt;(æ³¨ï¼šé€šå¸¸æ·±åº¦å­¦ä¹ æ¡†æ¶æ˜¯æœ€å°åŒ– Lossï¼Œæ‰€ä»¥æœ€å¤§åŒ–ç›®æ ‡å‰åŠ è´Ÿå·)&lt;/em&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;PPO ç®—æ³•æµç¨‹&lt;/h2&gt;
&lt;p&gt;$$
\begin{aligned}
&amp;#x26; \bullet ; \text{Initialize policy parameters } \theta \text{ and value parameters } \phi \
&amp;#x26; \bullet ; \textbf{For } \text{iteration } k = 1, 2, \dots \textbf{ do}: \
&amp;#x26; \bullet \qquad \textbf{1. Data Collection:} \
&amp;#x26; \bullet \qquad \text{Run policy } \pi_{\theta_{old}} \text{ in environment for } T \text{ steps} \
&amp;#x26; \bullet \qquad \text{Compute advantage estimates } \hat{A}&lt;em&gt;1, \dots, \hat{A}&lt;em&gt;T \text{ using GAE} \
&amp;#x26; \bullet \qquad \textbf{2. Optimization:} \
&amp;#x26; \bullet \qquad \textbf{For } \text{epoch } = 1 \to K \textbf{ do}: \
&amp;#x26; \bullet \qquad \qquad \text{Shuffle data and divide into mini-batches} \
&amp;#x26; \bullet \qquad \qquad \textbf{For } \text{each mini-batch } B \textbf{ do}: \
&amp;#x26; \bullet \qquad \qquad \qquad L = L^{CLIP}(\theta) - c_1 L^{VF}(\phi) + c_2 S[\pi&lt;/em&gt;\theta] \
&amp;#x26; \bullet \qquad \qquad \qquad \text{Update } \theta, \phi \text{ using Adam optimizer} \
&amp;#x26; \bullet \qquad \qquad \textbf{End For} \
&amp;#x26; \bullet \qquad \textbf{End For} \
&amp;#x26; \bullet \qquad \theta&lt;/em&gt;{old} \leftarrow \theta \
&amp;#x26; \bullet ; \textbf{End For}
\end{aligned}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;æ€»ç»“&lt;/h2&gt;
&lt;p&gt;PPO ä¹‹æ‰€ä»¥èƒ½æˆä¸º OpenAI çš„é»˜è®¤ç®—æ³•ï¼ˆDefault Algorithmï¼‰ï¼Œæ˜¯å› ä¸ºå®ƒï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;ç®€å•&lt;/strong&gt;ï¼šåªéœ€è¦å¯¹æ¢¯åº¦è¿›è¡Œç®€å•çš„æˆªæ–­ï¼ˆClipï¼‰ï¼Œä¸éœ€è¦å¤æ‚çš„äºŒé˜¶ä¼˜åŒ–ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç¨³å®š&lt;/strong&gt;ï¼šæˆªæ–­æœºåˆ¶ä¿è¯äº†ç­–ç•¥ä¸ä¼šå› ä¸ºä¸€æ¬¡ç³Ÿç³•çš„æ›´æ–°è€Œå´©æºƒã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;é€šç”¨&lt;/strong&gt;ï¼šæ—¢é€‚ç”¨äºç¦»æ•£åŠ¨ä½œï¼ˆAtariï¼‰ï¼Œä¹Ÿé€‚ç”¨äºè¿ç»­åŠ¨ä½œï¼ˆæœºå™¨äººæ§åˆ¶ï¼‰ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;è‡³æ­¤ï¼Œç»å…¸çš„ Policy Gradient å®¶æ—ï¼ˆREINFORCE $\to$ Actor-Critic $\to$ TRPO $\to$ PPOï¼‰å·²ç»æ¢³ç†å®Œæ¯•ã€‚&lt;/p&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-2.8vndvqvn7c.webp"/><enclosure url="https://pic.hana0721.top/rl-note-2.8vndvqvn7c.webp"/></item><item><title>RLç¬”è®°ï¼ˆ11ï¼‰ï¼šTRPO</title><link>https://claudiakim6827362.github.io/blog/rl-note-11</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/rl-note-11</guid><description>æ·±åº¦å¼ºåŒ–å­¦ä¹ çš„é‡Œç¨‹ç¢‘ï¼šè¯¦è§£ TRPO å¦‚ä½•é€šè¿‡ä¿¡ä»»åŒºåŸŸçº¦æŸä¿è¯ç­–ç•¥æ›´æ–°çš„å•è°ƒæ€§ã€‚æ¶µç›–ç›®æ ‡å‡½æ•°æ¨å¯¼ã€äºŒé˜¶æ³°å‹’è¿‘ä¼¼ã€å…±è½­æ¢¯åº¦æ³•åŠ HVP æŠ€å·§ã€‚</description><pubDate>Sat, 20 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;å¼•è¨€ï¼ˆIntroductionï¼‰&lt;/h2&gt;
&lt;p&gt;åœ¨ REINFORCE å’Œ A2C ç­‰ç­–ç•¥æ¢¯åº¦ç®—æ³•ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä½¿ç”¨å›ºå®šçš„å­¦ä¹ ç‡ $\alpha$ æ¥æ›´æ–°å‚æ•°ï¼š$\theta \leftarrow \theta + \alpha \nabla J$ã€‚
ä½†è¿™æœ‰ä¸€ä¸ªä¸¥é‡é—®é¢˜ï¼š&lt;strong&gt;ç­–ç•¥å‚æ•°çš„å˜åŒ– $\Delta \theta$ å¹¶ä¸ç­‰åŒäºç­–ç•¥è¡Œä¸ºçš„å˜åŒ–&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;æœ‰æ—¶å€™å‚æ•°æ”¹ä¸€ç‚¹ç‚¹ï¼Œç­–ç•¥åˆ†å¸ƒå˜åŠ¨å·¨å¤§ï¼ˆå¯¼è‡´æ€§èƒ½å´©å¡Œï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;æœ‰æ—¶å€™å‚æ•°æ”¹å¾ˆå¤šï¼Œç­–ç•¥åˆ†å¸ƒå‡ ä¹æ²¡å˜ï¼ˆè®­ç»ƒæ•ˆç‡ä½ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;TRPO (Trust Region Policy Optimization)&lt;/strong&gt; çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼šæˆ‘ä»¬ä¸ç›´æ¥æ§åˆ¶å‚æ•°çš„å˜åŒ–é‡ï¼Œè€Œæ˜¯æ§åˆ¶&lt;strong&gt;ç­–ç•¥åˆ†å¸ƒçš„å˜åŒ–é‡&lt;/strong&gt;ï¼ˆç”¨ KL æ•£åº¦è¡¡é‡ï¼‰ã€‚æˆ‘ä»¬åœ¨ä¸€ä¸ªâ€œä¿¡ä»»åŒºåŸŸâ€å†…è¿›è¡Œä¼˜åŒ–ï¼Œç¡®ä¿æ¯ä¸€æ­¥æ›´æ–°åï¼Œç­–ç•¥çš„è¡¨ç°éƒ½æ˜¯&lt;strong&gt;å•è°ƒä¸å‡&lt;/strong&gt;çš„ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;ç­–ç•¥ä¼˜åŒ–çš„å•è°ƒæ€§è¯æ˜&lt;/h2&gt;
&lt;p&gt;æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ‰¾åˆ°ä¸€ä¸ªæ–°ç­–ç•¥ $\pi_{\theta&apos;}$ï¼Œä½¿å¾—å®ƒçš„æœŸæœ›å›æŠ¥ $J(\theta&apos;)$ æ¯”æ—§ç­–ç•¥ $J(\theta)$ é«˜ã€‚&lt;/p&gt;
&lt;h3&gt;æ€§èƒ½å·®å¼‚å¼•ç† (Performance Difference Lemma)&lt;/h3&gt;
&lt;p&gt;é¦–å…ˆæ¨å¯¼æ–°æ—§ç­–ç•¥çš„ç›®æ ‡å‡½æ•°ä¹‹å·®ï¼š&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
J(\theta^\prime)-J(\theta)
&amp;#x26;= \mathbb{E}&lt;em&gt;{s_0}[V^{\pi&lt;/em&gt;{\theta^\prime}}(s_0)]-\mathbb{E}&lt;em&gt;{s_0}[V^{\pi&lt;/em&gt;{\theta}}(s_0)]\notag\
&amp;#x26;=\mathbb{E}&lt;em&gt;{\pi&lt;/em&gt;{\theta^\prime}}[\sum_{t=0}^\infty \gamma^t r(s_t,a_t)] - \mathbb{E}&lt;em&gt;{s_0}[\sum&lt;/em&gt;{t=0}^\infty \gamma^t V^{\pi_\theta}(s_t)-\sum_{t=1}^\infty \gamma^t V^{\pi_\theta}(s_t)] \notag \
&amp;#x26;=\mathbb{E}&lt;em&gt;{\pi&lt;/em&gt;{\theta^\prime}}[\sum_{t=0}^\infty \gamma^t r(s_t,a_t)] - \mathbb{E}&lt;em&gt;{\pi&lt;/em&gt;{\theta^\prime}}[\sum_{t=0}^\infty \gamma^t (V^{\pi_\theta}(s_t)-\gamma V^{\pi_\theta}(s_{t+1}))] \notag \
&amp;#x26;= \mathbb{E}&lt;em&gt;{\pi&lt;/em&gt;{\theta^\prime}}[\sum_{t=0}^\infty \gamma^t (r(s_t,a_t)+\gamma V^{\pi_\theta}(s_{t+1})-V^{\pi_\theta}(s_t))] \notag \
&amp;#x26;=\mathbb{E}&lt;em&gt;{\pi&lt;/em&gt;{\theta^\prime}}[\sum_{t=0}^\infty \gamma^t A^{\pi_\theta}(s_t,a_t )] \notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;å°†æœŸæœ›å±•å¼€ä¸ºçŠ¶æ€è®¿é—®åˆ†å¸ƒ $\nu^{\pi_{\theta&apos;}}$ çš„å½¢å¼ï¼š
$$
J(\theta^\prime)-J(\theta) = \sum_{t=0}^\infty \gamma^t \mathbb{E}&lt;em&gt;{s_t\sim p^{\pi&lt;/em&gt;{\theta^\prime}} \, ; a_t\sim\pi_{\theta^\prime}(\cdot|s_t)}[ A^{\pi_\theta}(s_t,a_t)]
= \frac{1}{1-\gamma} \mathbb{E}&lt;em&gt;{s\sim\nu^{\pi&lt;/em&gt;{\theta^\prime}}\, ;a\sim\pi_{\theta^\prime}(\cdot|s)}[A^{\pi_\theta}(s,a)]
$$&lt;/p&gt;
&lt;h3&gt;çŠ¶æ€åˆ†å¸ƒè¿‘ä¼¼&lt;/h3&gt;
&lt;p&gt;ä¸Šå¼å¾ˆéš¾è®¡ç®—ï¼Œå› ä¸º $\nu^{\pi_{\theta&apos;}}$ ä¾èµ–äºæ–°ç­–ç•¥ï¼ˆè€Œæ–°ç­–ç•¥è¿˜æ²¡æ±‚å‡ºæ¥ï¼‰ã€‚
TRPO åšäº†ä¸€ä¸ªå…³é”®å‡è®¾ï¼š&lt;strong&gt;å½“æ–°æ—§ç­–ç•¥å·®è·å¾ˆå°æ—¶ï¼ŒçŠ¶æ€è®¿é—®åˆ†å¸ƒå˜åŒ–ä¸å¤§&lt;/strong&gt;ï¼Œå³ $\nu^{\pi_{\theta&apos;}} \approx \nu^{\pi_\theta}$ã€‚&lt;/p&gt;
&lt;p&gt;ç›®æ ‡å‡½æ•°è¿‘ä¼¼ä¸ºï¼š
$$
\begin{align}
J(\theta^\prime)-J(\theta) &amp;#x26;\approx \frac{1}{1-\gamma}\mathbb{E}&lt;em&gt;{s\sim\nu^{\pi&lt;/em&gt;\theta}\,; a\sim\pi_{\theta^\prime}(\cdot|s)}[A^{\pi_\theta}(s,a)] \notag \
&amp;#x26;= \frac{1}{1-\gamma}\mathbb{E}&lt;em&gt;{s\sim\nu^{\pi&lt;/em&gt;\theta}\,; a\sim\pi_{\theta}(\cdot|s)}\left[\frac{\pi_{\theta^\prime}(a|s)}{\pi_\theta(a|s)}A^{\pi_\theta}(s,a)\right] \quad \text{(é‡è¦æ€§é‡‡æ ·)} \notag
\end{align}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;ä¿¡ä»»åŒºåŸŸçº¦æŸ&lt;/h2&gt;
&lt;p&gt;ä¸ºäº†è®©ä¸Šè¿°è¿‘ä¼¼æˆç«‹ï¼Œå¿…é¡»é™åˆ¶ $\pi_{\theta&apos;}$ å’Œ $\pi_\theta$ ä¸èƒ½å·®å¤ªå¤šã€‚æˆ‘ä»¬ä½¿ç”¨ &lt;strong&gt;KL æ•£åº¦&lt;/strong&gt; ä½œä¸ºçº¦æŸæ¡ä»¶ã€‚&lt;/p&gt;
&lt;p&gt;ä¼˜åŒ–ç›®æ ‡ï¼š
$$
\begin{align}
\max_{\theta^\prime} \quad &amp;#x26; \mathbb{E}&lt;em&gt;{s\sim\nu^{\pi&lt;/em&gt;\theta}\,; a\sim\pi_{\theta}(\cdot|s)}\left[\frac{\pi_{\theta^\prime}(a|s)}{\pi_\theta(a|s)}A^{\pi_\theta}(s,a)\right] \notag \
\text{s.t.} \quad &amp;#x26; \bar{D}&lt;em&gt;{KL}(\theta || \theta&apos;) = \mathbb{E}&lt;/em&gt;{s\sim\nu^{\pi_\theta}}[D_{KL}(\pi_{\theta}(\cdot|s) || \pi_{\theta&apos;}(\cdot|s))] \leqslant \delta \notag
\end{align}
$$
(æ³¨ï¼šå¿½ç•¥äº†å¸¸æ•°ç³»æ•° $\frac{1}{1-\gamma}$ï¼Œå› ä¸ºå®ƒä¸å½±å“æ¢¯åº¦æ–¹å‘)&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;æ•°å­¦è¿‘ä¼¼æ±‚è§£&lt;/h2&gt;
&lt;p&gt;ä¸ºäº†æ±‚è§£è¿™ä¸ªå¸¦çº¦æŸçš„ä¼˜åŒ–é—®é¢˜ï¼Œæˆ‘ä»¬å¯¹å…¶è¿›è¡Œæ³°å‹’å±•å¼€ã€‚&lt;/p&gt;
&lt;h3&gt;ç›®æ ‡å‡½æ•°çš„ä¸€é˜¶è¿‘ä¼¼&lt;/h3&gt;
&lt;p&gt;ä»¤ $L(\theta&apos;) = \mathbb{E}[\frac{\pi_{\theta&apos;}}{\pi_\theta} A^{\pi_\theta}]$ã€‚åœ¨ $\theta&apos; = \theta$ å¤„å±•å¼€ï¼š
$$
L(\theta&apos;) \approx L(\theta) + \nabla_{\theta&apos;} L(\theta&apos;)|&lt;em&gt;{\theta&apos;=\theta}^T (\theta&apos; - \theta)
$$
ç”±äº $L(\theta) = \mathbb{E}[1 \cdot A^{\pi&lt;/em&gt;\theta}] = 0$ (ä¼˜åŠ¿å‡½æ•°çš„æœŸæœ›ä¸º0)ï¼Œä¸” $\nabla_{\theta&apos;} L(\theta&apos;)|&lt;em&gt;{\theta} = \nabla&lt;/em&gt;\theta J(\theta)$ (ç­–ç•¥æ¢¯åº¦)ã€‚
è®°æ¢¯åº¦ä¸º $g$ï¼š
$$ L(\theta&apos;) \approx g^T (\theta&apos; - \theta) $$&lt;/p&gt;
&lt;h3&gt;çº¦æŸæ¡ä»¶çš„äºŒé˜¶è¿‘ä¼¼&lt;/h3&gt;
&lt;p&gt;KL æ•£åº¦åœ¨ $\theta&apos;=\theta$ å¤„çš„ä¸€é˜¶å¯¼æ•°ä¸º 0ï¼ˆå› ä¸ºæ˜¯æå°å€¼ç‚¹ï¼‰ï¼Œæ‰€ä»¥å¿…é¡»å±•å¼€åˆ°äºŒé˜¶ã€‚
$$
\bar{D}_{KL}(\theta || \theta&apos;) \approx \frac{1}{2} (\theta&apos; - \theta)^T \mathbf{H} (\theta&apos; - \theta)
$$
å…¶ä¸­ $\mathbf{H}$ æ˜¯ KL æ•£åº¦çš„ &lt;strong&gt;é»‘å¡çŸ©é˜µ (Hessian Matrix)&lt;/strong&gt;ï¼ˆä¹Ÿæ˜¯ Fisher Information Matrixï¼‰ã€‚&lt;/p&gt;
&lt;h3&gt;è¿‘ä¼¼åçš„ä¼˜åŒ–é—®é¢˜&lt;/h3&gt;
&lt;p&gt;ä»¤æ›´æ–°æ­¥é•¿ $\Delta \theta = \theta&apos; - \theta$ï¼Œé—®é¢˜è½¬åŒ–ä¸ºï¼š
$$
\begin{align}
\max_{\Delta \theta} \quad &amp;#x26; g^T \Delta \theta \notag \
\text{s.t.} \quad &amp;#x26; \frac{1}{2} \Delta \theta^T \mathbf{H} \Delta \theta \leqslant \delta \notag
\end{align}
$$&lt;/p&gt;
&lt;h3&gt;è§£æè§£&lt;/h3&gt;
&lt;p&gt;åˆ©ç”¨æ‹‰æ ¼æœ—æ—¥ä¹˜æ•°æ³•ï¼ˆæ¨å¯¼è§ä½ åŸç¬”è®°ï¼‰ï¼Œè§£å¾—ï¼š
$$
\Delta \theta = \sqrt{\frac{2\delta}{g^T \mathbf{H}^{-1} g}} \mathbf{H}^{-1} g
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;å…±è½­æ¢¯åº¦æ³• (Conjugate Gradient)&lt;/h2&gt;
&lt;p&gt;å…¬å¼é‡Œéœ€è¦è®¡ç®— $\mathbf{H}^{-1} g$ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;é—®é¢˜&lt;/strong&gt;ï¼š$\mathbf{H}$ æ˜¯ç¥ç»ç½‘ç»œå‚æ•°çš„ Hessian çŸ©é˜µã€‚å¦‚æœå‚æ•°æœ‰ 100ä¸‡ä¸ªï¼Œ$\mathbf{H}$ å°±æ˜¯ $100w \times 100w$ çš„çŸ©é˜µï¼Œæ˜¾å¼è®¡ç®—å®ƒçš„é€†æ˜¯ä¸å¯èƒ½çš„ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ€è·¯&lt;/strong&gt;ï¼šæˆ‘ä»¬ä¸éœ€è¦ç®— $\mathbf{H}^{-1}$ï¼Œæˆ‘ä»¬åªéœ€è¦ç®—å‘é‡ $x = \mathbf{H}^{-1} g$ã€‚è¿™ç­‰ä»·äºæ±‚è§£çº¿æ€§æ–¹ç¨‹ç»„ $\mathbf{H}x = g$ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;å…±è½­æ¢¯åº¦æ³• (CG)&lt;/strong&gt; æ˜¯ä¸€ç§è¿­ä»£ç®—æ³•ï¼Œå®ƒå¯ä»¥åªé€šè¿‡è®¡ç®—çŸ©é˜µ-å‘é‡ä¹˜ç§¯ ($\mathbf{H}v$)ï¼Œåœ¨ $k$ æ­¥å†…ï¼ˆ$k \ll \text{å‚æ•°ç»´åº¦}$ï¼‰æ‰¾åˆ° $x$ çš„è¿‘ä¼¼è§£ã€‚&lt;/p&gt;
&lt;h3&gt;Hessian-Vector Product (HVP)&lt;/h3&gt;
&lt;p&gt;CG ç®—æ³•éœ€è¦è®¡ç®— $\mathbf{H}v$ã€‚è™½ç„¶æˆ‘ä»¬ç®—ä¸èµ· $\mathbf{H}$ï¼Œä½†å¯ä»¥åˆ©ç”¨åå‘ä¼ æ’­ç®— $\mathbf{H}v$ã€‚
$$
\mathbf{H}v = \nabla_\theta (\nabla_\theta \bar{D}_{KL} \cdot v)
$$
&lt;strong&gt;ä»£ç å®ç°æŠ€å·§&lt;/strong&gt;ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;å…ˆç®— KL æ•£åº¦çš„æ¢¯åº¦ $\nabla \bar{D}_{KL}$ã€‚&lt;/li&gt;
&lt;li&gt;ç®—æ¢¯åº¦å’Œå‘é‡ $v$ çš„ç‚¹ç§¯ï¼š$scalar = \nabla \bar{D}_{KL}^T v$ã€‚&lt;/li&gt;
&lt;li&gt;å¯¹è¿™ä¸ªæ ‡é‡å†æ±‚ä¸€æ¬¡æ¢¯åº¦ï¼š$\nabla_\theta (scalar)$ã€‚
è¿™æ ·åªéœ€è¦ä¸¤æ¬¡åå‘ä¼ æ’­ï¼Œå°±èƒ½ç®—å‡º $\mathbf{H}v$ï¼Œå®Œå…¨é¿å…äº†å­˜å‚¨å·¨å¤§çš„ Hessian çŸ©é˜µã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2&gt;çº¿æœç´¢ (Line Search)&lt;/h2&gt;
&lt;p&gt;è™½ç„¶æˆ‘ä»¬ç®—å‡ºäº†æ›´æ–°æ–¹å‘ $\Delta \theta$ å’Œæœ€å¤§æ­¥é•¿ $\beta = \sqrt{\frac{2\delta}{g^T \mathbf{H}^{-1} g}}$ï¼Œä½†ç”±äºæ³°å‹’å±•å¼€åªæ˜¯&lt;strong&gt;å±€éƒ¨è¿‘ä¼¼&lt;/strong&gt;ï¼Œç›´æ¥èµ°è¿™ä¹ˆè¿œå¯èƒ½ä¼šå¯¼è‡´ç­–ç•¥æ€§èƒ½ä¸‹é™ï¼ˆKL æ•£åº¦è¶…æ ‡æˆ–ç›®æ ‡å‡½æ•°ä¸‹é™ï¼‰ã€‚&lt;/p&gt;
&lt;p&gt;TRPO é‡‡ç”¨ &lt;strong&gt;å›æº¯çº¿æœç´¢ (Backtracking Line Search)&lt;/strong&gt; æ¥ç¡®å®šæœ€ç»ˆæ­¥é•¿ï¼š
è®¾ $\theta_{new} = \theta + \alpha^j \beta \Delta \theta$ï¼Œå…¶ä¸­ $\alpha \in (0, 1)$ æ˜¯è¡°å‡ç³»æ•°ï¼ˆå¦‚ 0.5ï¼‰ã€‚
ä» $j=0, 1, 2, \dots$ å¼€å§‹å°è¯•ï¼Œç›´åˆ°æ»¡è¶³ä»¥ä¸‹ä¸¤ä¸ªæ¡ä»¶ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;KL çº¦æŸæ»¡è¶³&lt;/strong&gt;ï¼š$\bar{D}&lt;em&gt;{KL}(\theta || \theta&lt;/em&gt;{new}) \leqslant \delta$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç›®æ ‡å‡½æ•°æå‡&lt;/strong&gt;ï¼š$L(\theta_{new}) \geqslant 0$ (å³æ€§èƒ½ç¡®å®æå‡äº†)&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2&gt;TRPO ç®—æ³•æµç¨‹æ€»ç»“&lt;/h2&gt;
&lt;p&gt;$$
\begin{aligned}
&amp;#x26; \bullet ; \text{Initialize policy parameters } \theta_0 \
&amp;#x26; \bullet ; \textbf{For } k = 0, 1, 2, \dots \textbf{ do}: \
&amp;#x26; \bullet \qquad \text{Collect trajectories } \tau \text{ using } \pi_{\theta_k} \
&amp;#x26; \bullet \qquad \text{Estimate advantages } A^{\pi_{\theta_k}} \text{ (using GAE)} \
&amp;#x26; \bullet \qquad \text{Compute policy gradient } g = \nabla_\theta L(\theta)|&lt;em&gt;{\theta_k} \
&amp;#x26; \bullet \qquad \text{Use CG to compute } x \approx \mathbf{H}^{-1} g \text{ with HVP} \
&amp;#x26; \bullet \qquad \text{Compute max step length } \beta = \sqrt{\frac{2\delta}{x^T \mathbf{H} x}} \
&amp;#x26; \bullet \qquad \text{Perform Line Search to find best step size } \eta \in {\beta, 0.5\beta, 0.25\beta \dots} \
&amp;#x26; \bullet \qquad \text{Update } \theta&lt;/em&gt;{k+1} = \theta_k + \eta x \
&amp;#x26; \bullet ; \textbf{End For}
\end{aligned}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;ä¼˜ç¼ºç‚¹åˆ†æ&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜ç‚¹&lt;/strong&gt;ï¼š
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç†è®ºä¿è¯&lt;/strong&gt;ï¼šå•è°ƒæå‡ï¼Œä¸å†æ‹…å¿ƒå­¦ä¹ ç‡å¤ªå¤§å¯¼è‡´è®­ç»ƒå´©æºƒã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ•°æ®æ•ˆç‡&lt;/strong&gt;ï¼šæ¯” REINFORCE é«˜ï¼Œå› ä¸ºåˆ©ç”¨äº†äºŒé˜¶ä¿¡æ¯ï¼ˆè‡ªç„¶æ¢¯åº¦ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç¼ºç‚¹&lt;/strong&gt;ï¼š
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;è®¡ç®—å¤æ‚&lt;/strong&gt;ï¼šCG å’Œ HVP å®ç°å¤æ‚ï¼Œä¸”è®¡ç®—é‡å¤§ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;çº¦æŸå¤ªç¡¬&lt;/strong&gt;ï¼šKL æ•£åº¦æ˜¯ç¡¬çº¦æŸï¼Œå¤„ç†èµ·æ¥ä¸å¤Ÿçµæ´»ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;ğŸ’¡ é¢„å‘Š&lt;/strong&gt;ï¼š
TRPO è™½ç„¶å¥½ï¼Œä½†å¤ªå¤æ‚äº†ã€‚æœ‰æ²¡æœ‰ä¸€ç§æ–¹æ³•ï¼Œæ—¢èƒ½ä¿ç•™ TRPO çš„â€œä¿¡ä»»åŒºåŸŸâ€æ€æƒ³ï¼ˆç¨³å®šï¼‰ï¼Œåˆèƒ½åƒ SGD ä¸€æ ·ç®€å•ï¼ˆä¸€é˜¶ä¼˜åŒ–ï¼‰ï¼Ÿ
è¿™å°±æ˜¯ &lt;strong&gt;PPO (Proximal Policy Optimization)&lt;/strong&gt; çš„ç”±æ¥ï¼ˆä¸‹ä¸€ç« å†…å®¹ï¼‰ã€‚&lt;/p&gt;
&lt;/blockquote&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-2.8vndvqvn7c.webp"/><enclosure url="https://pic.hana0721.top/rl-note-2.8vndvqvn7c.webp"/></item><item><title>RLç¬”è®°ï¼ˆ10ï¼‰ï¼šActor-Critic</title><link>https://claudiakim6827362.github.io/blog/rl-note-10</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/rl-note-10</guid><description>ç­–ç•¥æ¢¯åº¦ä¸ä»·å€¼å‡½æ•°çš„å®Œç¾ç»“åˆï¼šè¯¦è§£ Actor-Critic æ¶æ„ã€‚ä» Baseline å‡å°æ–¹å·®çš„æ•°å­¦è¯æ˜ï¼Œåˆ°ä¼˜åŠ¿å‡½æ•° (Advantage) çš„æ¨å¯¼åŠ A2C ç®—æ³•æµç¨‹ã€‚</description><pubDate>Fri, 19 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;å¼•è¨€ï¼ˆIntroductionï¼‰&lt;/h2&gt;
&lt;p&gt;åœ¨ä¹‹å‰çš„ç¬”è®°ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†ä¸¤ç§æˆªç„¶ä¸åŒçš„å¼ºåŒ–å­¦ä¹ è·¯å¾„ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Value-Based (å¦‚ Q-Learning)&lt;/strong&gt;ï¼šé€šè¿‡å­¦ä¹ ä»·å€¼å‡½æ•° $Q(s,a)$ æ¥é—´æ¥å¯¼å‡ºç­–ç•¥ã€‚ä¼˜ç‚¹æ˜¯æ–¹å·®å°ï¼ˆåˆ©ç”¨äº† TD çš„ä¸€æ­¥æ›´æ–°ï¼‰ï¼Œç¼ºç‚¹æ˜¯æ— æ³•å¤„ç†è¿ç»­åŠ¨ä½œã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Policy-Based (å¦‚ REINFORCE)&lt;/strong&gt;ï¼šç›´æ¥å­¦ä¹ ç­–ç•¥ $\pi_\theta$ã€‚ä¼˜ç‚¹æ˜¯å¯ä»¥å¤„ç†è¿ç»­åŠ¨ä½œï¼Œç¼ºç‚¹æ˜¯æ–¹å·®æå¤§ï¼ˆå› ä¸ºä½¿ç”¨äº†è’™ç‰¹å¡æ´›å›æŠ¥ $G_t$ï¼‰ï¼Œä¸”åªèƒ½åœ¨å›åˆç»“æŸåæ›´æ–°ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Actor-Critic (AC)&lt;/strong&gt; æ¶æ„æ—¨åœ¨ç»“åˆä¸¤è€…çš„ä¼˜ç‚¹ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Actor (æ¼”å‘˜)&lt;/strong&gt;ï¼šå³ç­–ç•¥ç½‘ç»œ $\pi_\theta(a|s)$ï¼Œè´Ÿè´£ç”±çŠ¶æ€è¾“å‡ºåŠ¨ä½œã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Critic (è¯„è®ºå®¶)&lt;/strong&gt;ï¼šå³ä»·å€¼ç½‘ç»œ $V_w(s)$ æˆ– $Q_w(s,a)$ï¼Œè´Ÿè´£è¯„ä¼° Actor çš„åŠ¨ä½œå¥½ä¸å¥½ï¼Œå¸®åŠ© Actor å‡å°æ–¹å·®åŠ é€Ÿå­¦ä¹ ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;é™ä½æ–¹å·®çš„æŠ€å·§ï¼šåŸºçº¿ (Baseline)&lt;/h2&gt;
&lt;p&gt;å›é¡¾ REINFORCE çš„æ¢¯åº¦å…¬å¼ï¼š
$$
\nabla_\theta J(\theta) = \mathbb{E}&lt;em&gt;{\tau \sim \pi&lt;/em&gt;\theta} \left[ \sum_{t=0}^T \nabla_\theta \log \pi_\theta(a_t|s_t) G_t \right]
$$
è¿™é‡Œçš„ $G_t$ æ˜¯ä» $t$ æ—¶åˆ»å¼€å§‹çš„ç´¯ç§¯å›æŠ¥ã€‚ç”±äºç¯å¢ƒéšæœºæ€§å’Œç­–ç•¥éšæœºæ€§ï¼Œ$G_t$ çš„æ³¢åŠ¨éå¸¸å¤§ï¼Œå¯¼è‡´æ¢¯åº¦ä¼°è®¡ä¸ç¨³å®šã€‚&lt;/p&gt;
&lt;p&gt;ä¸ºäº†å‡å°æ–¹å·®ï¼Œæˆ‘ä»¬å¼•å…¥ä¸€ä¸ª &lt;strong&gt;åŸºçº¿å‡½æ•° (Baseline) $b(s)$&lt;/strong&gt;ã€‚åŸºçº¿å‡½æ•°åªä¸çŠ¶æ€æœ‰å…³ï¼Œä¸åŠ¨ä½œæ— å…³ã€‚
æˆ‘ä»¬æŠŠæ¢¯åº¦ä¿®æ”¹ä¸ºï¼š
$$
\nabla_\theta J(\theta) = \mathbb{E} \left[ \sum_{t=0}^T \nabla_\theta \log \pi_\theta(a_t|s_t) (G_t - b(s_t)) \right]
$$&lt;/p&gt;
&lt;h3&gt;æ•°å­¦è¯æ˜ï¼šå¼•å…¥åŸºçº¿ä¸æ”¹å˜æ¢¯åº¦æœŸæœ›&lt;/h3&gt;
&lt;p&gt;æˆ‘ä»¬éœ€è¦è¯æ˜å‡å»ä¸€é¡¹ $b(s_t)$ åï¼Œæ¢¯åº¦çš„æœŸæœ›å€¼ä¸å˜ã€‚å³è¯æ˜ï¼š
$$
\mathbb{E}&lt;em&gt;{a_t \sim \pi&lt;/em&gt;\theta} [\nabla_\theta \log \pi_\theta(a_t|s_t) \cdot b(s_t)] = 0
$$&lt;/p&gt;
&lt;p&gt;è¯æ˜å¦‚ä¸‹ï¼š
$$
\begin{align}
\mathbb{E}&lt;em&gt;{a \sim \pi} [\nabla&lt;/em&gt;\theta \log \pi(a|s) \cdot b(s)]
&amp;#x26;= \sum_{a} \pi(a|s) \frac{\nabla_\theta \pi(a|s)}{\pi(a|s)} b(s) \notag \
&amp;#x26;= b(s) \sum_{a} \nabla_\theta \pi(a|s) \notag \
&amp;#x26;= b(s) \nabla_\theta \sum_{a} \pi(a|s) \notag \
&amp;#x26;= b(s) \nabla_\theta (1) \notag \
&amp;#x26;= 0 \notag
\end{align}
$$
ç»“è®ºï¼šåªè¦ $b(s)$ ä¸ä¾èµ–äºåŠ¨ä½œ $a$ï¼Œæˆ‘ä»¬å¯ä»¥éšæ„å‡å»å®ƒè€Œä¸æ”¹å˜æ¢¯åº¦çš„æ–¹å‘ï¼Œä½†èƒ½æ˜¾è‘—æ”¹å˜æ¢¯åº¦çš„æ–¹å·®ã€‚é€šå¸¸ï¼Œæˆ‘ä»¬é€‰æ‹©çŠ¶æ€ä»·å€¼å‡½æ•° $V(s)$ ä½œä¸ºåŸºçº¿ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;Actor-Critic æ¶æ„æ¼”å˜&lt;/h2&gt;
&lt;h3&gt;Q Actor-Critic&lt;/h3&gt;
&lt;p&gt;å¦‚æœæˆ‘ä»¬ç”¨ä¸€ä¸ªç¥ç»ç½‘ç»œ $Q_w(s,a)$ æ¥è¿‘ä¼¼ REINFORCE ä¸­çš„ $G_t$ï¼Œæ¢¯åº¦å˜ä¸ºï¼š
$$
\nabla_\theta J(\theta) \approx \mathbb{E} [\nabla_\theta \log \pi_\theta(a|s) Q_w(s,a)]
$$
ä½†è¿™å¹¶æ²¡æœ‰è§£å†³é—®é¢˜ï¼Œå› ä¸ºå•çº¯æ‹Ÿåˆ $Q$ å€¼è¿˜æ˜¯å¾ˆéš¾ã€‚&lt;/p&gt;
&lt;h3&gt;Advantage Actor-Critic (A2C)&lt;/h3&gt;
&lt;p&gt;ä¸ºäº†åˆ©ç”¨ Baseline å‡å°æ–¹å·®ï¼Œæˆ‘ä»¬å¸Œæœ›æ¢¯åº¦å½¢å¼ä¸ºï¼š
$$
\nabla_\theta J(\theta) \approx \mathbb{E} [\nabla_\theta \log \pi_\theta(a|s) (Q_w(s,a) - V_v(s))]
$$
å…¶ä¸­ $Q(s,a) - V(s)$ è¢«ç§°ä¸º &lt;strong&gt;ä¼˜åŠ¿å‡½æ•° (Advantage Function)&lt;/strong&gt;ï¼Œè®°ä¸º $A(s,a)$ã€‚å®ƒè¡¨ç¤ºâ€œåœ¨çŠ¶æ€ $s$ ä¸‹ï¼ŒåŠ¨ä½œ $a$ æ¯”å¹³å‡æƒ…å†µå¥½äº†å¤šå°‘â€ã€‚&lt;/p&gt;
&lt;p&gt;ä½†æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬éœ€è¦åŒæ—¶ç»´æŠ¤ä¸¤ä¸ªç½‘ç»œï¼ˆä¸€ä¸ªç®— $Q$ï¼Œä¸€ä¸ªç®— $V$ï¼‰ï¼Œè®­ç»ƒä¼šå¾ˆéº»çƒ¦ã€‚æˆ‘ä»¬å¯ä»¥åˆ©ç”¨ &lt;strong&gt;TD Error&lt;/strong&gt; æ¥è¿‘ä¼¼ä¼˜åŠ¿å‡½æ•°ã€‚&lt;/p&gt;
&lt;p&gt;æ ¹æ®è´å°”æ›¼æ–¹ç¨‹ï¼š
$$ Q(s_t, a_t) \approx r_t + \gamma V(s_{t+1}) $$
å› æ­¤ï¼Œä¼˜åŠ¿å‡½æ•°å¯ä»¥å†™ä¸ºï¼š
$$
\begin{align}
A(s_t, a_t) &amp;#x26;= Q(s_t, a_t) - V(s_t) \notag \
&amp;#x26;\approx r_t + \gamma V(s_{t+1}) - V(s_t) \notag
\end{align}
$$
è¿™æ°å¥½å°±æ˜¯ &lt;strong&gt;TD Error ($\delta_t$)&lt;/strong&gt;ï¼&lt;/p&gt;
&lt;p&gt;å› æ­¤ï¼Œæˆ‘ä»¬åªéœ€è¦ç»´æŠ¤ä¸€ä¸ª &lt;strong&gt;Actor ç½‘ç»œ $\pi_\theta(a|s)$&lt;/strong&gt; å’Œä¸€ä¸ª &lt;strong&gt;Critic ç½‘ç»œ $V_w(s)$&lt;/strong&gt; å³å¯ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;A2C ç®—æ³•æµç¨‹&lt;/h2&gt;
&lt;p&gt;åœ¨ Advantage Actor-Critic ä¸­ï¼ŒCritic çš„ä»»åŠ¡æ˜¯æŠŠ $V_w(s)$ ä¼°å¾—è¶Šå‡†è¶Šå¥½ï¼ŒActor çš„ä»»åŠ¡æ˜¯åˆ©ç”¨ Critic æä¾›çš„ TD Error æ¥æ›´æ–°ç­–ç•¥ã€‚&lt;/p&gt;
&lt;h3&gt;Critic çš„æ›´æ–° (Value Update)&lt;/h3&gt;
&lt;p&gt;Critic çš„ç›®æ ‡æ˜¯æœ€å°åŒ– TD Error çš„å¹³æ–¹ï¼ˆå³å›å½’é—®é¢˜ï¼‰ï¼š
$$
L_{critic}(w) = \frac{1}{2} \left( r_t + \gamma V_w(s_{t+1}) - V_w(s_t) \right)^2
$$
æ¢¯åº¦æ›´æ–°ï¼š
$$ w \leftarrow w + \alpha_c \delta_t \nabla_w V_w(s_t) $$&lt;/p&gt;
&lt;h3&gt;Actor çš„æ›´æ–° (Policy Update)&lt;/h3&gt;
&lt;p&gt;Actor ä½¿ç”¨ TD Error ä½œä¸ºä¼˜åŠ¿å‡½æ•°çš„ä¼°è®¡å€¼è¿›è¡Œæ¢¯åº¦ä¸Šå‡ï¼š
$$
\nabla_\theta J(\theta) \approx \nabla_\theta \log \pi_\theta(a_t|s_t) \delta_t
$$
æ¢¯åº¦æ›´æ–°ï¼š
$$ \theta \leftarrow \theta + \alpha_a \delta_t \nabla_\theta \log \pi_\theta(a_t|s_t) $$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;ğŸ’¡ ç›´è§‰ç†è§£&lt;/strong&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å¦‚æœ $\delta_t &gt; 0$ï¼ˆæƒŠå–œï¼Œç»“æœæ¯”é¢„æœŸå¥½ï¼‰ï¼šå¢åŠ åŠ¨ä½œ $a_t$ çš„æ¦‚ç‡ã€‚&lt;/li&gt;
&lt;li&gt;å¦‚æœ $\delta_t &amp;#x3C; 0$ï¼ˆå¤±æœ›ï¼Œç»“æœæ¯”é¢„æœŸå·®ï¼‰ï¼šå‡å°åŠ¨ä½œ $a_t$ çš„æ¦‚ç‡ã€‚&lt;/li&gt;
&lt;li&gt;è¿™é‡Œçš„â€œé¢„æœŸâ€å°±æ˜¯ Critic æä¾›çš„ $V(s_t)$ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h3&gt;A2C ä¼ªä»£ç &lt;/h3&gt;
&lt;p&gt;$$
\begin{aligned}
&amp;#x26; \bullet ; \text{Initialize Actor } \pi_\theta \text{ and Critic } V_w \
&amp;#x26; \bullet ; \textbf{For } \text{episode } = 1 \to E \textbf{ do}: \
&amp;#x26; \bullet \qquad \text{Initialize state } s \
&amp;#x26; \bullet \qquad \textbf{For } \text{step } t = 1 \to T \textbf{ do}: \
&amp;#x26; \bullet \qquad \qquad \text{Sample action } a \sim \pi_\theta(\cdot|s) \
&amp;#x26; \bullet \qquad \qquad \text{Execute } a, \text{ observe } r, s&apos; \
&amp;#x26; \bullet \qquad \qquad \textbf{// Calculate TD Error (Advantage)} \
&amp;#x26; \bullet \qquad \qquad \delta \leftarrow r + \gamma V_w(s&apos;) - V_w(s) \
&amp;#x26; \bullet \qquad \qquad \textbf{// Update Critic} \
&amp;#x26; \bullet \qquad \qquad w \leftarrow w + \alpha_c \delta \nabla_w V_w(s) \
&amp;#x26; \bullet \qquad \qquad \textbf{// Update Actor} \
&amp;#x26; \bullet \qquad \qquad \theta \leftarrow \theta + \alpha_a \delta \nabla_\theta \log \pi_\theta(a|s) \
&amp;#x26; \bullet \qquad \qquad s \leftarrow s&apos; \
&amp;#x26; \bullet \qquad \textbf{End For} \
&amp;#x26; \bullet ; \textbf{End For}
\end{aligned}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;åå·®ä¸æ–¹å·®çš„æƒè¡¡ (Bias-Variance Tradeoff)&lt;/h2&gt;
&lt;p&gt;æˆ‘ä»¬å¯ä»¥æ€»ç»“ä¸€ä¸‹ä¸åŒè®¡ç®— Advantage çš„æ–¹æ³•ï¼Œå®ƒä»¬ä½“ç°äº† RL ä¸­æ ¸å¿ƒçš„æƒè¡¡ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;è’™ç‰¹å¡æ´› (REINFORCE)&lt;/strong&gt;ï¼š
&lt;ul&gt;
&lt;li&gt;$A_t \approx G_t - V(s_t)$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ— åå·®&lt;/strong&gt;ï¼š$G_t$ æ˜¯çœŸå®å›æŠ¥ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;é«˜æ–¹å·®&lt;/strong&gt;ï¼šå—æ•´ä¸ªåºåˆ—éšæœºæ€§å½±å“ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Actor-Critic (TD)&lt;/strong&gt;ï¼š
&lt;ul&gt;
&lt;li&gt;$A_t \approx r_t + \gamma V(s_{t+1}) - V(s_t)$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä½æ–¹å·®&lt;/strong&gt;ï¼šåªå—ä¸€æ­¥éšæœºæ€§å½±å“ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æœ‰åå·®&lt;/strong&gt;ï¼šä¾èµ–äº Critic çš„ä¼°è®¡ $V(s_{t+1})$ï¼Œå¦‚æœ Critic è¿˜æ²¡ç»ƒå¥½ï¼ŒActor å°±ä¼šè¢«å¸¦åã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ä¸ºäº†å¹³è¡¡ä¸¤è€…ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ &lt;strong&gt;å¤šæ­¥ TD&lt;/strong&gt; æˆ–è€… &lt;strong&gt;GAE (Generalized Advantage Estimation)&lt;/strong&gt;ï¼Œè¿™æ˜¯ PPO ç­‰è¿›é˜¶ç®—æ³•çš„æ ¸å¿ƒæŠ€å·§ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;æ€»ç»“&lt;/h2&gt;
&lt;p&gt;Actor-Critic æ¶æ„æ˜¯ç°ä»£æ·±åº¦å¼ºåŒ–å­¦ä¹ çš„ä¸»æµæ¶æ„ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å®ƒè§£å†³äº† REINFORCE æ–¹å·®å¤§ã€æ›´æ–°æ…¢çš„é—®é¢˜ã€‚&lt;/li&gt;
&lt;li&gt;å®ƒè§£å†³äº† DQN æ— æ³•å¤„ç†è¿ç»­åŠ¨ä½œçš„é—®é¢˜ã€‚&lt;/li&gt;
&lt;li&gt;å®ƒæ˜¯åç»­ &lt;strong&gt;A3C, DDPG, TRPO, PPO, SAC&lt;/strong&gt; ç­‰é«˜çº§ç®—æ³•çš„å…±åŒç¥–å…ˆã€‚&lt;/li&gt;
&lt;/ul&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-2.8vndvqvn7c.webp"/><enclosure url="https://pic.hana0721.top/rl-note-2.8vndvqvn7c.webp"/></item><item><title>RLç¬”è®°ï¼ˆ9ï¼‰ï¼šREINFORCE</title><link>https://claudiakim6827362.github.io/blog/rl-note-9</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/rl-note-9</guid><description>ä»ä»·å€¼åˆ°ç­–ç•¥ï¼šè¯¦è§£ç­–ç•¥æ¢¯åº¦ (Policy Gradient) å®šç†çš„å®Œæ•´æ•°å­¦æ¨å¯¼ï¼Œå¹¶ä»‹ç»æœ€åŸºç¡€çš„ç­–ç•¥æ¢¯åº¦ç®—æ³•â€”â€”REINFORCEã€‚</description><pubDate>Thu, 18 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;å¼•è¨€ï¼ˆIntroductionï¼‰&lt;/h2&gt;
&lt;p&gt;åœ¨ä¹‹å‰çš„ DQN ç­‰ç®—æ³•ä¸­ï¼Œæˆ‘ä»¬éƒ½æ˜¯å…ˆå­¦ä¹ ä»·å€¼å‡½æ•° $Q(s,a)$ï¼Œå†æ ¹æ®ä»·å€¼å‡½æ•°æ¨å¯¼å‡ºç­–ç•¥ï¼ˆä¾‹å¦‚ $\epsilon$-Greedyï¼‰ã€‚è¿™ç±»æ–¹æ³•ç§°ä¸º &lt;strong&gt;Value-Based&lt;/strong&gt; æ–¹æ³•ã€‚&lt;/p&gt;
&lt;p&gt;ä½†è¿™ç±»æ–¹æ³•æœ‰ä¸€äº›å±€é™ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;æ— æ³•å¤„ç†è¿ç»­åŠ¨ä½œç©ºé—´&lt;/strong&gt;ï¼šåœ¨è¿ç»­åŠ¨ä½œä¸­æ‰¾ $\max_a Q(s,a)$ éå¸¸å›°éš¾ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ— æ³•å­¦ä¹ éšæœºç­–ç•¥&lt;/strong&gt;ï¼šDQN æœ€ç»ˆå­¦åˆ°çš„æ˜¯ç¡®å®šæ€§ç­–ç•¥ï¼Œä½†åœ¨æŸäº›åšå¼ˆåœºæ™¯ï¼ˆå¦‚å‰ªåˆ€çŸ³å¤´å¸ƒï¼‰ï¼Œéšæœºç­–ç•¥æ‰æ˜¯æœ€ä¼˜çš„ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;å› æ­¤ï¼Œæˆ‘ä»¬å¼•å…¥ &lt;strong&gt;Policy-Based&lt;/strong&gt; æ–¹æ³•ï¼šç›´æ¥å‚æ•°åŒ–ç­–ç•¥ $\pi_\theta(a|s)$ï¼Œé€šè¿‡è°ƒæ•´å‚æ•° $\theta$ æ¥æœ€å¤§åŒ–æœŸæœ›å›æŠ¥ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;ç­–ç•¥çš„è¡¨ç¤º&lt;/h2&gt;
&lt;p&gt;æˆ‘ä»¬éœ€è¦ç”¨ä¸€ä¸ªå‡½æ•°ï¼ˆé€šå¸¸æ˜¯ç¥ç»ç½‘ç»œï¼‰æ¥è¡¨ç¤ºç­–ç•¥ã€‚&lt;/p&gt;
&lt;h3&gt;éšæœºç­–ç•¥ (Stochastic Policy)&lt;/h3&gt;
&lt;p&gt;è¾“å…¥çŠ¶æ€ $s$ï¼Œè¾“å‡ºåŠ¨ä½œçš„æ¦‚ç‡åˆ†å¸ƒã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç¦»æ•£åŠ¨ä½œ&lt;/strong&gt;ï¼ˆå¦‚ Softmaxï¼‰ï¼š
$$ \pi(a|s;\theta)=\frac{\exp(Q_\theta(s,a))}{\sum_{a^\prime}\exp(Q_\theta(s,a^\prime))} $$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è¿ç»­åŠ¨ä½œ&lt;/strong&gt;ï¼ˆå¦‚é«˜æ–¯åˆ†å¸ƒï¼‰ï¼š
$$ \pi(a|s;\theta) = \frac{1}{\sqrt{2\pi}\sigma} \exp\left(-\frac{(a-\mu_\theta(s))^2}{2\sigma^2}\right) $$
é€šå¸¸ç½‘ç»œè¾“å‡ºå‡å€¼ $\mu_\theta(s)$ å’Œæ ‡å‡†å·® $\sigma_\theta(s)$ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;ç¡®å®šæ€§ç­–ç•¥ (Deterministic Policy)&lt;/h3&gt;
&lt;p&gt;è¾“å…¥çŠ¶æ€ $s$ï¼Œç›´æ¥è¾“å‡ºåŠ¨ä½œå€¼ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç¦»æ•£åŠ¨ä½œ&lt;/strong&gt;ï¼š$$ a=\operatorname{argmax}&lt;em&gt;{a} Q&lt;/em&gt;\theta(s,a) $$ ï¼ˆä¸å¯å¾®ï¼Œæ— æ³•ç›´æ¥ç”¨æ¢¯åº¦ä¸‹é™ï¼‰&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è¿ç»­åŠ¨ä½œ&lt;/strong&gt;ï¼š$$ a=\mu_\theta(s) $$ ï¼ˆå¯å¾®ï¼Œç”¨äº DDPG ç­‰ç®—æ³•ï¼‰&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;ç­–ç•¥æ¢¯åº¦å®šç† (Policy Gradient Theorem)&lt;/h2&gt;
&lt;p&gt;è¿™æ˜¯ Policy-Based æ–¹æ³•çš„åŸºçŸ³ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æœ€å¤§åŒ–æœŸæœ›å›æŠ¥ $J(\theta)$ï¼Œé€šè¿‡è®¡ç®—æ¢¯åº¦ $\nabla_\theta J(\theta)$ æ¥æ›´æ–°å‚æ•°ã€‚&lt;/p&gt;
&lt;h3&gt;ç›®æ ‡å‡½æ•°&lt;/h3&gt;
&lt;p&gt;$$
J(\theta) = \mathbb{E}&lt;em&gt;{s_0}[V^{\pi&lt;/em&gt;\theta}(s_0)]
$$
å…¶ä¸­ $s_0$ æ˜¯åˆå§‹çŠ¶æ€ã€‚&lt;/p&gt;
&lt;h3&gt;æ¢¯åº¦æ¨å¯¼ (The &quot;Hard&quot; Part)&lt;/h3&gt;
&lt;p&gt;æˆ‘ä»¬éœ€è¦è®¡ç®— $\nabla_\theta V^{\pi_\theta}(s)$ã€‚æ ¹æ®è´å°”æ›¼æ–¹ç¨‹å±•å¼€ï¼š&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\nabla_\theta V^{\pi_\theta}(s)
&amp;#x26;= \nabla_\theta \sum_{a\in \mathcal{A}} \pi_\theta (a|s) Q^{\pi_\theta}(s,a) \notag \
&amp;#x26;= \sum_{a\in\mathcal{A}}\left[\nabla_\theta \pi_\theta (a|s) Q^{\pi_\theta}(s,a) +\pi_\theta (a|s) \nabla_\theta Q^{\pi_\theta}(s,a) \right] \notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;è¿™é‡Œçš„éš¾ç‚¹åœ¨äº $\nabla_\theta Q^{\pi_\theta}(s,a)$ï¼Œå› ä¸º $Q$ å€¼æœ¬èº«ä¹Ÿä¾èµ–äºç­–ç•¥å‚æ•° $\theta$ï¼ˆæœªæ¥çš„åŠ¨ä½œä¼šå˜ï¼‰ã€‚æˆ‘ä»¬ç»§ç»­å±•å¼€ $Q$ï¼š
$$
\begin{align}
\nabla_\theta Q^{\pi_\theta}(s,a) &amp;#x26;= \nabla_\theta \sum_{r,s^\prime} P(s^\prime, r| s, a) (r + \gamma V^{\pi_\theta}(s^\prime)) \notag \
&amp;#x26;= \sum_{s^\prime} P(s^\prime| s, a) \gamma \nabla_\theta V^{\pi_\theta}(s^\prime) \notag
\end{align}
$$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;æ³¨æ„ï¼šç¯å¢ƒçš„åŠ¨åŠ›å­¦ $P$ å’Œå¥–åŠ± $r$ ä¸ $\theta$ æ— å…³ï¼Œæ‰€ä»¥å¯¼æ•°ä¸º 0ã€‚&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;ä»£å›åŸå¼ï¼Œå¾—é€’å½’å½¢å¼ï¼š
$$
\begin{align}
\nabla_\theta V^{\pi_\theta}(s)
&amp;#x26;= \underbrace{\sum_{a\in\mathcal{A}}\nabla_\theta\pi_\theta(a|s) Q^{\pi_\theta}(s,a)}&lt;em&gt;{\phi(s)} + \gamma \sum&lt;/em&gt;{a\in\mathcal{A}}\pi_\theta (a|s) \sum_{s^\prime \in \mathcal{S}} P(s^\prime| s, a) \nabla_\theta V^{\pi_\theta}(s^\prime) \notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;å®šä¹‰è½¬ç§»æ¦‚ç‡ $d^{\pi_\theta}(s \to s&apos;, k)$ ä¸ºç­–ç•¥ $\pi_\theta$ ä» $s$ å‡ºå‘èµ° $k$ æ­¥åˆ°è¾¾ $s&apos;$ çš„æ¦‚ç‡ã€‚åå¤è¿­ä»£ä¸Šè¿°é€’å½’å¼ï¼š
$$
\begin{align}
\nabla_\theta V^{\pi_\theta}(s)
&amp;#x26;= \phi(s) + \gamma \sum_{s&apos;} d(s \to s&apos;, 1) \nabla_\theta V(s&apos;) \notag \
&amp;#x26;= \phi(s) + \gamma \sum_{s&apos;} d(s \to s&apos;, 1) [\phi(s&apos;) + \gamma \sum_{s&apos;&apos;} d(s&apos; \to s&apos;&apos;, 1) \nabla_\theta V(s&apos;&apos;)] \notag \
&amp;#x26;= \dots \notag \
&amp;#x26;= \sum_{x \in \mathcal{S}} \sum_{k=0}^\infty \gamma^k d^{\pi_\theta}(s \to x, k) \phi(x) \notag
\end{align}
$$&lt;/p&gt;
&lt;h3&gt;å¼•å…¥çŠ¶æ€è®¿é—®åˆ†å¸ƒ&lt;/h3&gt;
&lt;p&gt;å›åˆ°æ€»ç›®æ ‡å‡½æ•° $J(\theta)$ çš„æ¢¯åº¦ï¼š
$$
\begin{align}
\nabla_\theta J(\theta) &amp;#x26;= \mathbb{E}&lt;em&gt;{s_0} [\nabla&lt;/em&gt;\theta V^{\pi_\theta}(s_0)] \notag \
&amp;#x26;= \sum_{s \in \mathcal{S}} \left( \sum_{k=0}^\infty \gamma^k d^{\pi_\theta}(s_0 \to s, k) \right) \phi(s) \notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;åˆ©ç”¨çŠ¶æ€è®¿é—®åˆ†å¸ƒ $\nu^{\pi_\theta}(s)$ çš„å®šä¹‰ï¼š
$$ \sum_{k=0}^\infty \gamma^k d^{\pi_\theta}(s_0 \to s, k) \propto \nu^{\pi_\theta}(s) $$&lt;/p&gt;
&lt;p&gt;æˆ‘ä»¬å¾—åˆ°äº†æå…¶ä¼˜é›…çš„ &lt;strong&gt;ç­–ç•¥æ¢¯åº¦å®šç†&lt;/strong&gt;ï¼š
$$
\begin{align}
\nabla_\theta J(\theta)
&amp;#x26;\propto \sum_{s \in \mathcal{S}} \nu^{\pi_\theta}(s) \phi(s) \notag \
&amp;#x26;= \sum_{s \in \mathcal{S}} \nu^{\pi_\theta}(s) \sum_{a \in \mathcal{A}} \nabla_\theta \pi_\theta(a|s) Q^{\pi_\theta}(s,a) \notag
\end{align}
$$&lt;/p&gt;
&lt;h3&gt;å¯¹æ•°å¯¼æ•°æŠ€å·§ (Log-Derivative Trick)&lt;/h3&gt;
&lt;p&gt;ä¸ºäº†èƒ½åœ¨é‡‡æ ·ä¸­è®¡ç®—ï¼Œæˆ‘ä»¬åˆ©ç”¨æ’ç­‰å¼ $\nabla \pi = \pi \frac{\nabla \pi}{\pi} = \pi \nabla \log \pi$ï¼š
$$
\begin{align}
\nabla_\theta J(\theta)
&amp;#x26;= \mathbb{E}&lt;em&gt;{s \sim \nu^{\pi&lt;/em&gt;\theta}} \left[ \sum_{a \in \mathcal{A}} \pi_\theta(a|s) \nabla_\theta \log \pi_\theta(a|s) Q^{\pi_\theta}(s,a) \right] \notag \
&amp;#x26;= \mathbb{E}&lt;em&gt;{\pi&lt;/em&gt;\theta} [\nabla_\theta \log \pi_\theta(a|s) Q^{\pi_\theta}(s,a)] \notag
\end{align}
$$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;æ ¸å¿ƒç»“è®º&lt;/strong&gt;ï¼šæˆ‘ä»¬ä¸éœ€è¦çŸ¥é“ç¯å¢ƒçš„çŠ¶æ€è½¬ç§» $P$ï¼Œä¹Ÿä¸éœ€è¦å¯¹çŠ¶æ€åˆ†å¸ƒ $\nu(s)$ æ±‚å¯¼ã€‚åªè¦è®©æ™ºèƒ½ä½“åœ¨ç¯å¢ƒé‡Œç©ï¼Œæ”¶é›†æ•°æ®ï¼Œå°±å¯ä»¥è®¡ç®—æ¢¯åº¦ï¼&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2&gt;REINFORCE ç®—æ³•&lt;/h2&gt;
&lt;p&gt;REINFORCE æ˜¯æœ€åŸºç¡€çš„ç­–ç•¥æ¢¯åº¦ç®—æ³•ï¼Œå®ƒä½¿ç”¨ &lt;strong&gt;è’™ç‰¹å¡æ´›æ–¹æ³• (Monte-Carlo)&lt;/strong&gt; æ¥ä¼°è®¡ $Q^{\pi_\theta}(s,a)$ã€‚&lt;/p&gt;
&lt;p&gt;å¯¹äºä¸€æ¡å®Œæ•´çš„è½¨è¿¹ $\tau = {s_1, a_1, r_1, \dots, s_T, a_T, r_T}$ï¼Œæ—¶åˆ» $t$ çš„çœŸå®å›æŠ¥ $G_t$ æ˜¯ $Q(s_t, a_t)$ çš„æ— åä¼°è®¡ï¼š
$$ Q^{\pi_\theta}(s_t, a_t) \approx G_t = \sum_{k=t}^T \gamma^{k-t} r_k $$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;å‚æ•°æ›´æ–°å…¬å¼&lt;/strong&gt;ï¼š
$$ \theta \leftarrow \theta + \alpha \gamma^t G_t \nabla_\theta \log \pi_\theta(a_t|s_t) $$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ç›´è§‰&lt;/strong&gt;ï¼šå¦‚æœæŸä¸ªåŠ¨ä½œ $a_t$ å¸¦æ¥äº†é«˜å›æŠ¥ $G_t$ï¼Œæˆ‘ä»¬å°±å¢åŠ å®ƒçš„æ¦‚ç‡ï¼ˆ$\nabla \log \pi$ æ–¹å‘ï¼‰ï¼›å¦‚æœå›æŠ¥ä½ï¼ˆç”šè‡³æ˜¯è´Ÿçš„ï¼‰ï¼Œå°±å‡å°‘å®ƒçš„æ¦‚ç‡ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;ç®—æ³•ä¼ªä»£ç &lt;/h3&gt;
&lt;p&gt;$$
\begin{aligned}
&amp;#x26; \bullet ; \text{Initialize policy parameters } \theta \
&amp;#x26; \bullet ; \textbf{For } \text{episode } e = 1 \to E \textbf{ do}: \
&amp;#x26; \bullet \qquad \text{Generate trajectory } \tau = {s_1, a_1, r_1, \dots, s_T, a_T, r_T} \sim \pi_\theta \
&amp;#x26; \bullet \qquad \textbf{For } t = 1 \to T \textbf{ do}: \
&amp;#x26; \bullet \qquad \qquad G_t \leftarrow \sum_{k=t}^T \gamma^{k-t} r_k \
&amp;#x26; \bullet \qquad \qquad \theta \leftarrow \theta + \alpha \gamma^t G_t \nabla_\theta \log \pi_\theta(a_t|s_t) \
&amp;#x26; \bullet \qquad \textbf{End For} \
&amp;#x26; \bullet ; \textbf{End For}
\end{aligned}
$$&lt;/p&gt;
&lt;h3&gt;ä¼˜ç¼ºç‚¹åˆ†æ&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜ç‚¹&lt;/strong&gt;ï¼šå¯ä»¥ç›´æ¥å¤„ç†è¿ç»­åŠ¨ä½œï¼›å­¦ä¹ åˆ°çš„éšæœºç­–ç•¥å¯ä»¥æ¢ç´¢ï¼›æ•°å­¦æ¨å¯¼ä¼˜ç¾ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç¼ºç‚¹&lt;/strong&gt;ï¼š
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;æ–¹å·®æå¤§&lt;/strong&gt;ï¼šä¸€å±€æ¸¸æˆçš„ç»“æœéšæœºæ€§å¾ˆå¤§ï¼Œå¯¼è‡´æ¢¯åº¦ä¼°è®¡ä¸ç¨³å®šã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;On-Policy&lt;/strong&gt;ï¼šå¿…é¡»é‡‡é›†ä¸€æ¡æ•°æ®å°±æ›´æ–°ä¸€æ¬¡ï¼Œæ—§æ•°æ®æ— æ³•é‡å¤åˆ©ç”¨ï¼Œæ•ˆç‡ä½ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å›åˆæ›´æ–°&lt;/strong&gt;ï¼šå¿…é¡»ç­‰åˆ°æ¸¸æˆç»“æŸæ‰èƒ½è®¡ç®— $G_t$ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;ğŸ’¡ æ€è€ƒ&lt;/strong&gt;ï¼šä¸ºäº†å‡å°æ–¹å·®ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šå‡å»ä¸€ä¸ª &lt;strong&gt;åŸºçº¿ (Baseline)&lt;/strong&gt; $b(s)$ï¼Œæ¯”å¦‚çŠ¶æ€ä»·å€¼ $V(s)$ã€‚è¿™ä¸ä¼šæ”¹å˜æ¢¯åº¦çš„æœŸæœ›ï¼Œä½†èƒ½æ˜¾è‘—é™ä½æ–¹å·®ã€‚è¿™å°±æ˜¯ &lt;strong&gt;Actor-Critic&lt;/strong&gt; ç®—æ³•çš„é›å½¢ï¼ˆä¸‹ä¸€ç« å†…å®¹ï¼‰ã€‚&lt;/p&gt;
&lt;/blockquote&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-2.8vndvqvn7c.webp"/><enclosure url="https://pic.hana0721.top/rl-note-2.8vndvqvn7c.webp"/></item><item><title>RLç¬”è®°ï¼ˆ8ï¼‰ï¼šDQN</title><link>https://claudiakim6827362.github.io/blog/rl-note-8</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/rl-note-8</guid><description>æ·±åº¦å¼ºåŒ–å­¦ä¹ çš„å¼€å±±ä¹‹ä½œã€‚è¯¦è§£ DQN å¦‚ä½•åˆ©ç”¨ç¥ç»ç½‘ç»œæ‹Ÿåˆ Q å€¼ï¼Œä»¥åŠä¸¤å¤§æ ¸å¿ƒåˆ›æ–°ï¼šç»éªŒå›æ”¾ä¸ç›®æ ‡ç½‘ç»œã€‚è¿›é˜¶æ¶µç›– Double DQN ä¸ Dueling DQNã€‚</description><pubDate>Wed, 17 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;å¼•è¨€ï¼ˆIntroductionï¼‰&lt;/h2&gt;
&lt;p&gt;åœ¨ä¹‹å‰çš„ Q-Learning ç®—æ³•ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªçŸ©é˜µï¼ˆQ-Tableï¼‰æ¥è®°å½•æ¯ä¸ªçŠ¶æ€åŠ¨ä½œå¯¹ $(s,a)$ çš„ä»·å€¼ã€‚
è¿™ç§æ–¹æ³•æœ‰ä¸¤ä¸ªè‡´å‘½å±€é™ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;å†…å­˜é™åˆ¶&lt;/strong&gt;ï¼šå¦‚æœçŠ¶æ€ç©ºé—´å¾ˆå¤§ï¼ˆä¾‹å¦‚å›´æ£‹ $10^{170}$ï¼‰ï¼Œè¡¨æ ¼æ ¹æœ¬å­˜ä¸ä¸‹ã€‚è¿™è¢«ç§°ä¸º&lt;strong&gt;ç»´åº¦ç¾éš¾ (Curse of Dimensionality)&lt;/strong&gt;ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ³›åŒ–èƒ½åŠ›å·®&lt;/strong&gt;ï¼šå¯¹äºæ²¡è§è¿‡çš„çŠ¶æ€ï¼Œè¡¨æ ¼æ— æ³•ç»™å‡ºä¼°è®¡ï¼Œè€Œåœ¨è¿ç»­çŠ¶æ€ç©ºé—´ä¸­ï¼Œå‡ ä¹å¾ˆéš¾é‡åˆ°å®Œå…¨ä¸€æ ·çš„çŠ¶æ€ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥&lt;strong&gt;å‡½æ•°æ‹Ÿåˆ (Function Approximation)&lt;/strong&gt;ã€‚&lt;strong&gt;æ·±åº¦Qç½‘ç»œ (Deep Q-Network, DQN)&lt;/strong&gt; ä½¿ç”¨ä¸€ä¸ªç¥ç»ç½‘ç»œ $Q_\omega(s, a)$ æ¥è¿‘ä¼¼ $Q^*(s, a)$ï¼Œè¾“å…¥çŠ¶æ€ $s$ï¼Œè¾“å‡ºæ‰€æœ‰ç¦»æ•£åŠ¨ä½œçš„ Q å€¼ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;æ·±åº¦ Q ç½‘ç»œ (DQN)&lt;/h2&gt;
&lt;h3&gt;æ ¸å¿ƒå®šä¹‰&lt;/h3&gt;
&lt;p&gt;åœ¨ DQN ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨å‚æ•°ä¸º $\omega$ çš„ç¥ç»ç½‘ç»œæ¥æ‹ŸåˆåŠ¨ä½œä»·å€¼å‡½æ•°ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;è¾“å…¥&lt;/strong&gt;ï¼šçŠ¶æ€ $s$ï¼ˆä¾‹å¦‚æ¸¸æˆçš„å±å¹•åƒç´ ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è¾“å‡º&lt;/strong&gt;ï¼šæ¯ä¸ªåŠ¨ä½œ $a \in \mathcal{A}$ å¯¹åº”çš„ä»·å€¼ $Q(s,a)$ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;æŸå¤±å‡½æ•°&lt;/h3&gt;
&lt;p&gt;ç±»ä¼¼äº Q-Learningï¼Œæˆ‘ä»¬å¸Œæœ›ç¥ç»ç½‘ç»œçš„è¾“å‡ºé€¼è¿‘ TD Targetã€‚
å¯¹äºä¸€æ¡æ•°æ® $(s_i, a_i, r_i, s_i^\prime)$ï¼Œç›®æ ‡æ˜¯æœ€å°åŒ–å‡æ–¹è¯¯å·®ï¼š&lt;/p&gt;
&lt;p&gt;$$
J(\omega)=\frac{1}{2N}\sum_{i=1}^{N}\left[ \underbrace{Q_\omega(s_i,a_i)}&lt;em&gt;{\text{é¢„æµ‹å€¼}} - \underbrace{\left(r_i+\gamma \max&lt;/em&gt;{a^\prime}Q_\omega(s_i^\prime,a^\prime)\right)}_{\text{TD Target}} \right]^2
$$&lt;/p&gt;
&lt;p&gt;ç„¶è€Œï¼Œç›´æ¥è¿™æ ·è®­ç»ƒæ˜¯ä¸ç¨³å®šçš„ã€‚DQN å¼•å…¥äº†ä¸¤å¤§â€œæ³•å®â€æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;åˆ›æ–°ä¸€ï¼šç»éªŒå›æ”¾ (Experience Replay)&lt;/h2&gt;
&lt;p&gt;åœ¨ä¸€èˆ¬çš„ç›‘ç£å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬å‡è®¾è®­ç»ƒæ•°æ®æ˜¯&lt;strong&gt;ç‹¬ç«‹åŒåˆ†å¸ƒ (i.i.d)&lt;/strong&gt; çš„ã€‚ä½†åœ¨å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œæ™ºèƒ½ä½“é‡‡é›†çš„æ•°æ®æ˜¯åºåˆ—ç›¸å…³çš„ï¼ˆç°åœ¨çš„çŠ¶æ€ä¾èµ–äºä¸Šä¸€ç§’çš„çŠ¶æ€ï¼‰ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;åšæ³•&lt;/strong&gt;ï¼š
ç»´æŠ¤ä¸€ä¸ª&lt;strong&gt;å›æ”¾ç¼“å†²åŒº (Replay Buffer)&lt;/strong&gt; $\mathcal{R}$ã€‚&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;æ™ºèƒ½ä½“ä¸ç¯å¢ƒäº¤äº’ï¼Œå°†äº§ç”Ÿçš„æ•°æ® $(s_t, a_t, r_t, s_{t+1})$ å­˜å…¥ç¼“å†²åŒºã€‚&lt;/li&gt;
&lt;li&gt;è®­ç»ƒæ—¶ï¼Œä»ç¼“å†²åŒºä¸­&lt;strong&gt;éšæœºé‡‡æ ·&lt;/strong&gt;ä¸€ä¸ªæ‰¹æ¬¡ (Batch) çš„æ•°æ®è¿›è¡Œæ¢¯åº¦ä¸‹é™ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;ä½œç”¨&lt;/strong&gt;ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;æ‰“ç ´ç›¸å…³æ€§&lt;/strong&gt;ï¼šéšæœºé‡‡æ ·æ¶ˆé™¤äº†æ•°æ®ä¹‹é—´çš„æ—¶é—´ç›¸å…³æ€§ï¼Œæ»¡è¶³ç‹¬ç«‹åŒåˆ†å¸ƒå‡è®¾ï¼Œç¨³å®šç½‘ç»œè®­ç»ƒã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æé«˜æ ·æœ¬æ•ˆç‡&lt;/strong&gt;ï¼šä¸€æ¡ç»éªŒæ•°æ®å¯ä»¥è¢«å¤šæ¬¡é‡‡æ ·åˆ©ç”¨ï¼Œè€Œä¸æ˜¯ç”¨å®Œå³å¼ƒã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2&gt;åˆ›æ–°äºŒï¼šç›®æ ‡ç½‘ç»œ (Target Network)&lt;/h2&gt;
&lt;p&gt;åœ¨åŸç‰ˆ Q-Learning ä¸­ï¼ŒTD Target çš„è®¡ç®—ä¹Ÿä¾èµ–äºå½“å‰ç½‘ç»œå‚æ•° $\omega$ï¼š
$$
y_i = r_i + \gamma \max_{a&apos;} Q_\omega(s&apos;_i, a&apos;)
$$
è¿™å°±å¥½æ¯”â€œåœ¨å°„ç®­çš„åŒæ—¶ï¼Œé¶å­ä¹Ÿåœ¨åŠ¨â€ã€‚æ›´æ–° $\omega$ ä¼šåŒæ—¶æ”¹å˜é¢„æµ‹å€¼å’Œç›®æ ‡å€¼ï¼Œå®¹æ˜“å¯¼è‡´éœ‡è¡å‘æ•£ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;åšæ³•&lt;/strong&gt;ï¼š
å¼•å…¥ä¸€ä¸ªç»“æ„ç›¸åŒä½†å‚æ•°ç‹¬ç«‹çš„&lt;strong&gt;ç›®æ ‡ç½‘ç»œ (Target Network)&lt;/strong&gt;ï¼Œå‚æ•°è®°ä¸º $\omega^-$ã€‚
è®¡ç®—ç›®æ ‡å€¼æ—¶ä½¿ç”¨ $\omega^-$ï¼Œæ›´æ–°ç½‘ç»œæ—¶ä¼˜åŒ– $\omega$ã€‚&lt;/p&gt;
&lt;p&gt;$$
y_i = r_i + \gamma \max_{a&apos;} Q_{\omega^-}(s&apos;_i, a&apos;)
$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;æ›´æ–°è§„åˆ™&lt;/strong&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;è®­ç»ƒç½‘ç»œ $\omega$&lt;/strong&gt;ï¼šæ¯ä¸ª step éƒ½è¿›è¡Œæ¢¯åº¦ä¸‹é™æ›´æ–°ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç›®æ ‡ç½‘ç»œ $\omega^-$&lt;/strong&gt;ï¼šæ¯éš” $C$ æ­¥ï¼ˆä¾‹å¦‚ 1000 æ­¥ï¼‰ï¼Œå°† $\omega$ çš„å€¼å¤åˆ¶ç»™ $\omega^-$ ($\omega^- \leftarrow \omega$)ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;ğŸ’¡ ç›´è§‰&lt;/strong&gt;ï¼šå›ºå®šä½é¶å­ä¸€ä¼šå„¿ï¼Œè®©å°„æ‰‹ï¼ˆè®­ç»ƒç½‘ç»œï¼‰å®‰å¿ƒç„å‡†ï¼Œç­‰å°„æ‰‹ç»ƒå¥½äº†ï¼Œå†æŠŠé¶å­æŒªåˆ°æ–°çš„ä½ç½®ã€‚&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2&gt;DQN ç®—æ³•ä¼ªä»£ç &lt;/h2&gt;
&lt;p&gt;$$
\begin{aligned}
&amp;#x26; \bullet ; \text{Initialize main network } Q_\omega \text{ and target network } Q_{\omega^-} \text{ with weights } \omega \
&amp;#x26; \bullet ; \text{Initialize replay buffer } \mathcal{R} \
&amp;#x26; \bullet ; \textbf{For } \text{episode } e = 1 \to E \textbf{ do}: \
&amp;#x26; \bullet \qquad \text{Initialize state } s \
&amp;#x26; \bullet \qquad \textbf{For } \text{step } t = 1 \to T \textbf{ do}: \
&amp;#x26; \bullet \qquad \qquad \text{Select action } a \text{ using } \epsilon\text{-greedy based on } Q_\omega(s) \
&amp;#x26; \bullet \qquad \qquad \text{Execute } a, \text{ observe } r, s&apos; \
&amp;#x26; \bullet \qquad \qquad \text{Store transition } (s, a, r, s&apos;) \text{ in } \mathcal{R} \
&amp;#x26; \bullet \qquad \qquad \textbf{If } |\mathcal{R}| &gt; \text{batch_size}: \
&amp;#x26; \bullet \qquad \qquad \qquad \text{Sample batch } {(s_i, a_i, r_i, s&apos;&lt;em&gt;i)}&lt;/em&gt;{i=1}^N \text{ from } \mathcal{R} \
&amp;#x26; \bullet \qquad \qquad \qquad \text{Calculate targets: } y_i = r_i + \gamma \max_{a&apos;} Q_{\omega^-}(s&apos;&lt;em&gt;i, a&apos;) \
&amp;#x26; \bullet \qquad \qquad \qquad \text{Update } \omega \text{ by minimizing } \frac{1}{N}\sum (Q&lt;/em&gt;\omega(s_i, a_i) - y_i)^2 \
&amp;#x26; \bullet \qquad \qquad \qquad \textbf{Every } C \text{ steps: } \omega^- \leftarrow \omega \
&amp;#x26; \bullet \qquad \qquad s \leftarrow s&apos; \
&amp;#x26; \bullet \qquad \textbf{End For} \
&amp;#x26; \bullet ; \textbf{End For}
\end{aligned}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;è¿›é˜¶ 1ï¼šDouble DQN&lt;/h2&gt;
&lt;h3&gt;é—®é¢˜ï¼šè¿‡é«˜ä¼°è®¡ (Overestimation)&lt;/h3&gt;
&lt;p&gt;DQN åœ¨è®¡ç®—ç›®æ ‡å€¼æ—¶ä½¿ç”¨äº† $\max$ æ“ä½œï¼š$y_i = r + \gamma \max_{a&apos;} Q(s&apos;, a&apos;)$ã€‚
ç”±äºç¥ç»ç½‘ç»œæœ¬èº«å­˜åœ¨ä¼°è®¡è¯¯å·®ï¼Œ$\max$ æ“ä½œå€¾å‘äºé€‰æ‹©é‚£äº›è¢«&lt;strong&gt;é«˜ä¼°&lt;/strong&gt;çš„å€¼ã€‚è¿™ç§&lt;strong&gt;æœ€å¤§åŒ–åå·® (Maximization Bias)&lt;/strong&gt; ä¼šå¯¼è‡´ Q å€¼æ™®éåå¤§ï¼Œå½±å“ç­–ç•¥å­¦ä¹ ã€‚&lt;/p&gt;
&lt;h3&gt;è§£å†³æ–¹æ¡ˆ&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;è§£è€¦é€‰æ‹©ä¸è¯„ä¼°&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;é€‰æ‹©åŠ¨ä½œ&lt;/strong&gt;ï¼šä½¿ç”¨å½“å‰ç½‘ç»œ $Q_\omega$ æ¥å†³å®šå“ªä¸ªåŠ¨ä½œæœ€å¥½ï¼ˆå³ argmaxï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è¯„ä¼°ä»·å€¼&lt;/strong&gt;ï¼šä½¿ç”¨ç›®æ ‡ç½‘ç»œ $Q_{\omega^-}$ æ¥è®¡ç®—é‚£ä¸ªåŠ¨ä½œçš„ä»·å€¼ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Double DQN ç›®æ ‡å…¬å¼&lt;/strong&gt;ï¼š
$$
y_i = r_i + \gamma Q_{\omega^-}(s&apos;&lt;em&gt;i, \underset{a&apos;}{\operatorname{argmax}} Q&lt;/em&gt;\omega(s&apos;_i, a&apos;))
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;è¿›é˜¶ 2ï¼šDueling DQN&lt;/h2&gt;
&lt;h3&gt;æ ¸å¿ƒæ€æƒ³&lt;/h3&gt;
&lt;p&gt;åœ¨å¾ˆå¤šçŠ¶æ€ä¸‹ï¼Œ&lt;strong&gt;çŠ¶æ€æœ¬èº«çš„ä»·å€¼&lt;/strong&gt;æ¯”&lt;strong&gt;é€‰æ‹©ä»€ä¹ˆåŠ¨ä½œ&lt;/strong&gt;æ›´é‡è¦ã€‚
ä¾‹å¦‚ï¼šåœ¨èµ›è½¦æ¸¸æˆä¸­ï¼Œå¦‚æœå‰é¢æ˜¯æ­»èƒ¡åŒï¼ˆçŠ¶æ€å·®ï¼‰ï¼Œæ— è®ºä½ å‘å·¦è½¬è¿˜æ˜¯å‘å³è½¬ï¼ˆåŠ¨ä½œï¼‰ï¼Œä»·å€¼éƒ½å¾ˆä½ã€‚
Dueling DQN æ”¹å˜äº†ç½‘ç»œç»“æ„ï¼Œå°† Q å€¼åˆ†è§£ä¸ºä¸¤éƒ¨åˆ†ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;çŠ¶æ€ä»·å€¼å‡½æ•° (Value Function)&lt;/strong&gt; $V(s)$ï¼šä»…ä¸çŠ¶æ€æœ‰å…³ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ä¼˜åŠ¿å‡½æ•° (Advantage Function)&lt;/strong&gt; $A(s,a)$ï¼šä¸åŠ¨ä½œæœ‰å…³ï¼Œè¡¨ç¤ºåŠ¨ä½œ $a$ ç›¸æ¯”å¹³å‡æƒ…å†µå¥½å¤šå°‘ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$$
Q(s, a) = V(s) + A(s, a)
$$&lt;/p&gt;
&lt;h3&gt;å¯è¾¨è¯†æ€§é—®é¢˜ (Identifiability)&lt;/h3&gt;
&lt;p&gt;å¦‚æœç›´æ¥ç”¨ $V+A$ï¼Œç½‘ç»œä¼šå‡ºç°å”¯ä¸€æ€§é—®é¢˜ï¼ˆ$V$ åŠ  10ï¼Œ$A$ å‡ 10ï¼Œæ€»å’Œ $Q$ ä¸å˜ï¼‰ã€‚ä¸ºäº†è®© $V$ å’Œ $A$ èƒ½è¢«å”¯ä¸€ç¡®å®šï¼Œæˆ‘ä»¬éœ€è¦å¼ºè¡Œçº¦æŸ $A$ çš„æŸç§æ€§è´¨ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;èšåˆå…¬å¼ (Aggregation)&lt;/strong&gt;ï¼š
é€šå¸¸è®©ä¼˜åŠ¿å‡½æ•° $A$ å¯¹äºæŸä¸ªçŠ¶æ€çš„å‡å€¼ä¸º 0ï¼Œæˆ–è€…æœ€å¤§å€¼ä¸º 0ã€‚
$$
Q(s,a;\theta,\alpha,\beta)=V(s;\theta,\beta) + \left( A(s,a;\theta,\alpha) - \frac{1}{|\mathcal{A}|}\sum_{a^\prime}A(s,a^\prime;\theta,\alpha) \right)
$$
æˆ–è€…ï¼š
$$
Q(s,a;\theta,\alpha,\beta)=V(s;\theta,\beta) + \left( A(s,a;\theta,\alpha) - \max_{a^\prime}A(s,a^\prime;\theta,\alpha) \right)
$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ä¼˜ç‚¹&lt;/strong&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;åœ¨åŠ¨ä½œå¯¹ç¯å¢ƒå½±å“ä¸å¤§çš„çŠ¶æ€ä¸‹ï¼Œèƒ½æ›´å¿«åœ°å­¦ä¹ çŠ¶æ€ä»·å€¼ $V$ã€‚&lt;/li&gt;
&lt;li&gt;æå¤§åœ°æé«˜äº†è®­ç»ƒæ•ˆç‡å’Œç¨³å®šæ€§ã€‚&lt;/li&gt;
&lt;/ul&gt;</content:encoded><h:img src="https://pic.hana0721.top/rl-note-2.8vndvqvn7c.webp"/><enclosure url="https://pic.hana0721.top/rl-note-2.8vndvqvn7c.webp"/></item><item><title>RLç¬”è®°ï¼ˆ7ï¼‰ï¼šDyna-Q</title><link>https://claudiakim6827362.github.io/blog/rl-note-7</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/rl-note-7</guid><description>ä»è¯•é”™åˆ°è§„åˆ’ï¼šåŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹  (Model-Based RL) å…¥é—¨ã€‚è¯¦è§£ Dyna-Q ç®—æ³•å¦‚ä½•åˆ©ç”¨ç¯å¢ƒæ¨¡å‹ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ï¼ŒåŠ é€Ÿç­–ç•¥å­¦ä¹ ã€‚</description><pubDate>Tue, 16 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;å¼•è¨€ï¼ˆIntroductionï¼‰&lt;/h2&gt;
&lt;p&gt;åœ¨ä¹‹å‰çš„ Q-Learning å’Œ SARSA ä¸­ï¼Œæ™ºèƒ½ä½“åªèƒ½é€šè¿‡&lt;strong&gt;çœŸå®&lt;/strong&gt;åœ°ä¸ç¯å¢ƒäº¤äº’ï¼ˆæ‘”è·Ÿå¤´ã€åƒé‡‘å¸ï¼‰æ¥å­¦ä¹ ï¼Œè¿™è¢«ç§°ä¸º &lt;strong&gt;æ— æ¨¡å‹å¼ºåŒ–å­¦ä¹  (Model-Free RL)&lt;/strong&gt;ã€‚è¿™ç§æ–¹å¼è™½ç„¶ç¨³å¥ï¼Œä½†æ•ˆç‡è¾ƒä½ï¼Œå› ä¸ºçœŸå®äº¤äº’å¾€å¾€æ˜‚è´µä¸”ç¼“æ…¢ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;åŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹  (Model-Based RL)&lt;/strong&gt; å¼•å…¥äº†ä¸€ä¸ªæ–°çš„æ€è·¯ï¼šå¦‚æœæ™ºèƒ½ä½“èƒ½å­¦ä¼šç¯å¢ƒçš„è¿è¡Œè§„å¾‹ï¼ˆå»ºç«‹ä¸€ä¸ªæ¨¡å‹ï¼‰ï¼Œå®ƒå°±å¯ä»¥åœ¨è„‘æµ·ä¸­â€œæ¨æ¼”â€æœªæ¥ï¼Œä»è€Œå‡å°‘å¯¹çœŸå®ä¸–ç•Œçš„ä¾èµ–ã€‚&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;ğŸ’¡ ç›´è§‰ç†è§£&lt;/strong&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Model-Free (Q-Learning)&lt;/strong&gt;ï¼šåƒæ˜¯åœ¨ç»ƒä¹ æŠ•ç¯®ï¼Œå¿…é¡»æ¯æ¬¡çœŸæŠŠçƒæŠ•å‡ºå»æ‰çŸ¥é“è¿›æ²¡è¿›ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Model-Based (Dyna-Q)&lt;/strong&gt;ï¼šåƒæ˜¯ä¸‹æ£‹é«˜æ‰‹ï¼Œä¸ä»…åœ¨å®æˆ˜ä¸­å­¦ä¹ ï¼Œè¿˜åœ¨è„‘æµ·ä¸­å¤ç›˜å’Œæ¨æ¼”ï¼ˆPlanningï¼‰ï¼Œâ€œå¦‚æœæˆ‘èµ°è¿™ä¸€æ­¥ï¼Œå¯¹æ‰‹å¯èƒ½ä¼šé‚£æ ·èµ°...â€ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2&gt;æ ¸å¿ƒæ¦‚å¿µ&lt;/h2&gt;
&lt;h3&gt;ä»€ä¹ˆæ˜¯æ¨¡å‹ (Model)ï¼Ÿ&lt;/h3&gt;
&lt;p&gt;åœ¨ RL ä¸­ï¼Œæ¨¡å‹ $M$ æŒ‡çš„æ˜¯å¯¹ç¯å¢ƒåŠ¨æ€çš„æ¨¡æ‹Ÿã€‚ç»™å®šçŠ¶æ€ $s$ å’ŒåŠ¨ä½œ $a$ï¼Œæ¨¡å‹èƒ½é¢„æµ‹å‡ºä¸‹ä¸€ä¸ªçŠ¶æ€ $s&apos;$ å’Œå¥–åŠ± $r$ï¼š
$$
s&apos;, r \leftarrow M(s, a)
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;é¢„çŸ¥æ¨¡å‹&lt;/strong&gt;ï¼šå¦‚ä¸‹æ£‹ï¼Œè§„åˆ™æ˜¯å®Œå…¨å·²çŸ¥çš„ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å­¦ä¹ æ¨¡å‹&lt;/strong&gt;ï¼šå¦‚æœºå™¨äººèµ°è·¯ï¼Œéœ€è¦é€šè¿‡è§‚æµ‹æ•°æ® $(s, a, r, s&apos;)$ æ¥æ‹Ÿåˆç¯å¢ƒè§„å¾‹ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;ä¸¤ä¸ªå…³é”®æŒ‡æ ‡&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;æ”¶æ•›æ•ˆæœ&lt;/strong&gt;ï¼šç®—æ³•æ”¶æ•›åèƒ½å¤Ÿè·å¾—çš„æœŸæœ›å›æŠ¥ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ ·æœ¬å¤æ‚åº¦ (Sample Complexity)&lt;/strong&gt;ï¼šè¾¾åˆ°åŒæ ·çš„æ€§èƒ½ï¼Œéœ€è¦åœ¨çœŸå®ç¯å¢ƒä¸­äº¤äº’å¤šå°‘æ¬¡ã€‚
&lt;ul&gt;
&lt;li&gt;Model-Based çš„æ ¸å¿ƒä¼˜åŠ¿å°±æ˜¯&lt;strong&gt;é™ä½æ ·æœ¬å¤æ‚åº¦&lt;/strong&gt;ï¼ˆå°‘èµ°å¼¯è·¯ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;å­¦ä¹ ä¸è§„åˆ’&lt;/h3&gt;
&lt;p&gt;Dyna-Q æ¶æ„å°† RL è¿‡ç¨‹åˆ†ä¸ºäº†ä¸¤éƒ¨åˆ†ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;ç›´æ¥å¼ºåŒ–å­¦ä¹  (Direct RL)&lt;/strong&gt;ï¼šåˆ©ç”¨&lt;strong&gt;çœŸå®ç»éªŒ&lt;/strong&gt;æ›´æ–°ä»·å€¼å‡½æ•°ï¼ˆå’Œ Q-Learning ä¸€æ ·ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è§„åˆ’ (Planning)&lt;/strong&gt;ï¼šåˆ©ç”¨&lt;strong&gt;æ¨¡æ‹Ÿç»éªŒ&lt;/strong&gt;ï¼ˆæ¨¡å‹ç”Ÿæˆçš„ï¼‰æ›´æ–°ä»·å€¼å‡½æ•°ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2&gt;Dyna-Q ç®—æ³•&lt;/h2&gt;
&lt;p&gt;Dyna-Q æ˜¯å°† Q-Learning ä¸è§„åˆ’ç»“åˆçš„æœ€ç®€å•èŒƒä¾‹ã€‚å®ƒç»´æŠ¤ä¸€ä¸ªç®€å•çš„&lt;strong&gt;æŸ¥è¡¨å¼æ¨¡å‹ (Table-based Model)&lt;/strong&gt;ï¼Œè®°å½•åœ¨è¿™ä¸ªçŠ¶æ€ $s$ åšåŠ¨ä½œ $a$ æ›¾ç»å‘ç”Ÿäº†ä»€ä¹ˆã€‚&lt;/p&gt;
&lt;h3&gt;ç®—æ³•æµç¨‹&lt;/h3&gt;
&lt;p&gt;åœ¨æ¯ä¸ªæ—¶é—´æ­¥ $t$ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;è¡ŒåŠ¨&lt;/strong&gt;ï¼šåœ¨çœŸå®ç¯å¢ƒä¸­æ‰§è¡ŒåŠ¨ä½œï¼Œè·å¾— $(s, a, r, s&apos;)$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç›´æ¥å­¦ä¹ &lt;/strong&gt;ï¼šç”¨çœŸå®æ•°æ®æ›´æ–° $Q(s,a)$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ¨¡å‹å­¦ä¹ &lt;/strong&gt;ï¼šæŠŠ $(s, a) \to (r, s&apos;)$ è®°å…¥æ¨¡å‹ï¼ˆå¦‚æœæ˜¯ç¡®å®šæ€§ç¯å¢ƒï¼Œç›´æ¥è¦†ç›–ï¼›å¦‚æœæ˜¯éšæœºç¯å¢ƒï¼Œå¯èƒ½éœ€è¦è®°å½•åˆ†å¸ƒï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è§„åˆ’ (Planning)&lt;/strong&gt;ï¼š
&lt;ul&gt;
&lt;li&gt;é‡å¤ $N$ æ¬¡ï¼ˆæ¯”å¦‚ 10 æ¬¡ï¼‰ï¼š&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åšæ¢¦&lt;/strong&gt;ï¼šéšæœºä»è®°å¿†ä¸­æŒ‘é€‰ä¸€ä¸ª&lt;strong&gt;æ›¾ç»å»è¿‡çš„&lt;/strong&gt;çŠ¶æ€ $s_{sim}$ å’Œ&lt;strong&gt;æ›¾ç»åšè¿‡çš„&lt;/strong&gt;åŠ¨ä½œ $a_{sim}$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ¨æ¼”&lt;/strong&gt;ï¼šè¯¢é—®æ¨¡å‹å¾—åˆ°æ¨¡æ‹Ÿç»“æœ $r_{sim}, s&apos;_{sim}$ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;é—´æ¥å­¦ä¹ &lt;/strong&gt;ï¼šç”¨æ¨¡æ‹Ÿæ•°æ®æ›´æ–° $Q(s_{sim}, a_{sim})$ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;ç®—æ³•ä¼ªä»£ç &lt;/h3&gt;
&lt;p&gt;$$
\begin{aligned}
&amp;#x26; \bullet ; \text{Initialize } Q(s,a), \text{Model } M(s,a) \
&amp;#x26; \bullet ; \textbf{For } \text{episode } e = 1 \to E \textbf{ do}: \
&amp;#x26; \bullet \qquad \text{Initialize state } s \
&amp;#x26; \bullet \qquad \textbf{For } \text{step } t = 1 \to T \textbf{ do}: \
&amp;#x26; \bullet \qquad \qquad \text{Choose action } a \text{ using } \epsilon\text{-greedy} \
&amp;#x26; \bullet \qquad \qquad \text{Execute } a, \text{ observe } r, s&apos; \
&amp;#x26; \bullet \qquad \qquad \textbf{1. Direct RL (Q-Learning update):} \
&amp;#x26; \bullet \qquad \qquad Q(s,a) \leftarrow Q(s,a) + \alpha [r + \gamma \max_{a&apos;} Q(s&apos;, a&apos;) - Q(s,a)] \
&amp;#x26; \bullet \qquad \qquad \textbf{2. Model Learning:} \
&amp;#x26; \bullet \qquad \qquad M(s, a) \leftarrow (r, s&apos;) \
&amp;#x26; \bullet \qquad \qquad \textbf{3. Planning (Loop N times):} \
&amp;#x26; \bullet \qquad \qquad \textbf{For } n = 1 \to N \textbf{ do}: \
&amp;#x26; \bullet \qquad \qquad \qquad \text{Randomly select } s_{sim} \text{ previously observed} \
&amp;#x26; \bullet \qquad \qquad \qquad \text{Randomly select } a_{sim} \text{ previously taken in } s_{sim} \
&amp;#x26; \bullet \qquad \qquad \qquad r_{sim}, s&apos;&lt;em&gt;{sim} \leftarrow M(s&lt;/em&gt;{sim}, a_{sim}) \
&amp;#x26; \bullet \qquad \qquad \qquad Q(s_{sim}, a_{sim}) \leftarrow Q(s_{sim}, a_{sim}) + \alpha [r_{sim} + \gamma \max_{a&apos;} Q(s&apos;&lt;em&gt;{sim}, a&apos;) - Q(s&lt;/em&gt;{sim}, a_{sim})] \
&amp;#x26; \bullet \qquad \qquad \textbf{End For} \
&amp;#x26; \bullet \qquad \qquad s \leftarrow s&apos; \
&amp;#x26; \bullet \qquad \textbf{End For} \
&amp;#x26; \bullet ; \textbf{End For}
\end{aligned}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;ä¼˜ç¼ºç‚¹åˆ†æ&lt;/h2&gt;
&lt;h3&gt;ä¼˜åŠ¿&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;æ ·æœ¬æ•ˆç‡æé«˜&lt;/strong&gt;ï¼šåœ¨æ¯æ¬¡ä¸ç¯å¢ƒäº¤äº’åï¼ŒDyna-Q ä¼šè¿›è¡Œ $N$ æ¬¡è§„åˆ’ã€‚è¿™æ„å‘³ç€&lt;strong&gt;ä¸€æ¡çœŸå®ç»éªŒè¢«å¤ç”¨äº† $N+1$ æ¬¡&lt;/strong&gt;ã€‚å¯¹äºçœŸå®äº¤äº’å¾ˆæ˜‚è´µçš„åœºæ™¯ï¼ˆå¦‚æœºå™¨äººå®éªŒï¼‰ï¼Œè¿™éå¸¸æœ‰ç”¨ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;åŠ£åŠ¿&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;æ¨¡å‹åå·® (Model Bias)&lt;/strong&gt;ï¼šè¿™æ˜¯ Model-Based RL çš„æ­»ç©´ã€‚
&lt;ul&gt;
&lt;li&gt;å¦‚æœæ¨¡å‹å­¦é”™äº†ï¼ˆæ¯”å¦‚ç°å®ä¸­èµ°è¿™ä¸€æ­¥ä¼šæ‰å‘é‡Œï¼Œæ¨¡å‹å´è®¤ä¸ºä¼šé£è¿‡å»ï¼‰ï¼Œé‚£ä¹ˆè§„åˆ’å¾—è¶Šå¤šï¼Œæ™ºèƒ½ä½“å°±åœ¨é”™è¯¯çš„é“è·¯ä¸Šè¶Šèµ°è¶Šè¿œã€‚&lt;/li&gt;
&lt;li&gt;è§£å†³æ–¹æ¡ˆé€šå¸¸æ¶‰åŠ&lt;strong&gt;ä¸ç¡®å®šæ€§ä¼°è®¡&lt;/strong&gt;ï¼ˆå¦‚æœå¯¹æ¨¡å‹é¢„æµ‹ä¸è‡ªä¿¡ï¼Œå°±ä¸è¦ä¿¡å®ƒï¼‰æˆ–&lt;strong&gt;æ¢ç´¢å¥–åŠ±&lt;/strong&gt;ï¼ˆDyna-Q+ï¼Œé¼“åŠ±å»éªŒè¯æ¨¡å‹ä¸ç¡®å®šçš„åœ°æ–¹ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;æ€»ç»“&lt;/h2&gt;
&lt;p&gt;Dyna-Q å®Œç¾å±•ç¤ºäº†å¼ºåŒ–å­¦ä¹ å¦‚ä½•ç»“åˆâ€œè¡Œä¸‡é‡Œè·¯â€ï¼ˆçœŸå®äº¤äº’ï¼‰ä¸â€œè¯»ä¸‡å·ä¹¦â€ï¼ˆæ¨¡å‹è§„åˆ’ï¼‰ã€‚
åœ¨ä¸‹ä¸€ç« ï¼Œæˆ‘ä»¬å°†æ­£å¼å‘Šåˆ«â€œè¡¨æ ¼å‹ (Tabular)â€å¼ºåŒ–å­¦ä¹ ï¼Œå¼•å…¥ç¥ç»ç½‘ç»œï¼Œè¿›å…¥ &lt;strong&gt;æ·±åº¦å¼ºåŒ–å­¦ä¹  (Deep Reinforcement Learning)&lt;/strong&gt; çš„æ—¶ä»£ã€‚&lt;/p&gt;</content:encoded><h:img src="https://pic.hana0721.top//rl-note.3yex1wenfg.webp"/><enclosure url="https://pic.hana0721.top//rl-note.3yex1wenfg.webp"/></item><item><title>RLç¬”è®°ï¼ˆ6ï¼‰ï¼šæ—¶åºå·®åˆ†</title><link>https://claudiakim6827362.github.io/blog/rl-note-6</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/rl-note-6</guid><description>ç»“åˆäº†è’™ç‰¹å¡æ´›ä¸åŠ¨æ€è§„åˆ’çš„ç²¾åï¼šè¯¦è§£æ—¶åºå·®åˆ† (TD) å­¦ä¹ ã€‚æ¶µç›– SARSAã€Q-Learning åŠå…¶å¤šæ­¥æ‰©å±•ï¼Œæ·±å…¥å¯¹æ¯” On-Policy ä¸ Off-Policy çš„æœ¬è´¨åŒºåˆ«ã€‚</description><pubDate>Mon, 15 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;å¼•è¨€ï¼ˆIntroductionï¼‰&lt;/h2&gt;
&lt;p&gt;åœ¨å¤§éƒ¨åˆ†å¼ºåŒ–å­¦ä¹ çš„ç°å®åœºæ™¯ä¸­ï¼ŒMDP ä¸­çš„çŠ¶æ€è½¬ç§»æ¦‚ç‡ $\mathcal{P}$ å’Œå¥–åŠ±å‡½æ•° $\mathcal{R}$ é€šå¸¸æ˜¯æœªçŸ¥çš„ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å› ä¸ºæ²¡æœ‰æ¨¡å‹ï¼Œæˆ‘ä»¬æ— æ³•ç›´æ¥ç”¨&lt;strong&gt;åŠ¨æ€è§„åˆ’ (DP)&lt;/strong&gt; æ¥ç®—å‡ºæœ€ä¼˜è§£ã€‚&lt;/li&gt;
&lt;li&gt;æ™ºèƒ½ä½“å¿…é¡»åƒ&lt;strong&gt;è’™ç‰¹å¡æ´› (MC)&lt;/strong&gt; é‚£æ ·ï¼Œé€šè¿‡ä¸ç¯å¢ƒäº¤äº’ã€é‡‡æ ·æ•°æ®æ¥å­¦ä¹ ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;è¿™ç±»æ–¹æ³•ç»Ÿç§°ä¸º &lt;strong&gt;æ— æ¨¡å‹å¼ºåŒ–å­¦ä¹  (Model-Free RL)&lt;/strong&gt;ã€‚æœ¬ç« å°†ä»‹ç»å…¶ä¸­æœ€é‡è¦çš„ä¸€ç±»æ–¹æ³•ï¼š&lt;strong&gt;æ—¶åºå·®åˆ† (Temporal Difference, TD)&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;æ—¶åºå·®åˆ†æ–¹æ³• (Temporal Difference)&lt;/h2&gt;
&lt;h3&gt;æ ¸å¿ƒæ€æƒ³&lt;/h3&gt;
&lt;p&gt;æ—¶åºå·®åˆ† (TD) ç»“åˆäº†è’™ç‰¹å¡æ´› (MC) å’ŒåŠ¨æ€è§„åˆ’ (DP) çš„æ€æƒ³ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;åƒ MC&lt;/strong&gt;ï¼šç›´æ¥ä»ç»éªŒï¼ˆé‡‡æ ·æ•°æ®ï¼‰ä¸­å­¦ä¹ ï¼Œä¸éœ€è¦ç¯å¢ƒæ¨¡å‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;åƒ DP&lt;/strong&gt;ï¼šåˆ©ç”¨&lt;strong&gt;è‡ªä¸¾ (Bootstrapping)&lt;/strong&gt; çš„æ€æƒ³ï¼Œç”¨åç»§çŠ¶æ€çš„ä¼°è®¡å€¼æ¥æ›´æ–°å½“å‰çŠ¶æ€çš„ä¼°è®¡å€¼ï¼Œè€Œä¸éœ€è¦ç­‰åˆ°å›åˆç»“æŸã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;ä»·å€¼å‡½æ•°çš„æ›´æ–°&lt;/h3&gt;
&lt;p&gt;å›é¡¾è’™ç‰¹å¡æ´› (MC) çš„å¢é‡æ›´æ–°å…¬å¼ï¼š
$$
V(s_t) \leftarrow V(s_t) + \alpha [G_t - V(s_t)]
$$
å…¶ä¸­ $G_t$ æ˜¯ä» $t$ æ—¶åˆ»å¼€å§‹ç›´åˆ°å›åˆç»“æŸçš„çœŸå®å›æŠ¥ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TD çš„æ”¹è¿›&lt;/strong&gt;ï¼š
TD ä¸æƒ³ç­‰åˆ°å›åˆç»“æŸã€‚å®ƒåˆ©ç”¨è´å°”æ›¼æ–¹ç¨‹çš„æ€§è´¨ï¼Œç”¨ $r_t + \gamma V(s_{t+1})$ æ¥&lt;strong&gt;æ›¿ä»£&lt;/strong&gt; $G_t$ï¼š
$$
V(s_t) \leftarrow V(s_t) + \alpha [\underbrace{r_t + \gamma V(s_{t+1})}_{\text{TD Target}} - V(s_t)]
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;TD Target&lt;/strong&gt;: $r_t + \gamma V(s_{t+1})$ï¼Œè¿™æ˜¯æˆ‘ä»¬å¯¹çœŸå®å›æŠ¥ $G_t$ çš„ä¸€ä¸ªæœ‰åä½†æ–¹å·®æ›´å°çš„ä¼°è®¡ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;TD Error&lt;/strong&gt;: $\delta_t = r_t + \gamma V(s_{t+1}) - V(s_t)$ï¼Œè¡¨ç¤ºâ€œå½“ä¸‹çš„æƒŠå–œâ€â€”â€”å®é™…å‘ç”Ÿçš„æƒ…å†µæ¯”é¢„æœŸçš„å¥½äº†å¤šå°‘ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;ä¸ºä»€ä¹ˆå¯ä»¥æ›¿ä»£ï¼Ÿ&lt;/h3&gt;
&lt;p&gt;æ ¹æ® $V^\pi$ çš„å®šä¹‰æ¨å¯¼ï¼š
$$
\begin{align}
V^\pi(s) &amp;#x26;= \mathbb{E}&lt;em&gt;\pi[G_t | S_t=s] \notag \
&amp;#x26;= \mathbb{E}&lt;/em&gt;\pi [R_t + \gamma G_{t+1} | S_t=s] \notag \
&amp;#x26;= \mathbb{E}&lt;em&gt;\pi [R_t + \gamma V^\pi(S&lt;/em&gt;{t+1}) | S_t=s] \notag
\end{align}
$$
å¯è§ï¼Œ$R_t + \gamma V(S_{t+1})$ æ˜¯ $V(s)$ çš„æ— åä¼°è®¡ï¼ˆå‡è®¾ $V(S_{t+1})$ å‡†ç¡®ï¼‰ã€‚éšç€è¿­ä»£è¿›è¡Œï¼Œæœ€ç»ˆ $V$ ä¼šæ”¶æ•›åˆ° $V^\pi$ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;SARSA ç®—æ³•&lt;/h2&gt;
&lt;p&gt;SARSA æ˜¯ &lt;strong&gt;S&lt;/strong&gt;tate-&lt;strong&gt;A&lt;/strong&gt;ction-&lt;strong&gt;R&lt;/strong&gt;eward-&lt;strong&gt;S&lt;/strong&gt;tate-&lt;strong&gt;A&lt;/strong&gt;ction çš„ç¼©å†™ï¼Œå› ä¸ºå®ƒåˆ©ç”¨äº”å…ƒç»„ $(s_t, a_t, r_t, s_{t+1}, a_{t+1})$ è¿›è¡Œæ›´æ–°ã€‚&lt;/p&gt;
&lt;h3&gt;ä» V åˆ° Q&lt;/h3&gt;
&lt;p&gt;åœ¨ Model-Free åœºæ™¯ä¸‹ï¼Œæˆ‘ä»¬é€šå¸¸ç›´æ¥ä¼°è®¡ &lt;strong&gt;åŠ¨ä½œä»·å€¼å‡½æ•° $Q(s,a)$&lt;/strong&gt;ï¼Œè€Œä¸æ˜¯ $V(s)$ï¼Œä»¥ä¾¿ç›´æ¥é€‰å–åŠ¨ä½œã€‚
æ›´æ–°å…¬å¼ï¼š
$$
Q(s_t,a_t) \leftarrow Q(s_t,a_t) + \alpha [r_t + \gamma Q(s_{t+1},a_{t+1}) - Q(s_t,a_t)]
$$&lt;/p&gt;
&lt;h3&gt;æ¢ç´¢ä¸åˆ©ç”¨&lt;/h3&gt;
&lt;p&gt;SARSA éœ€è¦è§£å†³ä¸¤ä¸ªé—®é¢˜ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;ä¼°è®¡ä¸å‡†&lt;/strong&gt;ï¼šåœ¨è®­ç»ƒåˆæœŸï¼ŒQ å€¼æ˜¯ä¸å‡†ç¡®çš„ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;é‡‡æ ·è¦†ç›–&lt;/strong&gt;ï¼šå¦‚æœä¸€ç›´è´ªå©ªåœ°é€‰åŠ¨ä½œï¼Œå¯èƒ½æ°¸è¿œæ— æ³•å‘ç°æ›´å¥½çš„ç­–ç•¥ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;å› æ­¤ï¼ŒSARSA ä½¿ç”¨ &lt;strong&gt;$\epsilon$-è´ªå©ªç­–ç•¥ ($\epsilon$-Greedy)&lt;/strong&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ä»¥ $1-\epsilon$ çš„æ¦‚ç‡é€‰æ‹© $\arg\max_a Q(s,a)$ã€‚&lt;/li&gt;
&lt;li&gt;ä»¥ $\epsilon$ çš„æ¦‚ç‡éšæœºé€‰æ‹©åŠ¨ä½œã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;ç®—æ³•ä¼ªä»£ç &lt;/h3&gt;
&lt;p&gt;$$
\begin{aligned}
&amp;#x26; \bullet ; \text{Initialize } Q(s,a) \
&amp;#x26; \bullet ; \textbf{For } \text{episode } = 1 \to E \textbf{ do}: \
&amp;#x26; \bullet \qquad \text{Initialize state } s \
&amp;#x26; \bullet \qquad \text{Choose action } a \text{ from } s \text{ using } \epsilon\text{-greedy} \
&amp;#x26; \bullet \qquad \textbf{For } \text{step } = 1 \to T \textbf{ do}: \
&amp;#x26; \bullet \qquad \qquad \text{Take action } a, \text{ observe } r, s&apos; \
&amp;#x26; \bullet \qquad \qquad \text{Choose action } a&apos; \text{ from } s&apos; \text{ using } \epsilon\text{-greedy} \
&amp;#x26; \bullet \qquad \qquad Q(s,a) \leftarrow Q(s,a) + \alpha [r + \gamma Q(s&apos;,a&apos;) - Q(s,a)] \
&amp;#x26; \bullet \qquad \qquad s \leftarrow s&apos;, a \leftarrow a&apos; \
&amp;#x26; \bullet \qquad \textbf{End For} \
&amp;#x26; \bullet ; \textbf{End For}
\end{aligned}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;å¤šæ­¥ SARSA ($n$-step SARSA)&lt;/h2&gt;
&lt;p&gt;MC æ˜¯æ— åä½†æ–¹å·®å¤§ï¼ˆè¦ç­‰å¾ˆä¹…ï¼‰ï¼ŒTD(0) æ˜¯åå·®å¤§ä½†æ–¹å·®å°ï¼ˆçœ‹ä¸€æ­¥ï¼‰ã€‚æˆ‘ä»¬å¯ä»¥æŠ˜ä¸­ä¸€ä¸‹ï¼Œçœ‹ $n$ æ­¥ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å•æ­¥ TD (SARSA)&lt;/strong&gt;:
$$G_t^{(1)} = r_t + \gamma Q(s_{t+1}, a_{t+1})$$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;$n$ æ­¥ TD&lt;/strong&gt;:
$$G_t^{(n)} = r_t + \gamma r_{t+1} + \dots + \gamma^n Q(s_{t+n}, a_{t+n})$$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;$n$ æ­¥ SARSA æ›´æ–°è§„åˆ™&lt;/strong&gt;ï¼š
$$
Q(s_t,a_t) \leftarrow Q(s_t,a_t) + \alpha [G_t^{(n)} - Q(s_t,a_t)]
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;Q-Learning ç®—æ³•&lt;/h2&gt;
&lt;p&gt;Q-Learning æ˜¯å¼ºåŒ–å­¦ä¹ ä¸­æœ€è‘—åçš„ç®—æ³•ä¹‹ä¸€ï¼Œå®ƒä¸ SARSA éå¸¸åƒï¼Œä½†æœ‰ä¸€ä¸ªå…³é”®åŒºåˆ«ã€‚&lt;/p&gt;
&lt;h3&gt;æ›´æ–°è§„åˆ™&lt;/h3&gt;
&lt;p&gt;$$
Q(s_t,a_t) \leftarrow Q(s_t,a_t) + \alpha [r_t + \gamma \max_{a&apos;} Q(s_{t+1}, a&apos;) - Q(s_t,a_t)]
$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;å…³é”®åŒºåˆ«&lt;/strong&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;SARSA&lt;/strong&gt;ï¼šä½¿ç”¨ $Q(s_{t+1}, a_{t+1})$ã€‚è¿™é‡Œçš„ $a_{t+1}$ æ˜¯æ™ºèƒ½ä½“&lt;strong&gt;å®é™…é‡‡å–&lt;/strong&gt;çš„åŠ¨ä½œï¼ˆå¯èƒ½åŒ…å«äº† $\epsilon$ çš„éšæœºæ¢ç´¢ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Q-Learning&lt;/strong&gt;ï¼šä½¿ç”¨ $\max_{a&apos;} Q(s_{t+1}, a&apos;)$ã€‚ä¸ç®¡æ™ºèƒ½ä½“ä¸‹ä¸€æ­¥å®é™…åšäº†ä»€ä¹ˆï¼Œæˆ‘ä»¬åœ¨æ›´æ–°æ—¶éƒ½å‡è®¾å®ƒä¼šåš&lt;strong&gt;æœ€å¥½çš„&lt;/strong&gt;é‚£ä¸ªåŠ¨ä½œã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;ç®—æ³•ä¼ªä»£ç &lt;/h3&gt;
&lt;p&gt;$$
\begin{aligned}
&amp;#x26; \bullet ; \text{Initialize } Q(s,a) \
&amp;#x26; \bullet ; \textbf{For } \text{episode } e = 1 \to E \textbf{ do}: \
&amp;#x26; \bullet \qquad \text{Initialize state } s \
&amp;#x26; \bullet \qquad \textbf{For } \text{step } t = 1 \to T \textbf{ do}: \
&amp;#x26; \bullet \qquad \qquad \text{Choose action } a \text{ from } s \text{ using } \epsilon\text{-greedy} \
&amp;#x26; \bullet \qquad \qquad \text{Take action } a, \text{ observe } r, s&apos; \
&amp;#x26; \bullet \qquad \qquad Q(s,a) \leftarrow Q(s,a) + \alpha [r + \gamma \max_{a&apos;} Q(s&apos;, a&apos;) - Q(s,a)] \
&amp;#x26; \bullet \qquad \qquad s \leftarrow s&apos; \
&amp;#x26; \bullet \qquad \textbf{End For} \
&amp;#x26; \bullet ; \textbf{End For}
\end{aligned}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;æ ¸å¿ƒå¯¹æ¯”ï¼šåœ¨çº¿ç­–ç•¥ vs. ç¦»çº¿ç­–ç•¥&lt;/h2&gt;
&lt;p&gt;è¿™æ˜¯å¼ºåŒ–å­¦ä¹ ä¸­æœ€é‡è¦çš„åˆ†ç±»ä¹‹ä¸€ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;è¡Œä¸ºç­–ç•¥ (Behavior Policy)&lt;/strong&gt;ï¼šæ™ºèƒ½ä½“ä¸ç¯å¢ƒäº¤äº’ã€äº§ç”Ÿæ•°æ®æ—¶ä½¿ç”¨çš„ç­–ç•¥ï¼ˆé€šå¸¸åŒ…å«éšæœºæ€§ï¼Œå¦‚ $\epsilon$-greedyï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ç›®æ ‡ç­–ç•¥ (Target Policy)&lt;/strong&gt;ï¼šæˆ‘ä»¬æƒ³è¦å­¦ä¹ å’Œä¼˜åŒ–çš„ç­–ç•¥ï¼ˆé€šå¸¸æ˜¯è´ªå©ªç­–ç•¥ï¼Œå³æœ€ä¼˜ç­–ç•¥ï¼‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;| ç‰¹æ€§ | åœ¨çº¿ç­–ç•¥ (On-Policy) | ç¦»çº¿ç­–ç•¥ (Off-Policy) |
| :--- | :--- | :--- |
| &lt;strong&gt;å®šä¹‰&lt;/strong&gt; | è¡Œä¸ºç­–ç•¥ &lt;strong&gt;==&lt;/strong&gt; ç›®æ ‡ç­–ç•¥ | è¡Œä¸ºç­–ç•¥ &lt;strong&gt;!=&lt;/strong&gt; ç›®æ ‡ç­–ç•¥ |
| &lt;strong&gt;ä»£è¡¨ç®—æ³•&lt;/strong&gt; | &lt;strong&gt;SARSA&lt;/strong&gt; | &lt;strong&gt;Q-Learning&lt;/strong&gt; |
| &lt;strong&gt;æ›´æ–°ä¾æ®&lt;/strong&gt; | ä½¿ç”¨&lt;strong&gt;å®é™…æ‰§è¡Œ&lt;/strong&gt;çš„ä¸‹ä¸€ä¸ªåŠ¨ä½œ $a_{t+1}$ çš„ä»·å€¼ | ä½¿ç”¨&lt;strong&gt;ç†è®ºä¸Šæœ€ä¼˜&lt;/strong&gt;çš„åŠ¨ä½œ $\max Q$ çš„ä»·å€¼ |
| &lt;strong&gt;ä¼˜ç¼ºç‚¹&lt;/strong&gt; | æ¯”è¾ƒèƒ†å°ã€‚å› ä¸ºå®ƒçŸ¥é“è‡ªå·±ä¸‹ä¸€æ­¥å¯èƒ½ä¼šä¹±èµ°ï¼ˆéšæœºæ¢ç´¢ï¼‰ï¼Œæ‰€ä»¥å®ƒä¼šé¿å¼€æ‚¬å´–è¾¹ç¼˜ï¼ˆå“ªæ€•æ‚¬å´–è¾¹æœ‰å®è—ï¼‰ã€‚ | æ¯”è¾ƒå¤§èƒ†ã€‚å®ƒå‡è®¾è‡ªå·±ä¸‹ä¸€æ­¥ä¸€å®šä¼šèµ°æœ€ä¼˜è·¯å¾„ï¼Œæ‰€ä»¥ä¼šå‹‡æ•¢åœ°è´´ç€æ‚¬å´–èµ°ã€‚ |
| &lt;strong&gt;æ•°æ®æ•ˆç‡&lt;/strong&gt; | æ•°æ®å¿…é¡»ç°é‡‡ç°ç”¨ï¼Œä¸èƒ½ä½¿ç”¨æ—§ç­–ç•¥äº§ç”Ÿçš„æ•°æ®ï¼ˆReplay Bufferï¼‰ã€‚ | å¯ä»¥ä½¿ç”¨è¿‡å»çš„æ•°æ®ï¼Œæˆ–è€…åˆ«äººç©çš„æ•°æ®ï¼ˆé€‚åˆç»“åˆ Experience Replayï¼‰ã€‚ |&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;ğŸ’¡ ç›´è§‰ç†è§£&lt;/strong&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;SARSA&lt;/strong&gt; åƒæ˜¯ä¸€ä¸ª&lt;strong&gt;è°¨æ…çš„å­¦ç”Ÿ&lt;/strong&gt;ï¼šä»–åœ¨å­¦ä¹ æ—¶ä¼šè€ƒè™‘åˆ°è‡ªå·±è€ƒè¯•æ—¶å¯èƒ½ä¼šå› ä¸ºç´§å¼ ï¼ˆ$\epsilon$ éšæœºæ€§ï¼‰è€ŒçŠ¯é”™ï¼Œæ‰€ä»¥ä»–å¹³æ—¶ç»ƒä¹ æ—¶å°±å°½é‡é€‰å®¹é”™ç‡é«˜çš„è§£æ³•ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Q-Learning&lt;/strong&gt; åƒæ˜¯ä¸€ä¸ª&lt;strong&gt;ç†æƒ³ä¸»ä¹‰è€…&lt;/strong&gt;ï¼šä»–åœ¨å­¦ä¹ æ—¶å‡è®¾è‡ªå·±è€ƒè¯•æ—¶ç»å¯¹ä¸ä¼šçŠ¯é”™ï¼ˆå…¨é€‰æœ€ä¼˜è§£ $\max Q$ï¼‰ï¼Œæ‰€ä»¥ä»–ä¼šå­¦ä¹ é‚£æ¡ç†è®ºä¸Šåˆ†æ•°æœ€é«˜ã€ä½†å¯èƒ½é£é™©å¾ˆå¤§çš„è·¯å¾„ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;</content:encoded><h:img src="https://pic.hana0721.top//rl-note.3yex1wenfg.webp"/><enclosure url="https://pic.hana0721.top//rl-note.3yex1wenfg.webp"/></item><item><title>å›¾åºŠé…ç½®</title><link>https://claudiakim6827362.github.io/blog/rl-note-5</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/rl-note-5</guid><description>ä»æ¨¡å‹åˆ°ç»éªŒï¼šå¦‚ä½•ä¸ä¾èµ–çŠ¶æ€è½¬ç§»çŸ©é˜µï¼Œä»…é€šè¿‡â€˜ç©æ¸¸æˆâ€™æ¥ä¼°è®¡ä»·å€¼ï¼Ÿè¯¦è§£è’™ç‰¹å¡æ´›é¢„æµ‹ä¸æ§åˆ¶ã€å¢é‡æ›´æ–°åŠ GLIE æ€§è´¨ã€‚</description><pubDate>Sun, 14 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;blockquote&gt;
&lt;p&gt;å‚è€ƒ1ï¼š&lt;a href=&quot;https://axi404.top/blog/image-hosting&quot;&gt;å›¾åºŠé€‰æ‹©ä¸é…ç½®&lt;/a&gt; è¯¥æ–¹æ³•è¿˜æ˜¯ä½¿ç”¨ github ä½œä¸ºå›¾åºŠ&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;å‚è€ƒ2ï¼š&lt;a href=&quot;https://axi404.top/blog/r2-image-host&quot;&gt;cloudflare r2 å›¾åºŠé…ç½®&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;å‚è€ƒ3ï¼š&lt;a href=&quot;https://github.com/iawooo/cftc&quot;&gt;cloudflare ç»“åˆ telegram å®ç°å›¾åºŠé…ç½®&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;æœ¬æ–‡ä½¿ç”¨çš„æ˜¯ &lt;strong&gt;å‚è€ƒ 3&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;éœ€è¦æ³¨æ„çš„æ˜¯ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;ä½¿ç”¨çš„æ˜¯ cloudflare pages&lt;/li&gt;
&lt;li&gt;æ³¨æ„ DATABASE æ˜¯ binding&lt;/li&gt;
&lt;li&gt;æ‰€æœ‰çš„å˜é‡éƒ½æ˜¯å¿…é¡»çš„&lt;/li&gt;
&lt;/ol&gt;</content:encoded><h:img src="https://pic.hana0721.top//rl-note.3yex1wenfg.webp"/><enclosure url="https://pic.hana0721.top//rl-note.3yex1wenfg.webp"/></item><item><title>Astro-Pure Blog å¤šå¹³å°éƒ¨ç½²(2) - cloudflare pages</title><link>https://claudiakim6827362.github.io/blog/rl-note-4</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/rl-note-4</guid><description>å¦‚ä½•å°† Astro-Pure ä¸»é¢˜éƒ¨ç½²åˆ° Cloudflare Pages å¹³å°?</description><pubDate>Sat, 13 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;blockquote&gt;
&lt;p&gt;æ¥ä¸Šä¸€ç¯‡ï¼Œç°åœ¨å·²ç»æœ‰äº† xx-blog ä»“åº“&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;å‚è€ƒï¼š&lt;a href=&quot;https://docs.astro.build/zh-cn/guides/deploy/cloudflare/#%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8-cicd-%E8%BF%9B%E8%A1%8C%E9%83%A8%E7%BD%B2&quot;&gt;éƒ¨ç½²ä½ çš„ Astro ç«™ç‚¹è‡³ Cloudflare&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;1. æ³¨å†Œ cloudflare è´¦å·&lt;/h2&gt;
&lt;h2&gt;2. ç™»å½•è‡³ Cloudflare dashboard&lt;/h2&gt;
&lt;p&gt;Compute (Workers) &gt; Workers &amp;#x26; Pages -&gt;  Create Application -&gt; ä¸è¦ç›´æ¥è¿æ¥ githubï¼Œé€‰æ‹©ä¸‹é¢çš„ &lt;strong&gt;Get Start&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://pic.cloudinwind4132.top/1769962721405.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;ç„¶å Import an existing Git repository -&gt; é€‰æ‹©ä½ æƒ³è¦éƒ¨ç½²çš„ä»“åº“ï¼ˆä¾‹å¦‚ xx-blogï¼‰-&gt; Begin setup&lt;/p&gt;
&lt;p&gt;é…ç½®é¡¹ç›®ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Framework presetï¼ˆæ¡†æ¶é¢„è®¾ï¼‰ï¼šAstro&lt;/li&gt;
&lt;li&gt;Build commandï¼ˆæ„å»ºå‘½ä»¤ï¼‰ï¼šnpm run build&lt;/li&gt;
&lt;li&gt;Build output directoryï¼ˆæ„å»ºè¾“å‡ºç›®å½•ï¼‰ï¼šdist&lt;/li&gt;
&lt;li&gt;é‡è¦ï¼šVariables and Secrets ä¸­æ·»åŠ  &lt;code&gt;DEPLOYMENT_PLATFORM&lt;/code&gt;ï¼Œå€¼ä¸º &lt;code&gt;cloudflare&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;3. ä¿å­˜å¹¶éƒ¨ç½²ï¼Œè®¿é—®ç”Ÿäº§çš„é“¾æ¥&lt;/h2&gt;</content:encoded><h:img src="https://pic.hana0721.top//rl-note.3yex1wenfg.webp"/><enclosure url="https://pic.hana0721.top//rl-note.3yex1wenfg.webp"/></item><item><title>Astro-Pure Blog å¤šå¹³å°éƒ¨ç½²(2) - github page</title><link>https://claudiakim6827362.github.io/blog/rl-note-3</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/rl-note-3</guid><description>å¦‚ä½•å°† astro-pure ä¸»é¢˜éƒ¨ç½²åˆ° github.io? éœ€è¦æ³¨æ„ç»†èŠ‚</description><pubDate>Fri, 12 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;blockquote&gt;
&lt;p&gt;æ¥ç¬¬ä¸€ç¯‡ï¼Œç°åœ¨å·²ç»æœ‰äº† xx-blog ä»“åº“&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;ç›®æ ‡ï¼šç§æœ‰ä»“åº“ xx-blogï¼ˆAstro é¡¹ç›®ï¼‰ â†’ æ¯æ¬¡ commit è‡ªåŠ¨æ„å»º â†’ è‡ªåŠ¨å‘å¸ƒåˆ°å…¬å¼€çš„ xx.github.io â†’ é€šè¿‡ https://xx.github.io
è®¿é—®&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;æ–¹æ¡ˆï¼šğŸ‘‰ GitHub Actions + GitHub Pagesï¼ˆå®˜æ–¹æ¨èç©æ³•ï¼‰&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code&gt;xx-blog (ç§æœ‰, Astro æºç )
        |
        |  git push
        v
GitHub Actions
        |
        |  astro build
        v
xx.github.io (å…¬å¼€, åªå­˜ dist é™æ€æ–‡ä»¶)
        |
        v
https://xx.github.io

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å…³é”®ç‚¹ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;xx-blogï¼šç§æœ‰ï¼Œåªæ”¾æºç &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;xx.github.ioï¼šå…¬å¼€ï¼Œåªæ”¾æ„å»ºåçš„é™æ€æ–‡ä»¶&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;GitHub Actions è´Ÿè´£â€œæ¬è¿ + æ„å»º + å‘å¸ƒâ€&lt;/p&gt;
&lt;h2&gt;1. åˆ›å»º xx.github.io ä»“åº“&lt;/h2&gt;
&lt;p&gt;å¦‚æœç”¨æˆ·åä¸º xxï¼Œåˆ™åˆ›å»ºä¸€ä¸ªåä¸º xx.github.io çš„ä»“åº“ï¼Œå±æ€§ä¸º &lt;code&gt;Public&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;2. github page é…ç½®&lt;/h2&gt;
&lt;p&gt;xx.github.io â†’ Settings â†’ Pages&lt;/p&gt;
&lt;p&gt;è®¾ç½®ä¸ºï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sourceï¼šDeploy from a branch&lt;/li&gt;
&lt;li&gt;Branchï¼šmain&lt;/li&gt;
&lt;li&gt;Folderï¼š/ (root)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;3. github action é…ç½®&lt;/h2&gt;
&lt;p&gt;Settings -&gt; Actions -&gt; General -&gt; Workflow permissions&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://pic.cloudinwind4132.top/1769962883535.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2&gt;4. é…ç½® xx-blog ä»“åº“&lt;/h2&gt;
&lt;h3&gt;4.1 ä¿®æ”¹é…ç½®æ–‡ä»¶&lt;/h3&gt;
&lt;p&gt;ä¿®æ”¹ &lt;code&gt;xx-blog/astro.config.mjs&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export default defineConfig({
  // Top-Level Options
  site: isGithubPages ? &apos;https://xx.github.io/&apos; : (isCloudflare ? &apos;https://xx.pages.dev/&apos; : &apos;https://xx.top/&apos;),
  // site: &apos;https://hana-blog.pages.dev/&apos;,
  // base: &apos;/docs&apos;,
  trailingSlash: &apos;never&apos;,

  // Internationalization
  i18n: {
    locales: [&apos;zh&apos;, &apos;en&apos;],
    defaultLocale: &apos;zh&apos;,
    routing: {
      prefixDefaultLocale: false
    }
  },

  adapter: isGithubPages ? undefined : (isCloudflare ? cloudflare() : vercel()),
  output: isGithubPages ? &apos;static&apos; : (isCloudflare ? &apos;static&apos; : &apos;server&apos;),

  image: {
    service: {
      entrypoint: &apos;astro/assets/services/sharp&apos;
    }
  },

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;åˆ é™¤ &lt;code&gt;package.json&lt;/code&gt; ä¸­çš„ &lt;code&gt;overrides&lt;/code&gt; å­—æ®µï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&quot;overrides&quot;: {
    &quot;@emmetio/css-parser&quot;: &quot;0.5.0&quot;
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;4.2 åˆ›å»º token&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;æ‰“å¼€ Github çš„åˆ›å»º Token çš„ &lt;a href=&quot;https://github.com/settings/personal-access-tokens/new&quot;&gt;é¡µé¢&lt;/a&gt;ï¼Œ&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;åœ¨ Repository access ä¸­é€‰æ‹© xx.github.io çš„ä»“åº“ï¼Œä»“åº“æƒé™ä¸­ç»™ Content çš„ read and writeï¼Œ&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;åœ¨ xx-Blog çš„ä»“åº“çš„ settings ä¸­é€‰æ‹© Secrets and variables ä¸­çš„ Actions ä¸­æ·»åŠ ä¸€ä¸ª Secretï¼Œåå­—ä¸º PERSONAL_TOKENï¼Œå€¼ä¸ºåˆšåˆšåˆ›å»ºçš„ Tokenã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;4.3 æ–°å»º GitHub Actions å·¥ä½œæµ&lt;/h3&gt;
&lt;p&gt;åœ¨ xx-blog ä¸­åˆ›å»ºæ–‡ä»¶ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;.github/workflows/deploy.yml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å†…å®¹å¦‚ä¸‹ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;name: Deploy to xx.github.io

on:
  push:
    branches:
      - main

permissions:
  contents: write

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout source
        uses: actions/checkout@v3

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Setup Bun
        uses: oven-sh/setup-bun@v1
        with:
          bun-version: latest

      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: ~/.bun/install/cache
          key: ${{ runner.os }}-bun-${{ hashFiles(&apos;**/bun.lockb&apos;) }}
          restore-keys: |
            ${{ runner.os }}-bun-

      - name: Install dependencies
        run: bun i

      - name: Set environment variables
        run: |
          echo &quot;DEPLOYMENT_PLATFORM=github&quot; &gt;&gt; $GITHUB_ENV

      - name: Build site
        run: bun run build:github

      - name: Deploy to xx.github.io
        uses: peaceiris/actions-gh-pages@v3
        with:
          personal_token: ${{ secrets.PERSONAL_TOKEN }}
          external_repository: xx/xx.github.io
          publish_branch: main
          publish_dir: ./dist
          force_orphan: true

&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;5. éªŒè¯&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;åœ¨ cloudblog ä¸­éšä¾¿æ”¹ç‚¹ä¸œè¥¿&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;git push origin main&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;æ‰“å¼€ï¼šcloudblog â†’ Actions&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;çœ‹æ˜¯å¦ Deploy Astro to GitHub Pages å˜ç»¿ âœ…&lt;/p&gt;
&lt;ol start=&quot;4&quot;&gt;
&lt;li&gt;æŸ¥çœ‹ xx.github.io é‡Œ åº”è¯¥åªæœ‰è¿™äº›ä¸œè¥¿&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;cloud.github.io/
â”œâ”€â”€ index.html
â”œâ”€â”€ assets/
â”œâ”€â”€ favicon.svg
â”œâ”€â”€ _astro/
â”œâ”€â”€ 404.html
â””â”€â”€ ...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;âœ”ï¸ å…¨éƒ¨æ˜¯ Astro build åçš„ dist å†…å®¹&lt;/p&gt;
&lt;ol start=&quot;5&quot;&gt;
&lt;li&gt;è®¿é—®ï¼šhttps://xx.github.io&lt;/li&gt;
&lt;/ol&gt;</content:encoded><h:img src="https://pic.hana0721.top//rl-note.3yex1wenfg.webp"/><enclosure url="https://pic.hana0721.top//rl-note.3yex1wenfg.webp"/></item><item><title>Astro-Pure Blog å¤šå¹³å°éƒ¨ç½²(1)-Vercel</title><link>https://claudiakim6827362.github.io/blog/rl-note-2</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/rl-note-2</guid><description>å°† astro éƒ¨ç½²åˆ° verelã€ cloudflare pages</description><pubDate>Thu, 11 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;blockquote&gt;
&lt;p&gt;æœ¬ç¯‡å†…å®¹é€‚ç”¨äºå°† Astro-Pure ä¸»é¢˜éƒ¨ç½²åˆ° vercel&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;å› ä¸ºæœ¬äººæŒ‰ç…§å®˜æ–¹æŒ‡å— ä½¿ç”¨ themplate è¿›è¡Œéƒ¨ç½²çš„æ—¶å€™ï¼Œç¼–è¯‘å‡ºç°é—®é¢˜ï¼Œæ•…å†™æ­¤ç¯‡æ–‡ç« &lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;æ­¤å¤„æ„Ÿè°¢ï¼š&lt;a href=&quot;https://axi404.com/&quot;&gt;Axi404&lt;/a&gt;ï¼Œ&lt;a href=&quot;https://hana0721.top/&quot;&gt;hana0721&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;æœ¬æ–‡å‚è€ƒï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://axi404.top/blog/website-vercel&quot;&gt;Axi404 åšå®¢ä¸Šæ‰‹æŒ‡å—&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://axi404.top/blog/astro-multi-pages&quot;&gt;ä¸º Astro åšå®¢æ·»åŠ å¤šéƒ¨ç½²ç«™ç‚¹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://axi404.top/blog/waline-install&quot;&gt;Waline è¯„è®ºç³»ç»Ÿé…ç½®æŒ‡å—&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;1. github ä»“åº“é…ç½®&lt;/h2&gt;
&lt;h3&gt;1.1 for ä»“åº“&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;fork&lt;/code&gt; githubä»“åº“: https://github.com/Minakanmi-Yuki/hana-blog&lt;/p&gt;
&lt;p&gt;å‡è®¾ fork åˆ°ä¸ªäºº github ä¸‹çš„ä»“åº“åç§°ä¸º xx-blog&lt;/p&gt;
&lt;h3&gt;1.2 xx-blog ä»“åº“è®¾ç½®&lt;/h3&gt;
&lt;p&gt;ä¿®æ”¹é…ç½® &lt;code&gt;astro.config.ts&lt;/code&gt;ï¼Œåªéœ€è¦ä¿®æ”¹ &lt;code&gt;site&lt;/code&gt;ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// https://astro.build/config
export default defineConfig({
  // [Basic]
  site: &apos;https://xxx.top&apos;,
  // Deploy to a sub path
  // https://astro-pure.js.org/docs/setup/deployment#platform-with-base-path
  // base: &apos;/astro-pure/&apos;,
  trailingSlash: &apos;never&apos;,
  // root: &apos;./my-project-directory&apos;,
  server: { host: true },

&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;2. Vercel å¹³å°éƒ¨ç½²&lt;/h2&gt;
&lt;p&gt;ä½¿ç”¨ github è´¦å·ç™»å½• vercel&lt;/p&gt;
&lt;p&gt;é€‰æ‹© &lt;code&gt;import github repository&lt;/code&gt;ï¼Œå¯¼å…¥ xx-blog ä»“åº“ï¼Œç„¶åéƒ¨ç½²ï¼Œvercel ä¼šè‡ªåŠ¨å®Œæˆéƒ¨ç½²ï¼Œå¹¶æä¾›ä¸€ä¸ªå…è´¹çš„åŸŸå&lt;/p&gt;
&lt;h2&gt;3. ç»‘å®šä¸“å±åŸŸå&lt;/h2&gt;
&lt;p&gt;å‚è€ƒï¼š&lt;a href=&quot;https://axi404.top/blog/website-vercel#%E6%AD%A5%E9%AA%A4%E4%B8%83%E5%8F%AF%E9%80%89%E7%BB%91%E5%AE%9A%E4%BD%A0%E7%9A%84%E4%B8%93%E5%B1%9E%E5%9F%9F%E5%90%8D&quot;&gt;ç»‘å®šè‡ªå®šä¹‰åŸŸå&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;4. é›†æˆ Waline è¯„è®ºç³»ç»Ÿ&lt;/h2&gt;
&lt;p&gt;å‚è€ƒï¼š&lt;a href=&quot;https://axi404.top/blog/waline-install&quot;&gt;Waline è¯„è®ºç³»ç»Ÿé…ç½®&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;å…³é”®ï¼šç¬¬ä¸€ä¸ªåœ¨ https://your-waline-server-url/ui/ ä¸­æ³¨å†Œçš„è´¦å·æ˜¯ç®¡ç†å‘˜ï¼ŒåŠ¡å¿…åœ¨éƒ¨ç½²åç›´æ¥å…ˆè¡Œç™»å½•ã€‚&lt;/p&gt;</content:encoded><h:img src="https://pic.hana0721.top//rl-note.3yex1wenfg.webp"/><enclosure url="https://pic.hana0721.top//rl-note.3yex1wenfg.webp"/></item><item><title>Astro-Pure Blog éƒ¨ç½²</title><link>https://claudiakim6827362.github.io/blog/rl-note-1</link><guid isPermaLink="true">https://claudiakim6827362.github.io/blog/rl-note-1</guid><description>å¦‚ä½•å°† astro-pure ä¸»é¢˜éƒ¨ç½²åˆ° github.io?</description><pubDate>Wed, 10 Dec 2025 00:00:00 GMT</pubDate><content:encoded>&lt;blockquote&gt;
&lt;p&gt;æœ¬ç¯‡å†…å®¹é€‚ç”¨äºå°† Astro-Pure ä¸»é¢˜éƒ¨ç½²åˆ° xxx.github.io ä»“åº“ï¼Œç„¶åé€šè¿‡ xxx.github.io åŸŸåè®¿é—®;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;ä½†æ˜¯æŒ‰ç…§æœ¬æ–‡æ–¹æ³•éƒ¨ç½²åï¼Œå¯¼å…¥åˆ°vercel ä¼šæŠ¥é”™ï¼Œå› ä¸ºå¦‚æœæƒ³æŠŠ blog å¯¼å…¥åˆ° vercelï¼Œè¯·çœ‹å¦ä¸€ç¯‡æ–‡ç« &lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;å› ä¸ºæœ¬äººæŒ‰ç…§å®˜æ–¹æŒ‡å— ä½¿ç”¨ themplate è¿›è¡Œéƒ¨ç½²çš„æ—¶å€™ï¼Œç¼–è¯‘å‡ºç°é—®é¢˜ï¼Œæ•…å†™æ­¤ç¯‡æ–‡ç« &lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;æ­¤å¤„æ„Ÿè°¢ &lt;a href=&quot;https://huang2202.github.io/&quot;&gt;huang2202&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;1. åˆ›å»º xxx.github.io å¹¶é…ç½®&lt;/h2&gt;
&lt;p&gt;Settings -&gt; Actions -&gt; General -&gt; Workflow permissions&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://p.ipic.vip/iuffch.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;Setting-&gt;Pages-&gt;Build and deployment-&gt;é€‰æ‹© Github Action&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://p.ipic.vip/lajmey.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2&gt;2. git clone ç›¸å…³ä»£ç &lt;/h2&gt;
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;git clone https://github.com/huang2202/huang2202.github.io.git
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ä¸‹è½½åˆ°æœ¬åœ°åï¼Œåˆ é™¤ &lt;code&gt;.git&lt;/code&gt; æ–‡ä»¶å¤¹&lt;/p&gt;
&lt;h2&gt;3. git é…ç½®&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;cd huang2202.github.io

mv huang2202.github.io xxx.github.io
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å…³è”è‡ªå·±çš„ github ä»“åº“&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git init
git remote add origin https://github.com/xxx/xxx.github.io.git

git branch -M main
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ä¿®æ”¹é…ç½® &lt;code&gt;astro.config.ts&lt;/code&gt;ï¼Œåªéœ€è¦ä¿®æ”¹ &lt;code&gt;site&lt;/code&gt;ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// https://astro.build/config
export default defineConfig({
  // [Basic]
  site: &apos;https://xxx.github.io&apos;,
  // Deploy to a sub path
  // https://astro-pure.js.org/docs/setup/deployment#platform-with-base-path
  // base: &apos;/astro-pure/&apos;,
  trailingSlash: &apos;never&apos;,
  // root: &apos;./my-project-directory&apos;,
  server: { host: true },

&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;4. push&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;git add .
git commit -m &quot;init&quot;
git push -u origin main
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;5. ç™»å½•githubä»“åº“ï¼ŒæŸ¥çœ‹ Actions&lt;/h2&gt;
&lt;p&gt;æŸ¥çœ‹æ˜¯å¦éƒ¨ç½²æˆåŠŸï¼Œå¦‚æœæˆåŠŸï¼Œåˆ™è®¿é—® https://xxx.github.io&lt;/p&gt;</content:encoded><h:img src="https://pic.hana0721.top//rl-note.3yex1wenfg.webp"/><enclosure url="https://pic.hana0721.top//rl-note.3yex1wenfg.webp"/></item></channel></rss>